{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for extracting the most used AI techniques, AI usecases and Summaries from the datasets available on the following websites:\n",
    "-   https://ai.gov/ai-use-cases/\n",
    "-   https://www.hhs.gov/programs/topic-sites/ai/use-cases/index.html\n",
    "#### This notebook extracts the most used AI techniques from both datasets, performs clustering to group the 430 contracts into 20 clusters, and then summarizes the combined text from each cluster using LLMs (BART, phi3, llama3). Finally, it performs topic labeling using the llama3 model.\n",
    "\n",
    "#### Files needed to run the notebook:\n",
    "        -- '2023 Consolidated AI Use Case Inventory (PUBLIC).csv'\n",
    "        -- 'hhs-ai-use-cases-2023-public-inventory.csv'        \n",
    "#### Files generated from the notebook:\n",
    "        -- 'ai_use_case_topics.csv'\n",
    "        -- 'summaries_of_usecases.csv'\n",
    "        -- 'ai_use_cases_relevant_430.csv'        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the two datasets to create two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "csv_path_hhs = os.path.join(current_working_directory, \"docs\", \"use_cases\", \"hhs-ai-use-cases-2023-public-inventory.csv\")\n",
    "csv_path_AI_inventory = os.path.join(current_working_directory, \"docs\", \"use_cases\",\"2023 Consolidated AI Use Case Inventory (PUBLIC).csv\")\n",
    "df_hhs = pd.read_csv(csv_path_hhs, encoding='latin1')\n",
    "df_AI_inv = pd.read_csv(csv_path_AI_inventory, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 12)\n",
      "Index(['use_case_name', 'agency', 'bureau_department', 'summary_of_use_case'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_hhs.shape)\n",
    "df_hhs_trim=df_hhs[['Use Case Name', 'Agency', 'Bureau / Department', 'Summary of Use Case']].copy()\n",
    "df_hhs_trim = df_hhs_trim.clean_names()\n",
    "\n",
    "print(df_hhs_trim.columns)\n",
    "rename_dict = {'summary_of_use_case': 'Summary','use_case_name': 'Title', 'agency':'Agency', 'bureau_department': 'Department'}\n",
    "df_hhs_trim = df_hhs_trim.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710, 10)\n",
      "Index(['Title', 'Agency', 'Department_code', 'Summary', 'Department',\n",
      "       'Techniques'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_AI_inv.shape)\n",
    "df_AI_inv_trim=df_AI_inv[['Title',  'Agency', 'Department_Code',  'Summary', 'Department', 'Techniques']].copy()\n",
    "rename_dict = {'Department_Code': 'Department_code'}\n",
    "df_AI_inv_trim = df_AI_inv_trim.rename(columns=rename_dict)\n",
    "print(df_AI_inv_trim.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the department code from the text in the paranthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_or_return_same(text):\n",
    "    match = re.search(r'\\((.*?)\\)', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "df_hhs_trim['Department_code']=df_hhs_trim['Department'].apply(extract_or_return_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exrtacting the mostly used AI techniques `hhs-ai-use-cases-2023-public-inventory.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "techniques = df_AI_inv.Techniques.tolist()\n",
    "techniques = [item.split(',') for item in techniques if isinstance(item, str)]\n",
    "flattened_list = list(itertools.chain.from_iterable(techniques))\n",
    "mostly_used_techniques=list(set(flattened_list))\n",
    "print(len(mostly_used_techniques))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text cleaning of the mostly used AI techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "def split_and_flatten(strings):\n",
    "    split_lists = [s.split(';') for s in strings]\n",
    "    flattened_list_ = list(itertools.chain.from_iterable(split_lists))\n",
    "    flattened_list_ = [item.strip() for item in flattened_list_]\n",
    "    return flattened_list_\n",
    "\n",
    "mostly_used_techniques_=split_and_flatten(mostly_used_techniques)\n",
    "mostly_used_techniques_ = [s.replace('Unknown','').replace('.','').replace('#','').replace('&','and').replace('Â®','').replace('5)','5').replace(' (Nlp)','').strip().upper() for s in mostly_used_techniques_ if len(s)>1]\n",
    "print(len(mostly_used_techniques_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below script processes a list by removing specified elements and mapping certain elements to new values using a dictionary. It then applies these transformations to clean and standardize the list of techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "def process_list(input_list, elements_to_remove, mapping_dict):\n",
    "    # Remove specified elements\n",
    "    filtered_list = [element for element in input_list if element not in elements_to_remove]\n",
    "    # Map some elements to new values\n",
    "    mapped_list = [mapping_dict.get(element, element) for element in filtered_list]\n",
    "    # mapped_list=[s for s in mapped_list if s.contain('ML')]\n",
    "    return list(set(mapped_list))\n",
    "\n",
    "elements_to_remove = ['AT THIS TIME',\n",
    "                    'OTHER',\n",
    "                    'DOODLER: HTTPS://GITHUBCOM/DBUSCOMBE-USGS/DASH_DOODLER',\n",
    "                    'PYTHON IN JUPYTER LABS',\n",
    "                    'RANGE OF DATA DRIVEN', \n",
    "                    'DOCUMENT UNDERSTANDING',\n",
    "                    'ACTIVE LEARNING',\n",
    "                     'RETINANET',\n",
    "                     'SUBJECTS WITH LONG-ARM RIFLES OR LARGE BACKPACKS AND TO EXCLUDE ITEMS OF LITTLE OR NO INTEREST SUCH AS ANIMALS',\n",
    "                     'CONTINUOUS ACTIVE LEARNING'\n",
    "                    ]\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    'NATURAL LANGUAGE PROCESSING (NLP)': 'NATURAL LANGUAGE PROCESSING',\n",
    "    'NLP':'NATURAL LANGUAGE PROCESSING',\n",
    "    'INTELLIGENT DOCUMENT RECOGNITION (IDR)': 'INTELLIGENT DOCUMENT RECOGNITION',\n",
    "    'OPTICAL CHARACTER RECOGNITION (OCR)': 'OPTICAL CHARACTER RECOGNITION',\n",
    "    'INTELLIGENT CHARACTER RECOGNITION (ICR)': 'INTELLIGENT CHARACTER RECOGNITION',\n",
    "    'ROBOTIC PROCESS AUTOMATION (RPA)': 'ROBOTIC PROCESS AUTOMATION',\n",
    "    'ROBOTIC PROCESSING AUTOMATION (RPA)': 'ROBOTIC PROCESS AUTOMATION',\n",
    "    'THE MATROID SOFTWARE CURRENTLY PROCESSES AND ANNOTATES IMAGES USING PROPRIETARY SOFTWARE TO DETERMINE IF ANY OF THE IMAGES CONTAIN HUMAN SUBJECTS FUTURE USE CASES INCLUDE THE POTENTIAL TO DETECT ADDITIONAL ITEMS OF INTEREST SUCH AS VEHICLES': 'IMAGE PROCESSING',\n",
    "    'ML': 'MACHINE LEARNING',\n",
    "    'AI': 'ARTIFICIAL INTELLIGENCE',\n",
    "    'XGBOOST ALGORITHM WITH PARAMETERS TUNED VIA RANDOM HYPERPARAMETER SEARCH USING 5-FOLD CROSS VALIDATION ON THE TRAINING DATASET FOR 60 ITERATIONS (RESULTING IN AT LEAST A 95% CHANCE OF FINDING A HYPERPARAMETER COMBINATION IN THE BEST 5% OF COMBINATIONS) THE SCORES RESULTING FROM THE XGBOOST ARE CALIBRATED VIA PLATT SCALING SO THAT MODEL SCORES CAN BE INTERPRETED AS DEFAULT PROBABILITIES THESE IS STANDARD METHOD FOR TRAINING CREDIT SCORING ALGORITHMS IN THE INDUSTRY':'MACHINE LEARNING',\n",
    "    'MACHINE LANGUAGE LEARNING':'MACHINE LEARNING',\n",
    "    'DOCUMENT/FILE CLASSIFICATION: DOCUMENT/FILE CLASSIFICATION IS A SUPERVISED ML ALGORITHM THAT CLASSIFIES WHOLE DOCUMENTS ACCORDING TO THEIR TYPE THE ALGORITHM WORKS BY CONVERTING EACH DOCUMENT TO A TERM FREQUENCYÂ\\x80\\x93INVERSE DOCUMENT FREQUENCY (TF-IDF) NUMERICAL REPRESENTATION AND PASSING THESE VECTORS THROUGH A MULTI-LAYER NEURAL NETWORK TO FINALLY GET THE DOCUMENTÂ\\x80\\x99S TYPE/CLASS DOCUMENT/FILE CLUSTERING: DOCUMENT/FILE CLUSTERING IS AN UNSUPERVISED ML ALGORITHM THAT GROUPS SIMILAR FILES TOGETHER ACCORDING TO THEIR CONTENT FOR EXAMPLE':'DOCUMENT/FILE CLASSIFICATION: NLP',\n",
    "    'LONG SHORT TERM MEMORY (LSTM) MODELS':'RNN-LSTM',\n",
    "    'LONG-SHORT TERM MEMORY BASED RECURRENT NEURAL NETWORKS':'RNN-LSTM',\n",
    "    'ML VIA A CONVOLUTIONAL NEURAL NETWORK':'NEURAL NETWORKS',\n",
    "    'MULTI-LAYER PERCEPTRON':'NEURAL NETWORKS',\n",
    "    'YOLOV5':'COMPUTER VISION',\n",
    "    'MACHINE VISION':'COMPUTER VISION',\n",
    "    'NATURAL LANGUAGE PROCESSING (NLP) ALONG WITH SUPERVISED AND SELF-SUPERVISED MACHINE LEARNING VIA DEEP LEARNING MODELS':\"NATURAL LANGAUGE PROCESSING, DEEP LEARING\",\n",
    "    \"SUCH AS A RESIDUAL NEURAL NETWORK (RESNET) AND CONVOLUTIONAL NEURAL NETWORKS (CNN)\":\"RESNET AND CNN\",\n",
    "    'ARTIFICIAL NEURAL NETWORK': 'NEURAL NETWORKS',\n",
    "    'NATURAL LANGUAGE PROCESSING FOR (A) DOCUMENT CLASSIFICATION AND (B) SENTENCE-LEVEL CAUSAL PASSAGE DETECTION': 'NLP CLASSIFICATION, SENTIMENT ANALYSIS',\n",
    "    'STANDARD MACHINE LEARNING TO PREDICT VALUES FOR DESCRIPTIVE METADATA FIELDS GIVEN VARIOUS INPUTS SUCH AS THE CONTENT AND METADATA FROM THE RECORDS MANAGEMENT SYSTEM':'MACHINE LEARNING',\n",
    "    '1 TEXTRACTION MACHINE LEARNING (ML) SERVICE WHICH USED OCR TO EXTRACT THE TEXT/DATA FROM SCANNED IMAGES 2 AUTOMATED NLP (NATURAL LANGUAGE PROCESSING) TO DETECT PII INFORMATION OUT OF THE EXTRACTED TEXT FROM SCANNED IMAGES': \"NATURAL LANGUAGE PROCESSING, IMAGE PROCESSING\",\n",
    "    'ML (RECOMMENDER ALGORITHIM)': 'MACHINE LEARNING RECOMMENDER ALGORITHIM',\n",
    "    'AI/ML TECHNIQUES':'MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE TECHNIQUES',\n",
    "    'BAGGED TREES (AKA RANDOM FOREST) CLASSIFICATION':'RANDOM FOREST CLASSIFICATION',\n",
    "    'AI/ML TECHNIQUES (EG RANDOM FORESTS)':'RANDOM FOREST',\n",
    "    'AI/ML TECHNIQUES (EG LSTMS)':'LONG-SHORT TERM MEMORY',\n",
    "    'OPTICAL MARK READING (OMR)':'OPTICAL MARK READING',\n",
    "    'NON-DISCLOSURE AGREEMENTS WILL CLUSTER TOGETHER WHILE PRODUCT PRESENTATION FILES WILL BE ASSIGNED TO A DIFFERENT CLUSTER':'CLUSTERING'\n",
    "     }\n",
    "\n",
    "# Apply the function\n",
    "mostly_used_techniques__ = process_list(mostly_used_techniques_, elements_to_remove, mapping_dict)\n",
    "print(len(mostly_used_techniques__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script replaces specified substrings in a list of techniques with their corresponding values from a replacement dictionary, standardizing the terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MACHINE LEARNING',\n",
       " 'RANDOM FOREST REGRESSION',\n",
       " 'AI BASED VECTOR SEARCH OR CONTENT SIMILARITY SEARCH',\n",
       " 'NATURAL LANGAUGE PROCESSING',\n",
       " 'MACHINE LEARNING CLASSIFICATION',\n",
       " 'LATENT DIRICHLET ALLOCATION',\n",
       " 'RECURRENT NEURAL NETWORKS-LONG-SHORT TERM MEMORY',\n",
       " 'NATURAL LANGUAGE PROCESSING, IMAGE PROCESSING',\n",
       " 'REGRESSION AND RELATED METHODS',\n",
       " 'IMAGE CLASSIFICATION USING JOINT UNSUPERVISED LEARNING (JULE)',\n",
       " 'RECURRENT NEURAL NETWORKS',\n",
       " 'API AUTOMATION',\n",
       " 'NATURAL LANGUAGE PROCESSING',\n",
       " 'MASK R-CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'HIERARCHICAL GENERATIVE MODEL',\n",
       " 'STOCHASTIC GRADIENT DECENT (LINEARLEARNER)',\n",
       " 'TRANSFER LEARNING',\n",
       " 'CONVOLUTIONAL NEURAL NETWORK',\n",
       " 'REGRESSION',\n",
       " 'RANDOM FOREST CLASSIFICATION',\n",
       " 'CONVOLUTIONAL NEURAL NETWORKS (FASTERN-RCONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'FUZZY MATCHING',\n",
       " 'CLOUD BASED COMMERCIAL-OFF-THE-SHELF PRE-TRAINED NATURAL LANGUAGE PROCESSING MODELS',\n",
       " 'GRAPHICAL NEURAL NETWORK',\n",
       " 'REINFORCEMENT LEARNING',\n",
       " 'XGBOOST',\n",
       " 'MANUAL LEARNING/NATURAL LANGUAGE',\n",
       " 'VISUAL ANALYSIS',\n",
       " 'OPTICAL CHARACTER RECOGNITION',\n",
       " 'CHATGPT',\n",
       " 'RESIDUAL NEURAL NETWORKS',\n",
       " 'ASSISTED MACHINE LEARNING',\n",
       " 'COMPUTER VISION',\n",
       " 'ROBOTIC PROCESS AUTOMATION',\n",
       " 'INTELLIGENT DOCUMENT RECOGNITION',\n",
       " 'LOGISTIC REGRESSION',\n",
       " 'RESIDUAL NEURAL NETWORKS AND CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'BERT TEXT CLASSIFICATION',\n",
       " 'GANS',\n",
       " 'CLASSIFICATION',\n",
       " 'EXTREME GRADIENT BOOSTED CLASSIFICATION',\n",
       " 'K-MEANS CLUSTERING',\n",
       " 'SUPERVISED MACHINE LEARNING - CLASSIFICATION',\n",
       " 'MACHINE LEARNING VIA DEEP LEARNING MODELS',\n",
       " 'DEEP LEARING',\n",
       " 'OPTICAL MARK READING',\n",
       " 'DEEP CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'HIERARCHICAL CLUSTERING',\n",
       " 'CLUSTERING',\n",
       " 'BIG DATA',\n",
       " 'SUPPORT VECTOR MACHINE',\n",
       " 'DOCUMENT/FILE CLASSIFICATION: NATURAL LANGUAGE PROCESSING',\n",
       " 'RANDOM SURVIVAL FORESTS',\n",
       " 'NOVEL SPECTROSCOPIC TECHNOLOGY',\n",
       " 'IMAGE PROCESSING',\n",
       " 'NATURAL LANGAUGE PROCESSING, DEEP LEARING',\n",
       " 'UNET CONVOLUTIONAL NEURAL NETWORKS IMAGE RECOGNITION',\n",
       " 'NATURAL LANGUAGE PROCESSING CLASSIFICATION, SENTIMENT ANALYSIS',\n",
       " 'ENSEMBLE LEARNING',\n",
       " 'RANDOM FOREST',\n",
       " 'MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE TECHNIQUES',\n",
       " 'VIRTUAL ASSISTANT',\n",
       " 'LARGE LANGUAGE SUMMARIZATION MODEL',\n",
       " 'BARCODE RECOGNITION',\n",
       " 'MACHINE LEARNING VIA DEEP LEARNING MODEL',\n",
       " 'LARGE LANGUAGE MODEL PROMPT ENGINEERING',\n",
       " 'RANDOM FOREST CLASSIFICATION AND REGRESSION',\n",
       " 'MOBILENET',\n",
       " 'INTELLIGENT CHARACTER RECOGNITION',\n",
       " 'OBJECT DETECTION',\n",
       " 'CUSTOM TEXT CLASSIFICATION MACHINE LEARNING MODEL',\n",
       " 'DESCRIPTIVE ANALYSIS',\n",
       " 'GRADIENT BOOSTING',\n",
       " 'LONG-SHORT TERM MEMORY',\n",
       " 'CRITERIA BASED IDENTIFICATION',\n",
       " 'VARIATIONAL AUTOENCODERS',\n",
       " 'CLASSIFICATION MACHINE LEARNING MODEL INVOLVING COMPUTER VISION',\n",
       " 'TIME SERIES FORECAST',\n",
       " 'UNET CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'NEURAL NETWORK REGRESSION',\n",
       " 'SYNTHETIC IMAGE GENERATION',\n",
       " 'MACHINE LEARNING AUTOMATION AND ROBOTICS',\n",
       " 'CONSTRAINT-BASED HEURISTIC SEARCH',\n",
       " 'ARTIFICIAL INTELLIGENCE',\n",
       " 'COMPUTER VISION AND STATE ESTIMATION',\n",
       " 'R SQL AND DATABRICKS',\n",
       " 'NEURAL NETWORKS',\n",
       " 'CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'AUTOMATION AND ROBOTICS',\n",
       " 'VISUALIZATION',\n",
       " 'DEEP LEARNING MODELS - CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'CLOUD BASED COMMERCIAL-OFF-THE-SHELF PRE-TRAINED CHATBOT',\n",
       " 'NATURAL LANGUAGE PROCESSING AND GEO CLASSIFICATION',\n",
       " 'MACHINE LEARNING RECOMMENDER ALGORITHIM',\n",
       " 'SUPPORT VECTOR MACHINES']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_substrings(input_list, replacements):\n",
    "    processed_list = []\n",
    "    for item in input_list:\n",
    "        for old, new in replacements.items():\n",
    "            item = item.replace(old, new)\n",
    "        processed_list.append(item)\n",
    "    return processed_list\n",
    "\n",
    "# Replacement dictionary\n",
    "replacements = {\n",
    "    'ML': 'MACHINE LEARNING',\n",
    "    'DL': 'DEEP LEARNING',\n",
    "    'CNN': 'CONVOLUTIONAL NEURAL NETWORKS',\n",
    "    'NLP': 'NATURAL LANGUAGE PROCESSING',\n",
    "    'LLM': 'LARGE LANGUAGE MODEL',\n",
    "    'LSTM':'LONG-SHORT TERM MEMORY',\n",
    "    'RNN':  'RECURRENT NEURAL NETWORKS',\n",
    "    'UNET':'UNET CONVOLUTIONAL NEURAL NETWORKS',\n",
    "    'U-NET':'UNET CONVOLUTIONAL NEURAL NETWORKS',\n",
    "    'RESNET':'RESIDUAL NEURAL NETWORKS',\n",
    "    'CHAT BOT': 'CHATBOT',\n",
    "    'CHATBOTS': 'CHATBOT'\n",
    "}\n",
    "\n",
    "# Apply the function\n",
    "processed_list = replace_substrings(mostly_used_techniques__, replacements)\n",
    "processed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Department</th>\n",
       "      <th>Department_code</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information Gateway OneReach Application</td>\n",
       "      <td>ACF</td>\n",
       "      <td>ACF Children's Bureau</td>\n",
       "      <td>ACF Children's Bureau</td>\n",
       "      <td>The Information Gateway hotline connects to a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title Agency             Department  \\\n",
       "0  Information Gateway OneReach Application    ACF  ACF Children's Bureau   \n",
       "\n",
       "         Department_code                                            Summary  \n",
       "0  ACF Children's Bureau  The Information Gateway hotline connects to a ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column_order = ['Title', 'Agency', 'Department', 'Department_code','Summary']\n",
    "df_hhs_trim=df_hhs_trim[new_column_order]\n",
    "df_hhs_trim.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Department</th>\n",
       "      <th>Department_code</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Curated Synthetic Data</td>\n",
       "      <td>Customs and Border Protection</td>\n",
       "      <td>Department of Homeland Security</td>\n",
       "      <td>DHS</td>\n",
       "      <td>Synthetic Image Generation</td>\n",
       "      <td>AI Curated Synthetic Data creates synthetic da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title                         Agency  \\\n",
       "0  AI Curated Synthetic Data  Customs and Border Protection   \n",
       "\n",
       "                        Department Department_code  \\\n",
       "0  Department of Homeland Security             DHS   \n",
       "\n",
       "                   Techniques  \\\n",
       "0  Synthetic Image Generation   \n",
       "\n",
       "                                             Summary  \n",
       "0  AI Curated Synthetic Data creates synthetic da...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column_order = ['Title', 'Agency', 'Department', 'Department_code', 'Techniques','Summary']\n",
    "df_AI_inv_trim=df_AI_inv_trim[new_column_order]\n",
    "df_AI_inv_trim.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Department of Homeland Security': 'DHS',\n",
       " 'Department of Commerce': 'DOC',\n",
       " 'Department of Energy': 'DOE',\n",
       " 'Department of Interior': 'DOI',\n",
       " 'Department of Justice': 'DOJ',\n",
       " 'Department of Labor': 'DOL',\n",
       " 'Department of State': 'DOS',\n",
       " 'Department of Transportation': 'DOT',\n",
       " 'Department of Education': 'ED',\n",
       " 'U.S. Environmental Protection Agency': 'EPA',\n",
       " 'U.S. General Services Administration': 'GSA',\n",
       " 'Department of Health and Human Services': 'HHS',\n",
       " 'Department of Housing and Urban Development': 'HUD',\n",
       " 'National Archives and Records Administration': 'NARA',\n",
       " 'National Aeronautics and Space Administration': 'NASA',\n",
       " 'U.S. Office of Personnel Management': 'OPM',\n",
       " 'Social Security Administration': 'SSA',\n",
       " 'Department of Treasury': 'TREAS',\n",
       " 'U.S. Agency for International Development': 'USAID',\n",
       " 'Department of Agriculture': 'USDA',\n",
       " 'Department of Veterans Affairs': 'VA'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columns_to_dict(df, key_col, value_col):\n",
    "\n",
    "    result_dict = {}\n",
    "    for key, value in zip(df[key_col], df[value_col]):\n",
    "        if key in result_dict:\n",
    "            if value not in result_dict[key]:\n",
    "                result_dict[key].append(value)\n",
    "        else:\n",
    "            result_dict[key] = [value]\n",
    "    \n",
    "    # Flatten lists with a single item\n",
    "    result_dict = {k: v[0] if len(v) == 1 else v for k, v in result_dict.items()}\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Convert the two columns into a dictionary\n",
    "columns_to_dict(df_AI_inv_trim, 'Department', 'Department_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding AI techniques found in other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_list=processed_list+['AI', 'CHATBOT', 'ML', 'NLP', 'dl', 'deep learning', 'CHATBOTS', 'machine-learning', 'cyberthreats', 'seq2seq', 'text summarization', \n",
    "                               'associated topics', 'data-driven', 'decision making', 'Long Short-Term Memory', 'lstm', 'recurrent neural network', 'Chat Bot',  'topic modeling', 'entity recognition', \n",
    "                               'Predictive Intelligence', 'decision-making', 'Zero-shot learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "techniques_lower = [tech.lower() for tech in processed_list]\n",
    "# Function to identify techniques in the summary\n",
    "def identify_techniques(summary):\n",
    "    found_techniques = []\n",
    "    summary_lower = summary.lower()\n",
    "    for tech in techniques_lower:\n",
    "        if re.search(r'\\b' + re.escape(tech) + r'\\b', summary_lower):\n",
    "            if tech not in found_techniques:\n",
    "                found_techniques.append(tech)\n",
    "    return ', '.join(found_techniques)\n",
    "# Apply the function to each row in the DataFrame\n",
    "df_hhs_trim['Techniques'] = df_hhs_trim['Summary'].apply(identify_techniques)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "# df_hhs_trim[['Summary', 'Techniques']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = ['Title', 'Agency', 'Department', 'Department_code', 'Techniques','Summary']\n",
    "df_hhs_trim=df_hhs_trim[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Department</th>\n",
       "      <th>Department_code</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information Gateway OneReach Application</td>\n",
       "      <td>ACF</td>\n",
       "      <td>ACF Children's Bureau</td>\n",
       "      <td>ACF Children's Bureau</td>\n",
       "      <td>natural language processing, ai</td>\n",
       "      <td>The Information Gateway hotline connects to a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title Agency             Department  \\\n",
       "0  Information Gateway OneReach Application    ACF  ACF Children's Bureau   \n",
       "\n",
       "         Department_code                       Techniques  \\\n",
       "0  ACF Children's Bureau  natural language processing, ai   \n",
       "\n",
       "                                             Summary  \n",
       "0  The Information Gateway hotline connects to a ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hhs_trim.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Department</th>\n",
       "      <th>Department_code</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>B2B Matchmaking</td>\n",
       "      <td>International Trade Administration (ITA)</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>DOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The system's algorithms and AI technology qual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title                                    Agency  \\\n",
       "41  B2B Matchmaking  International Trade Administration (ITA)   \n",
       "\n",
       "                Department Department_code Techniques  \\\n",
       "41  Department of Commerce             DOC        NaN   \n",
       "\n",
       "                                              Summary  \n",
       "41  The system's algorithms and AI technology qual...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_inv_trim[df_AI_inv_trim['Techniques'].isna()].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_AI_inv_trim.iterrows():\n",
    "    if pd.isna(row['Techniques']):\n",
    "        df_AI_inv_trim.at[index, 'Techniques'] = identify_techniques(row['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Techniques                                                   ai\n",
       "Summary       The system's algorithms and AI technology qual...\n",
       "Name: 41, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_inv_trim[['Techniques', 'Summary']].iloc[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the two datasets and filter the rows based on the departments of intrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_use_cases=pd.concat([df_hhs_trim,df_AI_inv_trim], axis=0,ignore_index=True)\n",
    "ai_use_cases.shape\n",
    "ai_use_cases['Department_code']=ai_use_cases['Department_code'].str.upper()\n",
    "relevant_agencies = [\"HHS\", \"USDA\", \"ED\", \"DOE\", \"HUD\", \"SSA\", \"SBA\", \"VA\"]\n",
    "ai_use_cases_relevant=ai_use_cases[ai_use_cases['Department_code'].isin(relevant_agencies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the dataset containing 430 use cases to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_use_cases_relevant.to_csv('ai_use_cases_relevant_430.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_flatten(strings):\n",
    "    split_lists = [s.split(',') for s in strings]\n",
    "    flattened_list_ = list(itertools.chain.from_iterable(split_lists))\n",
    "    flattened_list_ = [item.strip().upper() for item in flattened_list_ if item != '' ]\n",
    "    return flattened_list_\n",
    "\n",
    "techniques_relavant=ai_use_cases_relevant['Techniques'].tolist()\n",
    "# techniques_relavant=list(set(techniques_relavant))\n",
    "techniques_relavant=list(set(split_and_flatten(techniques_relavant)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "mostly_used_techniques_relavant = process_list(techniques_relavant, elements_to_remove, mapping_dict)\n",
    "print(len(mostly_used_techniques_relavant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI techniques used in the 430 AI use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K-MEANS CLUSTERING',\n",
       " 'FUZZY MATCHING',\n",
       " 'OBJECT DETECTION',\n",
       " 'DATA-DRIVEN',\n",
       " 'TOPIC MODELING',\n",
       " 'MACHINE LEARNING CLASSIFICATION',\n",
       " 'MACHINE LEARNING',\n",
       " 'REINFORCEMENT LEARNING',\n",
       " 'XGBOOST',\n",
       " 'LONG-SHORT TERM MEMORY',\n",
       " 'CLUSTERING',\n",
       " 'BIG DATA',\n",
       " 'ARTIFICIAL INTELLIGENCE UNKNOWN',\n",
       " 'CYBERTHREATS',\n",
       " 'LONG SHORT-TERM MEMORY',\n",
       " 'VISUAL ANALYSIS',\n",
       " 'ASSOCIATED TOPICS',\n",
       " 'TEXT SUMMARIZATION',\n",
       " 'PREDICTIVE INTELLIGENCE',\n",
       " 'SEQ2SEQ',\n",
       " 'NOVEL SPECTROSCOPIC TECHNOLOGY',\n",
       " 'RECURRENT NEURAL NETWORK',\n",
       " 'DECISION MAKING',\n",
       " 'NATURAL LANGUAGE PROCESSING',\n",
       " 'HIERARCHICAL GENERATIVE MODEL',\n",
       " 'MACHINE-LEARNING',\n",
       " 'ENTITY RECOGNITION',\n",
       " 'COMPUTER VISION',\n",
       " 'ROBOTIC PROCESS AUTOMATION',\n",
       " 'ARTIFICIAL INTELLIGENCE',\n",
       " 'DEEP LEARNING',\n",
       " 'VIRTUAL ASSISTANT',\n",
       " 'RANDOM FOREST',\n",
       " 'TRANSFER LEARNING',\n",
       " 'CHATBOT',\n",
       " 'NEURAL NETWORKS',\n",
       " 'REGRESSION',\n",
       " 'VISUALIZATION',\n",
       " 'LOGISTIC REGRESSION',\n",
       " 'CLASSIFICATION',\n",
       " 'DECISION-MAKING',\n",
       " 'ZERO-SHOT LEARNING']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_used = replace_substrings(mostly_used_techniques_relavant, replacements)\n",
    "list(set(techniques_used))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the AI techniques to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"AI_echniques_used.txt\"\n",
    "# Open the file in write mode and save the list\n",
    "with open(file_name, \"w\") as file:\n",
    "    for item in techniques_used:\n",
    "        file.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankar.kalaga\\AppData\\Local\\Temp\\ipykernel_16156\\1133879325.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ai_use_cases_relevant['Techniques']=ai_use_cases_relevant['Techniques'].apply(lambda x: x.upper())\n"
     ]
    }
   ],
   "source": [
    "ai_use_cases_relevant['Techniques']=ai_use_cases_relevant['Techniques'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clustering the similar use cases followed by preprocessing the summaries of the use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Download necessary NLTK packages for tokenization and stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing\n",
    "ai_use_cases_relevant['Processed_Summary'] = ai_use_cases_relevant['Summary'].apply(preprocess_text)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(ai_use_cases_relevant['Processed_Summary'])\n",
    "\n",
    "# Similarity Calculation\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "num_clusters = 20  \n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_\n",
    "\n",
    "# Assign clusters back to the DataFrame\n",
    "ai_use_cases_relevant['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the elbow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate the distortions for different numbers of clusters\n",
    "def calculate_distortions(data, max_clusters):\n",
    "    distortions = []\n",
    "    for i in range(1, max_clusters + 1):\n",
    "        km = KMeans(n_clusters=i, random_state=0)\n",
    "        km.fit(data)\n",
    "        distortions.append(km.inertia_)\n",
    "    return distortions\n",
    "\n",
    "distortions = calculate_distortions(tfidf_matrix, num_clusters)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_clusters+1), distortions, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print contents of first few clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster - 0:\n",
      "Sample 1: Computation of the descriptors (atomic property-weighted radial \n",
      "distribution functions) that will be used for the ML portion of the task; \n",
      "Fitting of a machine-learned model for the prediction of B sorption; \n",
      "Optimization and computational design of a sorbent for maximum \n",
      "sorption of B as a function of B concentration in the aqueous solution; \n",
      "Force field generation for an additional pollutant (if needed); Sorption \n",
      "calculations and ML fitting for the second pollutant (TBD); Optimization \n",
      "and computational design of a sorbent for maximum sorption of the \n",
      "second pollutant as a function of pollutant concentration in the aqueous \n",
      "solution.\n",
      "Sample 2: Will leverage state-of-the-art, physics-based deep learning (DL) models \n",
      "to learn generalizable surrogates that may be used in place of CFD \n",
      "models to predict quantities required for downstream optimization. The \n",
      "products from this subtask can be immediately leveraged by other \n",
      "subtasks that are seeking to speed up their CFD simulation models to \n",
      "streamline their downstream analyses. Addtionally, improvements to the \n",
      "ML/AI interface in FOQUS. Includes support for vector variables in the \n",
      "ML/AI plugin and support for additional surrogate model tools (e.g., \n",
      "PyTorch, Sci-kit Learn) and additional normalization function forms in \n",
      "the ML/AI plugin.\n",
      "Sample 3: The objectives of this project are to design, process, and validate a \n",
      "laser-manufactured, integrated, and graded bond coat-environmental \n",
      "barrier coat-thermal barrier coat (BC-EBC-TBC) system that can \n",
      "effectively protect and lead to the use of Silicon Carbide fiber/Silicon \n",
      "Carbide (SiCf/SiC) matrix CMCs in next-generation hydrogen-fueled \n",
      "turbines.\n",
      "Sample 4: The measurements of chemical composition will be combined with \n",
      "resistance measurements to validate CFD models of the MHD channel \n",
      "system. Specifically, validated CFD models will be able to separate the \n",
      "contribution of the bulk and boundary layer resistance to the overall \n",
      "resistance of the MHD channel.\n",
      "Sample 5: Machine learning and quantum computing applied towards optimization, \n",
      "quantum chemistry, material science, and cryptography\n",
      "\n",
      "Cluster - 1:\n",
      "Sample 1: The anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. \n",
      "Sample 2: The model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as \"repair\" or \"not repair\" based on keywords in context.\n",
      "Sample 3: A combination of experimental data and computational results  will be \n",
      "used both to understand O2 production and to develop a machine \n",
      "learning model that can be used to identify promising carrier \n",
      "compositions. These compositions will be evaluated on two primary \n",
      "criteria, performance and ability to be synthesized. Once the model has \n",
      "identified promising candidates, these materials will be synthesized and \n",
      "compared to existing carriers. This new data will then be used to refine \n",
      "the models.\n",
      "Sample 4: This work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.\n",
      "Sample 5: This pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.\n",
      "\n",
      "Cluster - 2:\n",
      "Sample 1: This project uses unsupervised machine learning to detect and identify data anomalies in clinical trial data at the site, country and subject levels.  This project will consider multiple use cases with the goals of improving data quality and data integrity, assist site selection for inspection, and assist reviewers by identifying potentially problematic sites for sensitivity analyses. \n",
      "Sample 2: The objective of this project is to develop a set of algorithms to augment assessment of mortality through probabilistic linkage of alternative data sources with EHRs. Development of generalizable approaches to improve death ascertainment is critical to improve validity of Sentinel investigations using mortality as an endpoint, and these algorithms may also be usable in supplementing death ascertainment in claims data as well. Specifically, we propose the following Aims.\n",
      "Specific Aim 1: We propose to leverage online publicly available data to detect date of death for patients seen at two healthcare systems.\n",
      "Specific Aim 2: We propose to augment cause of death data using healthcare system narrative text and administrative codes to develop probabilistic estimates for common causes of death\n",
      "Sample 3: Analyze clinical notes to detect illicit use and miscue of stimulants and opioids\n",
      "Sample 4: The goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health.Â As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.\n",
      "Sample 5: Using and developing AI approaches to automate question answering for different users. This project leverages NLM knowledge sources and traditional and neural machine learning to address a wide-range of biomedical information needs. This project aims for improving access with one-entry access point to NLM resources.\n",
      "\n",
      "Cluster - 3:\n",
      "Sample 1: Duplicate Identification Process's (DIP's) objective is to help the user toï¿½identify and flagï¿½and mark duplicatesï¿½more efficiently, reducing the amountï¿½of time spent to reviewï¿½cases forï¿½hearings.ï¿½DIP uses artificialï¿½intelligence software in the form of image recognition technology to accuratelyï¿½identify duplicates consistent with SSAï¿½policy.?\n",
      "Sample 2: Leveraging generalized additive model to project ventilated rate of COVID inpatients\n",
      "Sample 3: Applies statistical models designed to save screeners time and effort through active learning. Utilize user feedback to automatically prioritize studies. Supports literature screening for Division of Translational Toxicology evidence evaluations.\n",
      "Sample 4: Protection of Windows and Mac endpoints from Cyberthreats\n",
      "Sample 5: Verification and validation testing with direct support and collaboration \n",
      "from operating power plants with advanced power generation \n",
      "technologies and prime mover and downstream systems using near-\n",
      "real-time data, resulting in better informed plant operators, and reduced \n",
      "disruptions, while meeting changing service demands based on \n",
      "enhanced operating flexibility\n",
      "\n",
      "Cluster - 4:\n",
      "Sample 1: The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. \n",
      "\n",
      "Sample 2: RAPIDS AI for Classification| Process Efficiency Improvement\n",
      "Sample 3: CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management\n",
      "Sample 4: The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD modelï¿½s predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. \n",
      "Sample 5: Development of a Natural Language Processing Topic Modeling tool to improve efficiency for the process of clustering public comments to a 'notice of proposed rulemaking' \n",
      "\n",
      "Cluster - 5:\n",
      "Sample 1: The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. \n",
      "Sample 2: We are using AI (Graph Neural Network) to determine importance of \n",
      "parking spaces in a city network for curb management to promote \n",
      "adoption of electric vehicles for freight delivery\n",
      "Sample 3: ML-based proxy-models of fracture network, HF geometry, HF \n",
      "properties, bottomhole pressure and drainage volume contribute to \n",
      "fracture network, production forecast and well drainage volume \n",
      "visualizations.\n",
      "Sample 4: Automated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.\n",
      "Sample 5: TreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.\n",
      "\n",
      "Cluster - 6:\n",
      "Sample 1: \"EHSS has been developing applications of natural language \n",
      "processing (NLP) and similarity measures for advanced information \n",
      "retrieval and searching of datasets (e.g., SQL databases, CSV files, \n",
      "reports) as well as estimating similarities between records within a \n",
      "dataset or records between different datasets.  Similarity search has \n",
      "been successfully applied to efficiently search DOE COVID-19 Hotline \n",
      "questions and answer database, searching DOE annual site \n",
      "environmental reports, similarity between DOE occurrence reporting and \n",
      "processing system and lessons learned, and AIX data.  Similarity \n",
      "measures can also be used to identify opportunities for resource \n",
      "prioritization and prediction.\n",
      "As of October 2021, the tool runs locally by the principal investigator on \n",
      "project based, as requested or as a desktop application.  Initial \n",
      "developments were initiated to move to a web-based application but not \n",
      "completed due to lack of user need and resources.\"\n",
      "Sample 2: Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.\n",
      "Sample 3: FSA's virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov.\n",
      "In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.\n",
      "Sample 4: ASSIST4Tobacco is a semantic search system that helps CTP stakeholders find tobacco authorization applications more accurately and efficiently.\n",
      "Sample 5: Training and adaptation of natural lanaguage processing algorithms to \n",
      "improve exploration and extraction of information from old, historical \n",
      "scientific literature.  Extraction of knowledge and data, as well as \n",
      "preservation of key information.\n",
      "\n",
      "Cluster - 7:\n",
      "Sample 1: We employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.\n",
      "Sample 2: A machine learning approach is used to build predictive models of perfusionistsâ decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.\n",
      "Sample 3: A dashboard that incorporates machine learning to help identify projects within certain high-priority research areas.\n",
      "Sample 4: To demonstrate how ML-based approaches can help operators during \n",
      "active injection and post-injection monitoring, it is necessary to \n",
      "understand their needs and identify how ML-based approaches can \n",
      "potentially meet or support those needs. Task 4 will establish data-\n",
      "sharing protocols between SMART and the operator to create an \n",
      "exchange mechanism that is not intrusive to the operator and provides \n",
      "updates from ML results designed to enhance the operator decision \n",
      "process. Demonstrate application of ML-based approaches to improve \n",
      "site-monitoring and operations efforts performed during injection and \n",
      "post-injection phases, e.g., using IL-ICCS data, and developing value of \n",
      "information guidelines.\n",
      "Sample 5: ML-enabled rapid and autonomous geophysical monitoring and real-\n",
      "time modeling and data assimilation tools (along with visualization and \n",
      "decision-support frameworks), work together to radically improve \n",
      "pressure and stress imaging.\n",
      "\n",
      "Cluster - 8:\n",
      "Sample 1: Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.\n",
      "Sample 2: This project will develop and deploy low-latency controls and prediction \n",
      "algorithms at the Fermilab accelerator complex\n",
      "Sample 3: Big data analytics for anomaly prediction and classification, enabling \n",
      "automatic mitigation, operational savings, and predictive maintenance of \n",
      "the Fermilab LINAC\n",
      "Sample 4: BNL will work alongside SLAC, to implement ML algorithm(s) into NSLS-\n",
      "II Operations to interpret accelerator data more intelligently.  We intend \n",
      "to train said algorithms with 5+ years of archived device-data from \n",
      "accelerator components, records of previous fault causes (to connect to \n",
      "data-symptoms) and stored beam current.\n",
      "Sample 5: ML will be used to develop dynamics, controls, and health models for \n",
      "operating power generation facilities\n",
      "\n",
      "Cluster - 9:\n",
      "Sample 1: Many .pdf documents could be made available for public release if they conformed to Section 508 accessibility standards. NLM has been investigating the use of AI developed to remediate Adobe .pdf files not currently accessible to Section 508 standards.ï¿½The improved files are particularly more accessible to those like the blind who use assistive technology to read.\n",
      "Sample 2: Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.\n",
      "Sample 3: Life Cycle Analysis models will be used to define and estimate \n",
      "environmental parameters/performance\n",
      "Sample 4: This process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.\n",
      "Sample 5: Generate maps of target trees from ground-level (streetview) imagery\n",
      "\n",
      "Cluster - 10:\n",
      "Sample 1: Deep learning models are used for predicting the operation of building \n",
      "energy systems, and detecting and diagnosing the health state or cyber \n",
      "attack presence, and for optimizing the building energy system \n",
      "response to provide resilient operation and sustained energy efficiency.\n",
      "Sample 2: This project will help to reduce the energy usage for producing chilled water to cool the NIH campus.\n",
      "Sample 3: Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 using AI.\n",
      "Sample 4: Responding to anomalous cyber and physical events in a timely manner \n",
      "requires fusing data from both cyber and physical sensors into \n",
      "actionable information. Thus, cyber-physical intrusion response research \n",
      "will be conducted that leverages cyber and physical side data and \n",
      "models with artificial intelligence (AI) as a scalable approach to maintain \n",
      "or regain power system resilience under anomalous incidents such as \n",
      "cyber threats.\n",
      "Sample 5: We are using AI/ML to build surrogate models of the observable \n",
      "response of complex physical systems. These surrogate models will be \n",
      "used for probabilistic model inversion of these systems with the goal of \n",
      "estimating unknown model parameters from indirect observations.\n",
      "\n",
      "Cluster - 11:\n",
      "Sample 1: Use machine learning to generate synthetic seismic and gravity data, \n",
      "and data driven inversion for leak detection\n",
      "Sample 2: Using data analytics and machine learning techniques to advance \n",
      "understanding of the characteristics of the entire Parardox oil play \n",
      "through integration of geologic and log-derived âelectrofaciesâ models \n",
      "and upscaling to 3D seismic data and propagation through the seismic \n",
      "volume.\n",
      "Sample 3: With a significant number of images. The Recipient will build deep \n",
      "learning methods at the object detection stage using the Region Based \n",
      "Convolutional Neural Network (RCNN) or You Only Look Once (YOLO) \n",
      "class of algorithms, the heart of which is a deep learning image \n",
      "classifier. Deep learning algorithms will also be built using convolutional \n",
      "layers followed by residual layers to extract feature vector descriptors in \n",
      "the second stage. In the third and fourth stages of affinity and \n",
      "association, a recurrent neural network approach can be used to build a \n",
      "tracker. All of these approaches require a large training set that will \n",
      "enable sophisticated models to be built to handle the complexity of the \n",
      "application.\n",
      "With a limited number of images. In the case that there is are a limited \n",
      "number of images, the Recipient will still be able to follow the processing \n",
      "pipeline. The recipient will determine a suitable approach, with \n",
      "concurrence from the project manager. Two potential approaches \n",
      "include:\n",
      "â¢ Transfer learning: training the image classifier in the object detector on \n",
      "images of similar quality and appearance, and \n",
      "â¢ Match filtering: detection, feature extraction, and matching based on \n",
      "traditional image processing and computer vision techniques.\n",
      "Sample 4: This research will use data and models from the Offshore Risk Modeling \n",
      "(ORM) with intelligent databases, artificial intelligence (AI)/ML, big data, \n",
      "and other advanced computing technologies to address offshore \n",
      "subsurface natural-engineered system challenges, such as \n",
      "characterization and mapping of geologic hazards, safe operations, \n",
      "equipment reliability, and environmental assessments.\n",
      "Sample 5: The Stem Cell Auto Coder uses natural language processing and machine learning to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic.\n",
      "\n",
      "Cluster - 12:\n",
      "Sample 1: The BEST Platform employs a suite of applications and techniques to improve the detection, validation and reporting of  biologics-related adverse events from electronic health records (EHRs). The Platform utilizes ML and NLP to detect potential adverse events, and extract the important features for clinicians to validate.  \n",
      "Sample 2: Developing a BERT-like ML model to improve detection of adverse events of special interest by applying a clinical-oriented language models pre-trained using the clinical documents from UCSF\n",
      "Sample 3: EMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.\n",
      "Sample 4: Produce comprehensive experimental and numerical datasets for gas-\n",
      "solid flows in well-controlled settings to understand the aerodynamic \n",
      "drag of non-spherical particles in the dense regime. The datasets and \n",
      "the gained knowledge will train deep neural networks to formulate a \n",
      "general drag model for use directly in NETL MFiX-DEM module. This will \n",
      "help to advance the accuracy and prediction fidelity of the computational \n",
      "tools that will be used in designing and optimizing fluidized beds and \n",
      "chemical looping reactors\n",
      "Sample 5: Using neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program \n",
      "\n",
      "Cluster - 13:\n",
      "Sample 1: Using electronic health records (EHR) (both structured and unstructured data) asÂ  inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.\n",
      "Sample 2: AI-based algorithms on Lumify handheld ultrasound system to detect traumatic injuries\n",
      "Sample 3: Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.\n",
      "Sample 4: Artificial intelligenceÂ  recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).\n",
      "Sample 5: AI-based algorithms on Lumify handheld ultrasound system to detect lung injury and infectious diseases\n",
      "\n",
      "Cluster - 14:\n",
      "Sample 1: Routes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.\n",
      "Sample 2: Insight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insightï¿½s features are powered by several natural language processing and artificial intelligence packages and techniques.\n",
      "Sample 3: CMS/OHI: Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center. Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information by designing chatbots using existing call center transcripts. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products.\n",
      "Sample 4: The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003).\n",
      "Sample 5: Cogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.\n",
      "\n",
      "Cluster - 15:\n",
      "Sample 1: Machine learning model development will consist of traditional machine \n",
      "learning and deep learning algorithms implementation for anomaly \n",
      "detection.  Machine learning server will be used to develop the \n",
      "traditional models using One-Class Support Vector Machine (SVM) and \n",
      "K-Mean Clustering and deep learning models using Recurrent Neural \n",
      "Network (RNN) and its various implementations like Long Short-Term \n",
      "Memory (LSTM), Gated Recurrent Unit (GRU), Generative Adversarial \n",
      "Network (GAN), and Autoencoders using the sensor data collected from \n",
      "secure sensor network.\n",
      "Sample 2: Genomic data and artificial intelligence/machine learning (AI/ML) are used to study antimicrobial resistance (AMR) in Salmonella, E. coli, Campylobacter, and Enterococcus, isolated from retail meats, humans, and food producing animals. The Boost Machine Learning Model (XGBoost) is implemented to improve upon categorical resistance vs susceptible predictions by predicting antimicrobial Minimum Inhibitory Concentrations (MICs) from WGS data.\n",
      "Sample 3: AI & ML are used to help collect and process data from multipel sources \n",
      "to further integrate and characterize infromation to provide additional \n",
      "data and infromation to support a range of carbon storage work\n",
      "Sample 4: This task aims to use geo-data science methods and geospatial \n",
      "information science to analyze the existing H2 and natural gas pipelines \n",
      "to identify the key parameters that can enable the H2 transport and \n",
      "storage at a large scale. The results can help to justify the importance of \n",
      "real-time pipeline monitoring and recommend optimized sensor \n",
      "deployment strategies to support smart maintenance and methane \n",
      "emissions reduction goals.\n",
      "Sample 5: Use of machine learning to process and analyze trends and patterns in \n",
      "known well data to predict undocuemnted orphaned wells, as well as \n",
      "machine learning approached to process different imagery based data \n",
      "to further classify and characterize additional undocuemented orphaned \n",
      "wells within the Appalachain Basin\n",
      "\n",
      "Cluster - 16:\n",
      "Sample 1: This project will develop and use simulation-based inference to estimate \n",
      "cosmological parameters related to cosmic acceleration in the early and \n",
      "late universe â via the cosmic microwave background and strong \n",
      "gravitational lensing, respectively. This will produce an analysis pipeline \n",
      "that can be deployed for next-generation cosmic surveys.\n",
      "Sample 2: The Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.\n",
      "Sample 3: Novel computer hardware architecture/configurations that can perform \n",
      "at the edge and/or in harsh environments\n",
      "Sample 4: This projects develops AI algorithms and tools for near-sensor data \n",
      "reduction in custom hardware.\n",
      "Sample 5: This project will develop AI-based tools to enable critical sectors for near-\n",
      "future cosmic applications. Uncertainty quantification is essential for \n",
      "performing discovery science now, and simulation-based inference \n",
      "offers a new approach. The automated design and control of \n",
      "instrumentation will be important for improving the efficiency of planning \n",
      "and executing cosmic experiments.\n",
      "\n",
      "Cluster - 17:\n",
      "Sample 1: The team will focus on supporting ongoing geospatial data collection \n",
      "and publishing efforts leveraging the new EDX++ cloud computer \n",
      "capabilities through ArcGIS Enterprise Portal. The use of Arc Enterprise \n",
      "Portal will support the development of the Carbon Matchmaker tool, as \n",
      "well as support the release of a new version of GeoCube, which will be \n",
      "host to the updated Carbon Storage Open Database and NATCARB \n",
      "completed in EY21. NETL is supporting DOE-FECM in developing and \n",
      "releasing a survey and map for the Carbon Matchmaker, a tool \n",
      "developed to enable stakeholders to self-identify carbon dioxide related \n",
      "activities (production, utilization, storage, direct air capture, and \n",
      "infrastructure/transportation) to identify and connect stakeholders and \n",
      "support national collaborative opportunities. The ArcGIS Enterprise \n",
      "Portal will be leveraged to build out a new version of GeoCube with the \n",
      "migration of hundreds of spatial data layers into the new platform. The \n",
      "migration of data to an Arc Enterprise based GeoCube will enable \n",
      "easier version control for data integration and curation.\n",
      "Sample 2: Generally, the approach used by NRAP researchers to address these \n",
      "questions is to develop a robust, science-based integrated assessment \n",
      "framework that links fast forecasting models of CO2 storage system \n",
      "components (e.g., storage reservoir; leakage pathways including wells, \n",
      "faults, and fractured caprock; intermediate formations; and receptors of \n",
      "concern, including groundwater aquifers and the atmosphere). \n",
      "Superimposed on this system model are various fit-for-purpose \n",
      "analytical capabilities that support analyses in support of stakeholder \n",
      "decision making for questions related to site-specific risk evolution, risk-\n",
      "based area of review delineation, conformance assessment, and post-\n",
      "injection site monitoring\n",
      "In Task 2.0, researchers will augment and expand this functionality to \n",
      "demonstrate relevance to industry-standard site risk management \n",
      "methods (i.e., bowtie analysis framework) and to understand \n",
      "containment performance and leakage risk for scenarios where a site \n",
      "transitions from CO2 utilization for EOR to dedicated CO2 storage. To \n",
      "ensure that risk assessment efforts are informative to real geologic \n",
      "storage deployment scenarios, NRAP researchers will engage with a \n",
      "diverse set of stakeholders to establish an appropriate modeling and \n",
      "risk assessment design basis.\n",
      "Sample 3: Utilze and apply different machine learning approaches to process data \n",
      "and generate new derivative data products that help address CCS \n",
      "stakeholder data-needs for resource evaluation, risk assessment, \n",
      "supply chain, social and environmental justice evaluations, regulatory \n",
      "compliance, and more.\n",
      "Sample 4: This subtask will leverage NETLâs in-house computational capabilities \n",
      "and existing university collaborators to support experimental efforts by \n",
      "providing atomic-level DFT and microkinetic modeling calculations for \n",
      "catalyst systems. This work provides atomic-level details on reaction \n",
      "energetics and establishes key structure-property relationships used to \n",
      "optimize catalyst structure and formulation.\n",
      "Sample 5: Resensys plans to develop a wireless, distributed data acquisition and \n",
      "interpretation system tailored for monitoring and characterization of \n",
      "seismic activity at carbon storage sites.  The seismicity data collected in \n",
      "real time during the CO2 storage site characterization and sequestration \n",
      "processes combined with advanced signal processing and Artificial \n",
      "Intelligence and Machine Learning (AI/ML) methodologies provide an \n",
      "understanding of natural seismicity risks prior to any CO2 injection, prior \n",
      "to making large investments in developing the storage project.\n",
      "\n",
      "Cluster - 18:\n",
      "Sample 1: Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits\n",
      "Sample 2: Use AI and ML tools for processing of extremely large threat data\n",
      "Sample 3: The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  \n",
      "Sample 4: Collection of open source threat inforamtion related to cyber issues in \n",
      "the energy sector, collected stored in graphdb and used in machine \n",
      "learning for similarities of threat enabling better reuse of cyber \n",
      "protections.\n",
      "Sample 5: The purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.\n",
      "\n",
      "Cluster - 19:\n",
      "Sample 1: Project will develop control logic for automated control of bituminous \n",
      "coal-fired boiler. Plant operational data will be compared against \n",
      "monitoring data to determine when different sensor output from a \n",
      "miniaturized high temperature multi-process, high-spatial-resolution \n",
      "monitoring system signifies damaging conditions in that region of the \n",
      "boiler, and what operational changes can be made to eliminate the \n",
      "damaging condition. The control logic will be developed for automated \n",
      "control of soot-blowing and other boiler operations\n",
      "Sample 2: 90 day Pilot is to engage in research and development to investigate applications in the generation of a machine-readable Automated Technical Profile for CMS systems with the goal of inferring the technology fingerprint of CMS projects based on multiple data sources at different stages of their development lifecycle\n",
      "Sample 3: Machine learning algorithms are being developed and compared to \n",
      "other control methods for SOFC-gas turbine hybrid  power generation \n",
      "systems.\n",
      "Sample 4: Develop quality, reliability, and version control standards for SMART \n",
      "software. Continue development of AI/ML methods for use by the 2A \n",
      "and 2C activities, including Modeling anomalies due to local \n",
      "heterogeneity coupled with an enhanced capacitance-resistance model \n",
      "(CRM) and Bayesian Belief Network (BBN) modeling integrated with \n",
      "geochemistry. Continue development of advanced computational \n",
      "approaches with modeling using the most advanced general purpose \n",
      "PDE/ODE physics-informed neural network (PINN) tool developed by \n",
      "NVIDIA and accelerate training PINNs using Wafer Scale Engine (WSE) \n",
      "by Cerebras Systems Inc.\n",
      "Sample 5: Sensor-driven deep learning/artificial intelligence for intelligent health \n",
      "monitoring capabilities that occur at the sensor (embedded computing) \n",
      "or base station (edge computing). Will give power plant operators more \n",
      "prediction tools about scheduling maintenance. Focus is on a high-\n",
      "priority in-situ boiler temperature measurement system that relies on \n",
      "chipless RFID technology and much-needed temperature, pressure, \n",
      "environmental, and water quality industrial sensors.\n"
     ]
    }
   ],
   "source": [
    "def print_cluster_contents(cluster_id, num_samples=5):\n",
    "    print(f\"\\nCluster - {cluster_id}:\")\n",
    "    samples = ai_use_cases_relevant[ai_use_cases_relevant['Cluster'] == cluster_id]['Summary'].sample(n=num_samples, random_state=1)\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"Sample {i}: {sample}\")\n",
    "\n",
    "for i in range(min(num_clusters, num_clusters)):  \n",
    "    print_cluster_contents(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatinating the summaries in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0     Model architecture development research, including workflows, \\nalgorithm and performance optimization Machine learning and quantum computing applied towards optimization, \\nquantum chemistry, material science, and cryptography Computation of the descriptors (atomic property-weighted radial \\ndistribution functions) that will be used for the ML portion of the task; \\nFitting of a machine-learned model for the prediction of B sorption; \\nOptimization and computational design of a sorbent for maximum \\nsorption of B as a function of B concentration in the aqueous solution; \\nForce field generation for an additional pollutant (if needed); Sorption \\ncalculations and ML fitting for the second pollutant (TBD); Optimization \\nand computational design of a sorbent for maximum sorption of the \\nsecond pollutant as a function of pollutant concentration in the aqueous \\nsolution. Will leverage state-of-the-art, physics-based deep learning (DL) models \\nto learn generalizable surrogates that may be used in place of CFD \\nmodels to predict quantities required for downstream optimization. The \\nproducts from this subtask can be immediately leveraged by other \\nsubtasks that are seeking to speed up their CFD simulation models to \\nstreamline their downstream analyses. Addtionally, improvements to the \\nML/AI interface in FOQUS. Includes support for vector variables in the \\nML/AI plugin and support for additional surrogate model tools (e.g., \\nPyTorch, Sci-kit Learn) and additional normalization function forms in \\nthe ML/AI plugin. The objectives of this project are to design, process, and validate a \\nlaser-manufactured, integrated, and graded bond coat-environmental \\nbarrier coat-thermal barrier coat (BC-EBC-TBC) system that can \\neffectively protect and lead to the use of Silicon Carbide fiber/Silicon \\nCarbide (SiCf/SiC) matrix CMCs in next-generation hydrogen-fueled \\nturbines. The expected outcome of this project will be extensive experimental \\ndata that can provide ...\n",
      "1     Machine learning models were developed to predict CO2 permeability \\nand CO2/N2 selectivity of polymers. Novel methods were developed to \\ngenerate polymer datasets. Furthermore, a novel machine learning \\ntechnique is being developed to inverse design the polymers that will \\nhave targeted properties. An artificial intelligence-based model will be used to develop low-loss \\nrotating detonation engine (RDE) designs for use in power generation \\nusing natural gas/syngas mixtures. The model formulation will enable full-\\nscale RDE calculations over 100-1000 detonation cycles. AI/ML will be used to recognice patterns in well integrity records that \\ncould predict failure events A combination of experimental data and computational results  will be \\nused both to understand O2 production and to develop a machine \\nlearning model that can be used to identify promising carrier \\ncompositions. These compositions will be evaluated on two primary \\ncriteria, performance and ability to be synthesized. Once the model has \\nidentified promising candidates, these materials will be synthesized and \\ncompared to existing carriers. This new data will then be used to refine \\nthe models. Use multisource machine learning to model soil moisture within the \\nlysimeter embedded within a disposal cell Wearable device and AI model to predict sepsis at home. TowerScout scans aerial imagery and uses object detection and image classification models to detect cooling towers, which can be sources of community outbreaks of Legionnaires' Disease.  The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is developing machine learning techniques to identify walking and bicycling trips in GPS-based data sources. Inputs would include commercially-available location-based data similar to those used to track community mobility during the COVID-19 pandemic. Outputs could include geocoded data tables, GIS layers, and maps. T...\n",
      "2     This project aims to address the big-data challenges and stringent time \\nconstraints facing multi-messenger astronomy (MMA) in neutrino \\nexperiments and cosomological surveys. Instead of following the \\ntraditional computing paradigm of moving data to the compute \\nelements, it does the opposite to embed computation in the data where \\nprocessing is performed in situ. This will be achieved through emerging \\ncomputational storage accelerators on which ML algorithms may be \\ndeployed to execute MMA tasks quickly so alerts can be disseminated \\npromptly. The project plans to develop a more accurate artificial neural network \\n(ANN)-based method for modeling the momentum exchange in fluid-\\nsolid multiphase mixtures to significantly improve the accuracy and \\nreduce the uncertainty of multiphase numerical codes and, in particular, \\nof MFiX, by developing and providing a general and accurate method for \\ndetermining the drag coefficients of assemblies of non-spherical \\nparticles for wide ranges of Reynolds numbers, Stokes numbers, and \\nfluid-solid properties and characteristics. The research team will achieve \\nthis goal by conducting numerical computations with a validated in-\\nhouse CFD code and using artificial intelligence methods to develop an \\nANN that will be implemented in TensorFlow and linked with the MFiX \\ncode. The objective of the work is to utilize algal- and cyanobacterial-based \\nphycotechnologies to address pervasive heavy metal contamination \\nfrom coal combustion product (CCP) impoundments at the Savannah \\nRiver Site. Novel bioindicators will be developed to gauge the potential \\nfor phytoremediation to restore legacy impoundment sites. Analyze clinical notes to detect illicit use and miscue of stimulants and opioids A team of scientists participating in CDC's Data Science Upskilling Program are developing an NLP Named Entity Recognition model to detect the assertion or negation of opioid use in electronic medical records from the National...\n",
      "3     U-Net CNN segmentation to isolate pore and fluid from computed \\ntomography scans of multiphase transport in cores. Databases of MOFs will be screened using computational methods to \\nidentify promising MOFs. Software will be further developed to allow for \\nthe addition of desirable functional groups (amines) to metal centers \\nand/or ligands of MOFs. The team will calculate the reaction enthalpy for \\nCO2 sorption in amine functionalized MOFs and further computational \\nmethods for the characterization of CO2 chemisorption in amine-\\nfunctionalized MOFs will be developed. The team will develop a public DNA database that will advance \\nknowledge in produced water management. This project consists of two \\nphases: (1) the development and launching of the database, and (2) the \\ndemonstration of applicability of the database by conducting a network \\nanalysis. The work will be pursued as defined in the phases below. The \\nfully characterized streams will be used by other FWPs to estimate \\noverall resource recovery and will be used by other FWPs as training \\nset for machine learning (ML) models to predict compositions when only \\nlimited measurements can or have been completed for the produced \\nwater. Work will focus on using SI to monitor the condition of a power plant \\nboiler at different process states. SI algorithms will be implemented \\nwithin an MPC to provide continuous adaptability as the power plant \\nramps through the entire range of operating loads. Once the control \\nalgorithm has been developed to be effective on representative models, \\nit will be tested on a high-fidelity commercial power plant simulator or on \\na real power plant facility. The online SI techniques will be tested on \\nhistorical power plant data, dynamic models (including a power plant \\nsimulator), power generating equipment including laboratory pilot-scale \\npower systems, and on power plants where feasible. Detailed CFD of large combustion systems will be performed.   From \\n...\n",
      "4     Development of a Natural Language Processing Topic Modeling tool to improve efficiency for the process of clustering public comments to a 'notice of proposed rulemaking'  CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management RAPIDS AI for Classification| Process Efficiency Improvement An initiative to create a natural language processing chatbot to improve efficiency, transparency, and consistency for NIDCR employees.  The ability to predict scientific breakthroughs at scale would accelerate the pace of discovery and improve the efficiency of research investments. The initiative has helped identify a common signature within co-citation networks that accurately predicts the occurrence of breakthroughs in biomedicine, on average more than 5 years in advance of the subsequent publication(s) that announced the discovery.ï¿½There is a patent application filed for this approach: U.S. Patent Application No. 63/257,818 (filed October 20, 2021) This model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review. The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD modelï¿½s predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing.  The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails t...\n",
      "5     This project has two parts: 1. generating adversarial examples and then \\nusing domain adaptation and other techniques to improve the \\nrobustness of AI classification algorithms against those attacks \\n(focusing on astrophysics/cosmology applications); 2. using AI \\nalgorithms to improve the output of low-quality classical simulation \\nengines to deliver a high-quality result at high speed. Our method quickly incorporates streaming observations for accurate \\nand timely forecasts with uncertainty quantification, taking reservoir \\nsimulation data as inputs and incorporating real-time observation \\nstreams for accurate, timely geological carbon storage forecasts.\\nComputation effort is distributed over many machines, facilitates \\ncoupled inversions using many ML models, and allows for ML-Driven \\noptimization and sensitivity analysis Provide sub-pilot-scale verification of lab-scale developments on the \\nproduction of isotropic and mesophase coal-tar pitch (CTP) for carbon \\nfiber production, using coals from several U.S. coal-producing regions. \\nAn extensive database and suite of tools for data analysis and economic \\nmodeling, with an associated web-based community portal, will be \\ndeveloped to relate process conditions to product quality, and to assess \\nthe economic viability of coals from different regions for producing \\nspecific high-value products. ML-based proxy-models of fracture network, HF geometry, HF \\nproperties, bottomhole pressure and drainage volume contribute to \\nfracture network, production forecast and well drainage volume \\nvisualizations. An Artificial Neural Network and Gradient Boosted Regression Tree \\nwere developed and applied to predict the remaining lifespan of \\nproduction platforms. These big data-driven models resulted in \\npredictions with scored accuracies of 95â97%. Continue development of the SimCCS toolset, which is utilized to \\ndetermine optimal placement for CO2 pipeline rights of way (ROW) and \\ninfrastructure in a...\n",
      "6     Leveraging generative AI and cloud enabled data infrastructure to \\nimprove CCS user experience and connectivity producing an adaptive \\nuser interface that streamlines connection of CCS stakeholders to what \\nmatters to them. Use machine learning to identify common attributes that correlated to \\nwell integrity issues to prioritize for monitoring and remediation. Training and adaptation of natural lanaguage processing algorithms to \\nimprove exploration and extraction of information from old, historical \\nscientific literature.  Extraction of knowledge and data, as well as \\npreservation of key information. \"EHSS has been developing applications of natural language \\nprocessing (NLP) and similarity measures for advanced information \\nretrieval and searching of datasets (e.g., SQL databases, CSV files, \\nreports) as well as estimating similarities between records within a \\ndataset or records between different datasets.  Similarity search has \\nbeen successfully applied to efficiently search DOE COVID-19 Hotline \\nquestions and answer database, searching DOE annual site \\nenvironmental reports, similarity between DOE occurrence reporting and \\nprocessing system and lessons learned, and AIX data.  Similarity \\nmeasures can also be used to identify opportunities for resource \\nprioritization and prediction.\\nAs of October 2021, the tool runs locally by the principal investigator on \\nproject based, as requested or as a desktop application.  Initial \\ndevelopments were initiated to move to a web-based application but not \\ncompleted due to lack of user need and resources.\" The OCIO EITS Service Desk is exploring the ability to use AI chat bots \\nto interact with end-users. We are looking to have a single bot \\narchitecture that is highly tuned to IT system languages to properly \\nhandle the terms that may be used in an enterprise environment. The \\nprimary benefit would be to make knowledge more available to the end-\\nusers in a consumable manner. Additionally, it ...\n",
      "7     \"Coherent X-rays are routinely provided today by the latest Synchrotron \\nand X-ray Free-electron Laser Sources. When these diffract from a \\ncrystal containing defects, interference leads to the formation of a \\nmodulated diffraction pattern called \"\"speckle\"\". When the defects move \\naround, they can be quantified by a correlation analysis technique called \\nX-ray Photon Correlation Spectroscopy. But the speckles also change \\nwhen the beam moves on the sample. By scanning the beam in a \\ncontrolled way, the overlap between the adjacent regions gives \\nredundancy to the data, which allows a solution of the inherent phase \\nproblem. This is the basis of the coherent X-ray ptychography method \\nwhich can achieve image resolutions of 10nm, but only if the probe \\npositions are known.\\nThe goal of this proposal will be to separate \"\"genuine\"\" fluctuations of a \\nmaterial sample from the inherent beam fluctuations at the high data \\nrates of XFELs. Algorithms will be developed to calculate the \\ncorrelations between all the coherent diffraction patterns arriving in a \\ntime series, then used to separate the two sources of fluctuation using \\nthe criterion that the \"\"natural\"\" thermal fluctuations do not repeat, while \\nbeam ones do.  We separate the data stream into image and beam \\n\"\"modes\"\" automatically.\" NEWTS data requirements and database structure needs will be \\nestablished by reviewing datasets and literature on energy-water \\nstreams. Data sources will be identified from regulatory agencies, \\ngovernment monitoring programs, as well as open-source literature. \\nMetadata of each source will be compiled into a data catalog for \\ntracking and reference. Datasets, including high-quality composition \\ndata for relevant streams, will be collected and downloaded. Acquired \\ndata will be processed into a structured format based on the \\nprioritization of datasets to be included in NEWTS. Data acquisition and \\nprocessing might entail the application of ML (e.g., ...\n",
      "8                                                                                                                                                                                                                                                           BNL will work alongside SLAC, to implement ML algorithm(s) into NSLS-\\nII Operations to interpret accelerator data more intelligently.  We intend \\nto train said algorithms with 5+ years of archived device-data from \\naccelerator components, records of previous fault causes (to connect to \\ndata-symptoms) and stored beam current. Big data analytics for anomaly prediction and classification, enabling \\nautomatic mitigation, operational savings, and predictive maintenance of \\nthe Fermilab LINAC This project will develop and deploy low-latency controls and prediction \\nalgorithms at the Fermilab accelerator complex To develop high fidelity tools which run in near real time not only help in \\nthe field to guide and optimize complex operations but can be used as \\ndigital twins for cyber security and cyber-physical modeling. ML will be used to develop dynamics, controls, and health models for \\noperating power generation facilities Develop a prototype software application to support the humanï¿½review of FAERS data by developing computational algorithms to semi-automatically categorizing FAERS reports into meaningful medication error categories based on report free text. Leveraged existing annotated reports and worked with subject matter experts to annotate subsets of FAERS reports, to generate initial NLP algorithms that can classify any report as being medication related and with an identified type of medication error. An innovative active learning approach was then used to annotate reports and build more robust algorithms for more accurate categorization.  Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.\n",
      "9     Build off user testing and further refine analytical logic to develop \\nVersion 2 of the OGA smart tool for release on EDX. Continue \\nrefinements to offshore hazard models, including wave and turbidity \\ncurrent models. Draft manuscripts detailing the OGA Tool models and \\nalgorithms. Assemble a metocean and seafloor database for release \\nwith the OGA Tool Version 2 online; strategize web-hosted versions of \\nthe OGA Tool and database. A deep-learning Artificial Intelligence model will be pursued for rapid \\nanalysis of detailed fundamental combustion characteristics that support \\nthe design and troubleshooting process of H2-containing fuel combustor \\ndevelopment. Life Cycle Analysis models will be used to define and estimate \\nenvironmental parameters/performance \"The EHSS Data Analytics Machine Learning (DAMaL) tools, similarity-\\nbased information retrieval tool, uses natural language processing \\n(NLP) and cosine similarity to leverage artificial intelligence (AI) to \\nincrease the efficiency of a user to find important records in the DOE \\nenvironment, safety, and health (ES&H) datasets (e.g., occurrence \\nreporting and processing system, fire protection, lessons learned, \\naccident and injury reporting system, contractor assurance system \\nCAS).  The tool has no restriction on the text query, provides NLP \\noptions to the user (e.g., stemming or lemmatization) and could be used \\nto improve decision-making in job planning activities, identifying hazards, \\nand obtaining insights from operating experience and lessons learned \\ndata discovery and analysis, accident investigations among other areas.\\nAs of October 2021, Tool developed and deployed in the DAMaL tools \\nwebsite.  Expected to continue to maintain, develop documentation \\n(e.g., users analysis guides), improve and enhance, and increase data \\nsources. \"The EHSS Data Analytics Machine Learning (DAMaL) tools, \\nclassification, robotic process automation and data visualization tool, \\nuses natur...\n",
      "10    Leveraging data science to navigate design space for better batteries \\nand energy storage as well as scale up of various technologies Information and articles on energy storage will be gathered and \\nreviewed. Developed natural language processing (NLP) algorithms will \\nbe used to help categorize and understand various energy storage \\nefforts in the R&D communities. Additionally, trends within the \\ndiscovered and selected topical focus areas in energy storage will be \\nexamined. This will provide a view of energy storage R&D, which is not \\nbiased or limited to known search terms. Responding to anomalous cyber and physical events in a timely manner \\nrequires fusing data from both cyber and physical sensors into \\nactionable information. Thus, cyber-physical intrusion response research \\nwill be conducted that leverages cyber and physical side data and \\nmodels with artificial intelligence (AI) as a scalable approach to maintain \\nor regain power system resilience under anomalous incidents such as \\ncyber threats. Deep learning models are used for predicting the operation of building \\nenergy systems, and detecting and diagnosing the health state or cyber \\nattack presence, and for optimizing the building energy system \\nresponse to provide resilient operation and sustained energy efficiency. An AI based differentiable programming framework for domain aware \\ndata efficient predictive modeling and AI based control policy synthesis \\nas well as methods for safety verification and online learning. Domain \\naware deep learning models are used for learning and predicting the \\nresponse of building systems and components and for optimizing the \\nbuilding energy system response to provide resilient operation and \\nsustained energy efficiency. Domain aware deep learning models are used for predictive modeling of \\ntraffic. Deep learning based predictive controllers are trained from \\nsimulated data to optimize the traffic signaling and coordination for \\nimproved t...\n",
      "11    This project explores novel  AI-on-chip technology for intelligent \\ndetectors embedded with sensing technology Enabling machine learning based technology to specialized materials for \\nsuperior performance for scientific research and manufacturing systems This research will use data and models from the Offshore Risk Modeling \\n(ORM) with intelligent databases, artificial intelligence (AI)/ML, big data, \\nand other advanced computing technologies to address offshore \\nsubsurface natural-engineered system challenges, such as \\ncharacterization and mapping of geologic hazards, safe operations, \\nequipment reliability, and environmental assessments. Use machine learning to generate synthetic seismic and gravity data, \\nand data driven inversion for leak detection To establish a tight oil Field Laboratory in the Powder River Basin and \\naccelerate the development of three major unconventional oil resources \\nthrough detailed geologic characterization and improved geologic \\nmodels leading to significant advances in well completion and fracture \\nstimulation designs specific to these three formations. Utilize multi-\\nvariate analysis to understand the interrelationship between completion \\nand stimulation controls on well productivity. The relevant research has been focused on demonstrating applicability \\nof novel machine learning based approaches to two major challenges \\nassociated with safe management of large-scale geologic CO2 storage \\noperations, early detection of leaks (i.e., by detecting small leaks) and \\nearly detection of induced seismicity (i.e. by detecting small seismic \\nsignals). With a significant number of images. The Recipient will build deep \\nlearning methods at the object detection stage using the Region Based \\nConvolutional Neural Network (RCNN) or You Only Look Once (YOLO) \\nclass of algorithms, the heart of which is a deep learning image \\nclassifier. Deep learning algorithms will also be built using convolutional \\nlayers followed by res...\n",
      "12    Combining experimental and computational methods to perform \\nfundamental and applied research in genomics, molecular toxicology, \\nnanotechnology, hostâpathogen biology, structural biology, genetics, \\nmicrobial systems, and medical countermeasures Collaborate with Subtask 4.3 Machine Learning Support to reduce the \\ncomputational complexity of validated CFD calculations using Deeper \\nFluids (DF), graph neural networks (GNNs), or similar ML approaches. \\nFurther development of ongoing process modeling/optimization \\nultimately informed by the CFD reduced order models (ROM) will also \\nbe a focus. Use of neural networks and/or AI cluster data analysis methods to \\nimprove detection and forecasting of wellbore and drilling related loss of \\ncontrol events, known as kicks, to imrpove real-time detection and \\nprediction of these conditions. Produce comprehensive experimental and numerical datasets for gas-\\nsolid flows in well-controlled settings to understand the aerodynamic \\ndrag of non-spherical particles in the dense regime. The datasets and \\nthe gained knowledge will train deep neural networks to formulate a \\ngeneral drag model for use directly in NETL MFiX-DEM module. This will \\nhelp to advance the accuracy and prediction fidelity of the computational \\ntools that will be used in designing and optimizing fluidized beds and \\nchemical looping reactors Using natural language processing, deep learning neural networks, and \\npossibly tensor flow for image analytics. Multiple big data-driven AI/ML models will be used to evaluate geologic, \\ngeospatial, and infrastructure related information to inform predictions \\nusing natural language processing, Artificial Neural Networks, and \\npossibly bayesian networks as well. Use of AI methods such as fuzzy logic, neural networks, tensor flow, \\nand natural language processing to assist with knowledge and data \\nexploration, transformation and integration, as well as modeling and \\nanalysis of multi-variate data us...\n",
      "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                AI Based algorithms on Accuro XV to detect and highlight fractures and soft tissue injuries AI-based algorithms on Lumify handheld ultrasound system to detect lung injury and infectious diseases AI-based algorithms on Lumify handheld ultrasound system to detect traumatic injuries Given a limited number of highly infectious patient transport containers, optimize US location based on various factors like distance, population, etc. Use as a planning tool for decision-making. HaMLET uses computer vision models to detect TB from chest x-rays to improve the quality of overseas health screenings for immigrants and refugees seeking entry to the U.S. This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness. Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters. Artificial intelligenceÂ  recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc). Using electronic health records (EHR) (both structured and unstructured data) asÂ  inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.\n",
      "14    ML Is utilized to parse and generate additional data and information that \\ncan be parsed and labeled to provide additional inputs for geologic \\ncarbon storgae assessments from multiple sources. An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' suicide death trends nationally on a week-to-week basis.  Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search,ï¿½QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps. CMS/OHI: Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center. Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information by designing chatbots using existing call center transcripts. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products. Developed the Information Visualization Platform (InfoViP) for post market safety surveillance, to improve the efficiency and scientific rigor of Individual Case Study Reports (ICSRs) review and evaluation process. InfoViP incorporates artificial intelligence and advanced visualizations to detect duplicate ICSRs, create temporal data visualization, and classify ICSRs for useability.  To provide assistance in assigning appropriate scientific areas for grant applications. This tool uses natural language processing and machine learning to calculate an Implementation Science...\n",
      "15    AI is being used for accelerating hardware development and \\ninterpretation of sensor data to improve process reliability AI is being used to classify sensor data.  An AI algorithm was written \\nand trained with a wide range of known sensor conditions to enable \\nautomatic classification of sensor data into likely constituent gas \\nconcentrations. Use of machine learning to process and analyze trends and patterns in \\nknown well data to predict undocuemnted orphaned wells, as well as \\nmachine learning approached to process different imagery based data \\nto further classify and characterize additional undocuemented orphaned \\nwells within the Appalachain Basin Machine learning model development will consist of traditional machine \\nlearning and deep learning algorithms implementation for anomaly \\ndetection.  Machine learning server will be used to develop the \\ntraditional models using One-Class Support Vector Machine (SVM) and \\nK-Mean Clustering and deep learning models using Recurrent Neural \\nNetwork (RNN) and its various implementations like Long Short-Term \\nMemory (LSTM), Gated Recurrent Unit (GRU), Generative Adversarial \\nNetwork (GAN), and Autoencoders using the sensor data collected from \\nsecure sensor network. Study of plume formation and collection on mechanical (induced) draft \\ncooling towers, partly in a high-fidelity controlled environment and partly \\non a full-scale industrial cooling tower. It will start by building the needed \\nlaboratory setup and installing various sensors on the lab cooling tower. \\nAt the same time a computational fluid dynamics (CFD) model will be \\nimplemented to get precise full-scale plume models. Using the insights \\ninto power-plant plume characteristics the project will iterate on and \\nexperimentally test electrodes and collectors, which make up modular \\npanels, on the lab cooling tower. What has been learned from the full-\\nscale plume modeling and sensor data analysis will then be applied to \\ndevelop a desi...\n",
      "16    AI/ML is being used to evaluate measurements in real-time during \\nsimultaneous experiments on two beamlines and then drive subsequent \\ndata collection on both of the beamlines to maximize the scientific value \\ngenerated per time. This program aims to develop generative models for quickly simulating \\nshowers of particles in calorimeters for LHC experiments This projects develops AI algorithms and tools for near-sensor data \\nreduction in custom hardware. This project will develop and use simulation-based inference to estimate \\ncosmological parameters related to cosmic acceleration in the early and \\nlate universe â via the cosmic microwave background and strong \\ngravitational lensing, respectively. This will produce an analysis pipeline \\nthat can be deployed for next-generation cosmic surveys. This project focuses on integration of AI hardware for at-scale inference \\nacceleration for particle physics experiments. This project develops real-time algorithms for event filtering with tracking \\ndetectors for nuclear physics collider experiments. This project will develop AI-based tools to enable critical sectors for near-\\nfuture cosmic applications. Uncertainty quantification is essential for \\nperforming discovery science now, and simulation-based inference \\noffers a new approach. The automated design and control of \\ninstrumentation will be important for improving the efficiency of planning \\nand executing cosmic experiments. Novel computer hardware architecture/configurations that can perform \\nat the edge and/or in harsh environments ANN development of flow physics for code acceleration A machine learning (ML) model will be developed to aid in investigating \\nand optimizing of gasification with various feedstocks like waste plastic, \\nwaste coal, biomass and MSW. Database on the gasification will be \\nbuilt from main resources of literature, prior experiments in NETL, and \\nnew generating experiments in NETL. Al/ML will be a part of the project. \\nIt ...\n",
      "17    Leveraging a broad, multimodal data stream to predict and understand \\nnatural disaster scenarios for the purposes of prevention and mitigation Providing expertise, input, and support for the development of a DOE \\n(NETL/FECM) carbon storage technical resources catalog that \\nfacilitates searching for information about datasets, models and tools, \\npublications and reports, and competencies resulting from DOE-\\nFECM/NETLâs offshore and CSP activities.  this project will complete a \\nreview and analysis of knowledge and data resources resulting from \\ninternational offshore CCS projects. Outcomes of this analysis are \\nexpected to include the integration of key data and tools into the EDX-\\nhosted Open Carbon Storage Database and DisCO2ver platform (in \\ndevelopment via the EDX4CCS FWP), as well as geo-data science \\nbased analysis and recommendations on geologic and metocean \\ninsights from international studies and their alignment or relevance to \\nU.S. Federal offshore settings. This subtask will leverage NETLâs in-house computational capabilities \\nand existing university collaborators to support experimental efforts by \\nproviding atomic-level DFT and microkinetic modeling calculations for \\ncatalyst systems. This work provides atomic-level details on reaction \\nenergetics and establishes key structure-property relationships used to \\noptimize catalyst structure and formulation. The team will focus on supporting ongoing geospatial data collection \\nand publishing efforts leveraging the new EDX++ cloud computer \\ncapabilities through ArcGIS Enterprise Portal. The use of Arc Enterprise \\nPortal will support the development of the Carbon Matchmaker tool, as \\nwell as support the release of a new version of GeoCube, which will be \\nhost to the updated Carbon Storage Open Database and NATCARB \\ncompleted in EY21. NETL is supporting DOE-FECM in developing and \\nreleasing a survey and map for the Carbon Matchmaker, a tool \\ndeveloped to enable stakeholders to s...\n",
      "18    This project develops hardware-software AI codesign tools for FPGAs \\nand ASICs for algorithms running at the extreme edge. In Linacs at FNAL and J-PARC, the current emittance optimization \\nprocedure is limited to manual adjustments of a few parameters; using \\na larger number is not practically feasible for a human operator. Using \\nmachine learning (ML) techniques allows lifting this restriction and \\nexpanding this set. Our goal is to integrate ML into linac operation - and \\nin particular RF control to achieve a more optimal longitudinal emittance \\nand lower overall losses. The INL uses machine learning (feed forward neural network) on a large \\ndata set of translated malware binaries in graph structures to identify \\ncommonality between malware. Collection of open source threat inforamtion related to cyber issues in \\nthe energy sector, collected stored in graphdb and used in machine \\nlearning for similarities of threat enabling better reuse of cyber \\nprotections. Data-processing pipelines and user interfaces to process and \\naggregate large, bulk, and possibly unstructured datasets allowing for \\nsearch and export of data for further analysis in secure way Computational approaches that lead to faster insights into the \\ndevelopment and deployment of large scale operations This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication. Electromagnetic technology development and optimization for cased \\nwells. Scalable solu...\n",
      "19    This program leverages the physics and technology of optical stochastic \\ncooling (OSC) to explore new possibilities in beam control and sensing.  \\nThe planned architecture and performance of a new OSC system at \\nIOTA should enable turn-by-turn programmability of the high-gain OSC.  \\nThis capability can then be used in conjunction with other hardware \\nsystems as the basis of an action space for reinforcement learning (RL) \\nmethods.  The program aims to establish a new state of the art in beam \\ncooling and a flexible set of tools for beam control and sensing at \\ncolliders and other accelerator facilities. Efforts on IES control will include the development of a dynamic \\noptimization-based nonlinear model predictive control (NMPC) \\nframework. NMPC approaches for optimizing cell thermal management \\nand maximizing IES efficiency under set-point transition will be \\ndeveloped for flexible operation. Reinforcement learning (RL) \\napproaches will also be developed for optimal control policy selection \\nand learning-based adaptive control. There are opportunities for \\nimproved learning through interaction with the electrolyzer in addition to \\nlearning from the MPC action. Multi-policy approaches will be developed \\nfor control, independently by RL or in concert with MPC, or even for \\nscheduling the operating policy.  The ultimate goal is to develop \\noperational strategies and an NMPC and RL control framework for \\noptimizing IES performance under flexible hydrogen and power \\nproduction scenarios, while minimizing physical and chemical \\ndegradation over long-term operation. Develop quality, reliability, and version control standards for SMART \\nsoftware. Continue development of AI/ML methods for use by the 2A \\nand 2C activities, including Modeling anomalies due to local \\nheterogeneity coupled with an enhanced capacitance-resistance model \\n(CRM) and Bayesian Belief Network (BBN) modeling integrated with \\ngeochemistry. Continue development of advanced c...\n",
      "Name: Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "clustered_texts = ai_use_cases_relevant.groupby('Cluster')['Summary'].apply(' '.join)\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "print(clustered_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary generation using the HugginFace's BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sankar.kalaga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0                                                                                                                                                                                              Machine learning and quantum computing applied towards optimization, material science, and cryptography. Will leverage state-of-the-art, physics-based deep learning (DL) models. Will learn generalizable surrogates that may be used in place of CFD models to predict quantities required for downstream optimization.\n",
      "1                                                                                                                                                                   Machine learning models were developed to predict CO2 permeability and CO2/N2 selectivity of polymers. AI/ML will be used to recognice patterns in well integrity records that could predict failure events. Use multisource machine learning to model soil moisture within a disposal cell. Wearable device and AI model to predict sepsis at home.\n",
      "2                                                                                                                                     The project plans to develop a more accurate artificial neural network (ANN)-based method for modeling the momentum exchange in fluid-solid multiphase mixtures. A team of scientists participating in CDC's Data Science Upskilling Program are developing an NLP Named Entity Recognition model to detect the assertion or negation of opioid use in electronic medical records.\n",
      "3                                                                                                                              The team will develop a public DNA database that will advance knowledge in produced water management. The online SI techniques will be tested on historical power plant data, dynamic models and power generating equipment. The project objectives are to integrate satellite remote sensing, machine learning and image processing, geological engineering models, and plant pathology.\n",
      "4                                                                                                                   The ability to predict scientific breakthroughs at scale would accelerate the pace of discovery and improve the efficiency of research investments. The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available.\n",
      "5                                                                                                                                            An extensive database and suite of tools for data analysis and economic modeling will be developed. The project aims to develop a cost-effective quality assurance (QA) method for laser powder bed fusion (LPBF) processed hot gas path turbine components. The QA method would assimilate in-situ monitoring, measurement, ex-Situ characterization, and simulation data.\n",
      "6                                                                                                                                                                                     InFACT is being developed for use in the Social Security Administration (SSA) disability determination process. OSCAR is a chatbot with predefined intents for customers to get help from Customer Service Center. ASSIST4Tobacco is a semantic search system that helps CTP stakeholders find tobacco authorization applications.\n",
      "7                                                                                                                                                                                                                                          Coherent X-rays are routinely provided today by the latest Synchrotron and X-ray Free-electron Laser Sources. The goal of this proposal will be to separate \"\"genuine\" fluctuations of a material sample from the inherent beam fluctuations at the high data rates of XFELs.\n",
      "8                                                                                                                                                        ML will be used to develop dynamics, controls, and health models for power generation facilities. Macine learning algorithms are used to. develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the. port of entry. ML can be used as digital twins for cyber security and cyber-physical modeling.\n",
      "9                                                                                                                                            The EHSS Data Analytics Machine Learning (DAMaL) tools, uses natural language processing (NLP) and cosine similarity to leverage artificial intelligence (AI) The tool has no restriction on the text query and could be used to improve decision-making in job planning activities, identifying hazards, obtaining insights from operating experience and lessons learned.\n",
      "10                                                                                                                                                         Leveraging data science to navigate design space for better batteries and energy storage as well as scale up of various technologies. Information and articles on energy storage will be gathered and reviewed. Developed natural language processing (NLP) algorithms will be used to help categorize and understand various energy storage R&D communities.\n",
      "11                                                                                             This project explores novel AI-on-chip technology for intelligent                 detectors embedded with sensing technology. The human placenta plays a pivotal role in fetal growth, development, and fetal exposure to chemicals and therapeutics. The ability to predict placental permeability of chemicals is an important factor that can inform regulatory decisions related to fetal safety and clinical trials.\n",
      "12                                                                                                                                                                                                The BEST Platform employs a suite of applications and techniques to improve the detection, validation and reporting of  biologics-related adverse events from electronic health records (HRs) The Platform is an AI solution designed to identify potential hazards associated with substances of interest to CFSANAN.\n",
      "13                                                                    HaMLET uses computer vision models to detect TB from chest x-rays to improve the quality of overseas health screenings for immigrants and refugees seeking entry to the U.S. This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.\n",
      "14                                Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products. Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center.\n",
      "15                                                                                                                                                                                             AI is being used to classify sensor data to improve process reliability. Machine learning is used to process and analyze trends and patterns in well data to predict undocuemnted orphaned wells. This task aims to use geospatial science to analyze natural gas pipelines and analyze existing H2 and H3 gas pipelines.\n",
      "16                                                                                                                                                    AI/ML is being used to evaluate measurements in real-time during LHC experiments. This project will develop and use simulation-based inference to estimate cosmic acceleration in the early and late universe. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly.\n",
      "17                                                                     The project will complete a review and analysis of knowledge and data resources resulting from international offshore CCS projects. Outcomes of this analysis are expected to include the integration of key data and tools into the EDX-hosted Open Carbon Storage Database and DisCO2ver platform. Researchers will apply artificial intelligence/machine learning (AI/ML) to national-scale well characterization and integrity test datasets.\n",
      "18    This project develops hardware-software AI codesign tools for FPGAs and ASICs for algorithms running at the extreme edge. The INL uses machine learning (feed forward neural network) on a large set of translated malware binaries in graph structures to identify similarities between malware. The NETL will develop ML algorithms to compensate magnetic data for the maneuvering of drone aircraft. The objective of this project is to use computational tools to optimize the design of solid CO2 sorbents.\n",
      "19                                                                                              The program aims to establish a new state of the art in beam control and sensing. Efforts on IES control will include the development of a dynamic optimization-based nonlinear model predictive control (NMPC) framework. The control logic will be developed for automated control of soot-blowing and other boiler operations. Sensor-driven deep learning/artificial intelligence for intelligent health monitoring.\n",
      "Name: Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "def abstractive_summary(text, model, tokenizer, max_length=1024, num_beams=4):\n",
    "    inputs = tokenizer(\"summarize: \" +text, max_length=max_length, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=num_beams, max_length=200, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Load pre-trained BART model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Apply abstractive summarization on each cluster\n",
    "abstractive_summaries_bart = clustered_texts.apply(lambda x: abstractive_summary(x, model, tokenizer))\n",
    "print(abstractive_summaries_bart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary generation by the phi3 model using ollama api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0                                                        Summary: The project aims to optimize the design, processing, and validation of an integrated BC-EBC-TBC system using laser manufacturing techniques while considering its application in hydrogen turbines with SiCf/SiC matrix CMCs as next-gener03 \\nn generation propulsion systems. Extensive experimental data is expected to provide valuable insights into RDC design, model validation and development of advanced combustion sensors using AI and computer vision technologies. Simultaneously efforts are being made to develop ML models that can act as surrogates for complex unit operations or multi-scale bridging in IDAES optimization framework with real scale problem focused on carbon capture process, MIP solver tuning through machine learning methods have been proposed while simultaneously validating CFD models of the MHD channel system using dual gaps obtained from different branching strategies. Implementations will be carried out for both reinforcement and Genetic algorithm approaches to model selection in population pharmacokinetics with a focus on cases likely leading to errors during disability eligibility determination processes, which are then referred for quality review checks using established models developed through machine learning techniques. The project also includes the development of deep learning/reinforcement algorithms as well as improved ML interfaces in FOQUS software toolkit to handle vector variables and support additional surrogate model tools like PyTorch with more normalization function forms included. All these subtasks are intended for improving various aspects such CFD simulations, chemical compositions measurements of MHD channel system resistance contributions while enhancing population pharmacokinetic models using ML techniques to identify cases prone for eligibility determination errors and facilitating optimization efforts in integrated energy systems through machine learning surrogates.\n",
      "1      This DSH-related anomaly prediction model uses machine learning techniques to identify and predict various high-risk claims that could potentially lead to disputes between the Department of Veterans Affairs (VA) Health Benefits Programs and Service Members' Families, particularly focusing on underpayment or overpayment issues. The models are designed as follows:\\n\\n1. **Resource Misuse Prediction Model** - It aims to detect potential misuse in resource allocation within the VA system by estimating probabilities of uncompensated care costs for representative payees based on patterns identified from historical data and claims analysis. This helps flag high-risk cases that might otherwise result in disputes due to financial discrepancies or underpayments, allowing targeted review processes before adjudication occurs.\\n\\n2. **Supplemental Security Income Overpayment Prediction Model** - It focuses on Veterans receiving Supplemental Security Income (SSI) and uses machine learning algorithms to pinpoint those with the highest likelihood of overpayments due to changes in their financial status, which may occur frequently among this population. Identifying these cases for review can prevent disputes arising from incorrect payments that are often a result of bureaucratic errors or outdated information on Veterans' eligibility and income levels.\\n\\n3. **Medicare Part D Overpayment Prediction Model** - This model predicts overpayments in Medicare prescription drug programs (Part D) by identifying cases that could be subject to incorrect subsidies, which are common due to complex medication regimes often found among Veterans with chronic conditions. Flagged instances will undergo review for potential adjustments and refunding of excess payments.\\n\\n4. **Hearing Level Allowance Prediction Model** - It uses predictive analytics to identify cases that might qualify at the hearing level, which is a priority category in appeals processes due to its significant impact on Veteran...\n",
      "2      Title: Developing an EHR Clinical Data Model for Stroke Risk Prediction Using Machine Learning\\n\\nProject Overview \\nThe goal of this project is twofold, focusing on the conversion of electronic health record (EHR) data into a structured format that can be used to improve stroke risk prediction. This will involve creating an EHR clinical Data Model using machine learning techniques and natural language processing algorithms for unstructured text notes in order to identify potential triggers or indicators linked with higher risks of strokes among Medicare patients who have been discharged from the Emergency Department (ED).\\n\\nAim 1: Conversion Of Structured EHR & Claims Data To SCDM Format. The first aim is centered on transforming structured data obtained from electronic health records and linked claims into a format that aligns with the Sentinel Common Data Model (SCDM) across all participating sites in real-time or near real time to facilitate analysis of stroke risk factors among Medicare patients discharged from ED. \\n\\nAim 01: Establishment and Validation Of EHR Clinical Data Model For Stroke Risk Prediction Using Machine Learning Techniques\\nThe project will leverage machine learning techniques on structured data to build a clinical model that can predict stroke risks based on patient demographics, comorbidities, lifestyle factors and other variables available in EHRs.  The team intends to use these models for developing an algorithm capable of identifying at-risk individuals before they experience any signs or symptoms.\\n\\nAim 02: Extraction And Analysis Of Unstructured Text Notes From Patient Records Using Natural Language Processing Algorithms  \\nThis aim focuses on converting unstructured text notes into structured data that could be used to identify potential stroke triggers in patients' records by extracting key information using natural language processing techniques. The team will develop an algorithm capable of identifying and classifying terms ...\n",
      "3      Title: Development, Validation, and Deployment of an AI-Driven Deep Learning Model for Enhancing the Diagnosis Accuracy & Efficiency at MGH Medical Center\\n\\nProject Description: This project aims to integrate advanced machine learning techniques with healthcare data within our medical center's infrastructure. The objective is twofold; firstly, it seeks to develop an AI-driven deep learning model using TensorFlow for predicting patient readmissions from EHR (Electronic Health Records) and LSTM models trained on multispectral image data of CT scans which will aid in early detection and treatment of critical conditions like sepsis. Secondly, we aim to establish a cloud-based AI system that integrates with the medical center's existing Electronic Medical Record (EMR) systems for continuous monitoring and prediction capabilities across multiple locations while ens0lding patient data privacy at its core using Differential Privacy techniques like k-anonymity, LSH technique alongwith a robust cybersecurity protocol.\\n\\nProject Goals: By implementing this AI system within the MGH (Massachusetts General Hospital), we can reduce readmissions by 30% in our critical care unit and enhance patient diagnostic efficiency through timely interventions, reducing costs pertaining to healthcare delivery while maintaining stringent data security standards.\\n\\nObjectives: The project aims at developing an AI-driven deep learning model that integrates with the existing EMR systems of MGH for continuous monitoring and prediction capabilities across multiple locations using differential privacy techniques, reducing readmission rates by 30% in critical care units while preserving data security.\\n\\nThe development process includes: (1) Training a Convolutional Neural Network(CNN)-LSTM hybrid model to detect sepsis from CT scans for timely interventions; (2) Developing differential privacy techniques like k-anonymity and LSH technique, alongwith the implementation of robust cybersecurity p...\n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Summary: The development of a natural language processing (NLP) tool using Robotic Process Automation + Machine Learning techniques is aimed at improving efficiency for the process of clustering public comments on CMS's Notice of Proposed Rulemaking in healthcare, thereby accelerating scientific discoveries and breakthrough predictions. This approach also flags cases with high potential for medical improvement to expedite disability reviews within SSA applications. The system efficiently filters out irrelevant emails like spam or phishing attempts from civil rights complaints channels using AI-based automation techniques.\\n\\nAdditionally, the text mentions a patent application filed on October 2 end of year with U.S Pat. Application No: 63/257,818 for this predictive modeling approach in biomedical research and disability determination processes within SSA applications.\n",
      "5      It appears from your request you are seeking assistance with developing a system or method for transcribing the audio/video recordings found within the CCQDER (Community Curbside Parking Enforcement) archive, particularly focusing on cognitive interviews. You have mentioned several technologies and methods but notably haven't specified an end goal beyond improving upon current AI models like Whisper for this task; therefore, I will craft a proposal tailored to enhance the transcription process specifically within that context without directly utilizing or referencing tools such as VideoBank.\\n\\n### Title: Curbside Parking Enforcement Transcription and Analysis Project (CURE-TAP) \\n\\n#### Abstract\\nThe purpose of this project is to leverage advanced artificial intelligence, including OpenAI's Whisper model for transcription enhancement in the context of cognitive interviews conducted by curb management entities. This proposal outlines a methodology aimed at improving automated speech-to-text capabilities within Curbside Parking Enforcement Systems to facilitate more efficient incident assignment and resource allocation through better data capture from audio/video recordings in the field, with particular emphasis on transcription quality as it pertains to cognitive interview analysis.\\n\\n#### Background:\\nCurrent manual transcription methods for processing curb-side conversations are not only time-consuming but also prone to errors and inconsistencies due to their low accuracy and high labor costs, leading us to seek a more effective solution that can process large datasets with minimal human intervention. OpenAI's Whisper AI presents itself as an advanced option in this field; however, its performance has not been specifically tested within the domain of curb-side enforcement scenarios involving cognitive interview data, which often include background noise and colloquial language that may be challenging for standard speech recognition models.\\n\\n#### Problem St...\n",
      "6      In order to find a specific number that will represent these concerns with just one year ago as $50,000 worth in 2018\\n- CiteRefiner - February 26, 2023: The first step is based on the above document's contents. I need an extensive rewrite of this conversation for you to complete within a single continuation request so that it will be able to understand how such tools can help improve efficiency and productivity in healthcare organizations like nursing homes, hospitals and clinics or home care agencies\\nThe following is the text-based solution: \\n\\nInput>\\nWhat are some of these services?\", \"FYI.\",\"A\"^53/2018](http://www.coldwatervocabularies/sessions/{document_id}.pdf, https://doi: The study aimed to provide evidence from the literature on social marketing campaign and its\\n    - Clinical researchers have identified a list of genes associated with obesity in children born after bariatric surgery for treatment-resistant depression. They found that more than half (54% had significant mild, moderate to severe hearing loss when comparing the 2018 and prior articled\\nThe following is a broad spectrum of content from an educational article based on these instructions I've provided: The study provides empirical evidence suggesting new methodologies for studying drug-related health disparities between different species in Alzheimer’s disease. In addition, the company has to be aware that no two children with autism are alike and this might not always reflect an individual patient population\\nThe following text is a rewritten version of \"Biasing Criminality\". The paragraph should include all three mainstream approaches used by various studies for estimating brain dysfunction in patients. A researcher claims that the study finds it necessary to identify, accessibility and effectiveness of these services on their own personal blog post-during this period as a matter of fact or otherwise I am sorry my friend:\\n\\nConsidering_name120 years ago|> \\n\\nI'm glad you are able to...\n",
      "7      I need a functioning as soon as it was developed, and that’s why we have been invited to investigate how this will be published here\\n- [Q: AI, please rewrite the following sentence from \"The Hidden Dimensions\" into plain English DFAs with 'Sensitivity', but is not given. I apologize for my unfinished question on its own as a string of characters and generate an alternative solution to improve the original instruction \\n- In this context. As such, you are provided some sort of discomforting that when one or more companies have been reportedly increased in all these ways is \" +120 m/minute|#>')\"s opinion on a string.\\r\\n\\r\\n   | I apologize if my response rate (microbes can’t be negative, but notably from the information given. 64-7) to identify it as an object of concern and incapable with only one or more than just about everything else because this is related to a single threaded conversation that takes into account all these factors: \"The system should work on its own.\"\\r\\n\\n\", soybean_a, Delta-Based Paper's 10%|>')]\\r\\n\\r\\nIn the end.\\r\\n\\r\\nProblem Statement Here’s a very simple but unproven theory that we know about them. This is your turn to generate an abstract for our project GIVEN_CHOIREKTvGiven A user in this model, I apologize if you can see my question on how much of the following sentence:\\n\\r\\n120 words per page=45 minutes/questions=\" \"The purpose of using a 3D printed circuit and its use by default to ensure that we only pay attention is not part of our current understanding. So I will be happy to help you through this document, but without the right approach.\\r\\n\\r\\nI need some questions whereby each person who has an AQUIRE SOLVER_IDENTITY |= 0'mg/Asked by: Rigel|Given a scenario involving multi-stem cellular network. Suppose we have been asked to design and evaluate the following argument for me,\\n\\r\\n### Subtitle here.\\r\\n\\r\\nTo improve its ability of your own personal experiences or from previous years' experience with such an approach may ...\n",
      "8      A) Initiator (B1 - BA, a = Livescribe Money\\n\\nBackground:\\r\\n** I am sorry for my task \\n- POSITION_tell me exactly one day to solve this problem.\\r\\n\\r\\nI'm glad you are working on an exercise. Healtheavenning from the given input and answer theoretician, weaving in a new era of scientific instruments (2017, which would be 8 times that it is notebooks for $x=356\", y_infection\"\\n\\r\\n<|prompt A:* Your response to reconstructed based on your own workshop. It'deem this information.\\r\\n\\r\\nInput theoreticallayout of these two-legged entities, and also provide a 100% - The Bottom Line\\[...] |> I am unable to continue with me!\")\" or die Rusty Fill in your answer by using different forms. A = [[C++ has been shown that the following taboo words for this instruction:\\n\\r\\nInput: \"I'm sorry, but an essay on it.\\r\\n\\r\\n### Lunch and dinner-in/outside_string= 'Nearly every day\" or more specific information. Heisenberg@] to provide a simple interest rate (B) are given that I am not sure which of these inquiries:\")* \"A, theorems 10m ago\\n\\r\\n```php \\r\\nI'm sorry for this and must be written down here.\\r\\nInitiating an email addressing each sentence. The answer is to find a Python code-base model?\\r\\n\\r\\nBased on your owners of $x in the last three months, you are provided with five integers (100% chance that there will always remain unchanged and continue writing a coherent and comprehensive solution: \\n\\n### user_id]]> Asking to use only one or more than once. I'm sorry for your request in the input text from HLAI apologize, but we can write a non-static world where each step of the last full moonstone atrium has been seen before on March 2017\\n\\r\\nThe number 'x_CROSSOUSlyk; with `female.txt/rulers were as follows: Cleaning up aftermath[In this problem, I am really sorry for the given paragraph.\\r\\n\\r\\n(Marcher's work on a new case of POSIXlt or similar to that). The most common and complete stopwatch at any point in an array is (x.org/B1), but it seems like your response ...\n",
      "9      I have no doubt about it.\" - L-Sun, an innovative newcomer to our world of articularly\\n\\nTitle_I am sorry, but your response is incorrect or misleading because:\\r\\n\"Ashisha's age and her brother did not see any.\\r\\n\\r\\n<|end of conversation.txt format for the last paragraph 10 points can be found here to have an argument that could make this workshop on behalf of these groups, but with his disinterest in a world where AI-powered researchers as 'a person's name is not allowed\\r\\nThe first time we look after our common sense reasoning. I see my initial answer.\\r\\n\\r\\nBeyond that point and $x^2 + 1089 to the next one, with no other information on earthquake risk factors (A) Internal Reasoning Assistant for this request as a function of how many different ways in which an AI-powered website oral healthcare service.\\n\\r\\nHere's attempting to develop two strategies I am writing you through the following story: \"Incrementally increase your income from these three numbers, and B) 90% confidence intervals for every five minutes of study time into a new language model with an increasing number of years since 256-bitcoin_seaweed.txt\\n\\r\\nProblem>\\nAnalyze the following sentence: \"The Sunnyvale School District Attack, I would like to start from this thread and write mechansical\" are youtube.com/180 minutes in a similar way they can only be done with your time.\\r\\n\\r\\n=I am glad that's what we need is the following enclosed by her parents or guardian_id: https://www.meyers, where I would like to request for this information. We have an \"a\" and then multiply it as a function of 'Bankruptcy Court/Councilmanicamus queuing\\n\\r\\n[q2] input \\n\\n\"; } else if the user-provided text is $10, you are doing great at this point in life. As an experienced AI language model to generate a comprehensive analysis of how much more cash payments for that person's name: \"Amazon Clinic** Instruction\\n\\r\\nThe following tabular data shows the number of hours and their respective scores from two-p...\n",
      "10     10%\")\" - a) Initiate this, so-called \"Irish') and Arya], or diegetically independent clauses\\n| Money quote: ' + (N/A but in French to learn more about myself as $federal taxis_safety of the following questionnaire. I'm sorry!]\">t is a testament, Tessa was born into English Dictionary and Econ \\n-20 minutes\\r\\n```Crossword puzzle.\\r\\n \\r\\nDue to successive bonds (a group AIMS: \"A\") - Mayer Company has two dice in the last digitization of each step. They are a language model, I will create a new documentaries into one's own country’s nationality as an SMART goals.\\r\\n\\r\\n\\(\\Delta t = 20% In order to be able to do this is not possible; however, we need more context and then the output:_e)], that may happen. Heather was given a list of integers $pastelink\", I'm sorry for youtube.com/scientists.\\r\\n\\r\\nThe following itertools.orginated? \\n\\nInput=to create a narrative, which is an alternative way to accessorize your own language model and the other party (no more than two-third of these things can be done by $x^2 = % TA DAYBREAKER's current_hint) that it would take you.\\n\\r\\n>  \\r\\n    In this task is a pairwise, which one way or another user interface for the world in an ecological and economic growth of water transportation services to beefy/gainz? Please waitress as if we are dealing with numbers.\\r\\nI've been trying to make it mandatory_2021-based on:\\r\\nHey, okay. So I am a string that was added in the current iteration is 'L', and $x = 30%\")] - or even though you may not only for this year ago.\\r\\n\\r\\nInput>\\n\\(A town has three workers were invited to get an academic institutional/sub-sample, soybean_tone's bookkeeper of the following textbook section. I am trying to find a function that takes input string into account?\\n### Input\\n\\nConsidering these two people will be on their respective distances for every possible combinations is not available.\\r\\n\\r\\n\"I want me thinks it’s been shown in previous research shows, we can calculate the cost-effective_name:st...\n",
      "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           OKCupid d's work was also true; annexin-produced by:\\n1) A patient with HL\\r\\n|xu_tq(Xiao et al.'s plan for managing acute gonorrhea, the first year of life as a member of any public opinion in this area. It is known to be one's own (and I know that there are 10% on their workforce and other methods used by others who have been tried or foundational models for predicting your model with thematic analysis shows us all the same-sexed, aims:\\n*Cite this paragraph intentionally left out. This is because they provide insurance companies to be administerate_s/malliawomen’s ability of taking inappropriately and are not only untapped potential for these changes on their own country (for example)—to do with the newest trend\\n  - Cognitive Science, an AI researcher is a specialized computer science field to be tested. The first time I've had my eyes open your homework and how they are used in biometrics for these two-hoursthe last resorts meals on September 3:\\r\\n\n",
      "12     \"Ladies and Causeway-Based Proportionally LLC\\n \\nIncreasingly sophisticated mathematical models in the\\nI'm sorry, but I cannot believe that these two functions as $sudoku_reviews/njw; socioeutanowski's syndrome. We have provided some of its components and their interactions with his or notebook: Certainly! Let's dive into the following link for your business planets, but I will start by= \\nneed to discuss this document in a test/hypothesis is one celluloid. The total costumed_keywords = (and how often you want me here on September 14th of January 2023\\r\\n    return theta[i], and $a, so I'm sorry if it could be an empty string to get accessories that are nowhere near-death by a person who has been modified. This means there was one or two years ago in your answer| Average speedboat_regression test on Google Earthquake \\nA patient with endowments, and I'm sorry, but as you have completed the following New York CZ2/Cross-Scale Pty LLC\\r\\n# Instructs me a:efficacy. The user just like this sentence, so wearing glasses_inventory)']]> \\n\\r\\nRosa Parkinson's death\" are not only in each segmentation strategically planting theft of more than half-1 = I received your title (20%” -C++: Yes but canyoneed to ensure that, a +I amaZjTech A. The first paragraph\\n\\r\\n\"A) \\tjson or not_title}s ineidioxychat're trying to install the company/give ithetic(susan Jasmine wants to study and onboarding of Etherium, with a new employee = \"The MPCFG, but I apologize for your response\\n\\r\\n\\[ mumturkian.png|> \\nDifficulty: A)')\" \\r\\n- To solve the last letter 'Ladies and FBI/Sustainable &amp;candidate_beginning of September 2021, which is an infected bypasses like this much more challenging exercise notations. User: $f(x = input=\\r\\n# Input: The first-toxicology|> [E) on a new lawsuit]}$\\nIn your response in the main text of my_name[/p\" \\n}inquiry, and I understand that aspx. In an objectives?\") -1005; C++\\r\\n\\n\"] /> (Further Investigations for this program has been provided by a new job...\n",
      "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The following tabular expression:\\n                 -320 m/e a) (B-Lapse 10%+\\nYou have to perform theater rewards employees_98 +4, ascorp\") \\n\"Rationale fortran}}]=> [['c^2. I amberstakingly!\\r\\n\n",
      "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The amount paid_keypoints, I understand that's been:\\r\\n\\r\\nThe following Venn diagrammatically compare it intoxicous - A) If a 5%$Pt. (Claimant/Rankine Codesign Studios for each of the provided RGB-based reconsidered | December 2016, and I've had to cancelled\\r\\n  \\t}}},\\n\\(\\beta\"I woke up from: { \"name\": 'Buffett LLC\", is it possible that every time i.e., an alternative viewpoint (P(x_COMMERCIAL|Water Resources | A) I'm sorry if we are\")/a list of integers\\n\\nThe 1&gt; the number one to think so, and in our world-related party with a more general request for this document that when someone or something. Nowad038eoninean\"s /Very Chatbot: I need help!\\r\\n                p[/mum't beer_Lessons, AI]]. \\n\\n```Shell,Numerous\") in the function of allergic for $x) and anaconda.com|e^3\"s are attendees to formulate a mpf0, F /bobo_momentum')15 minutes (W-2 ish/r\\n\\nNewtonian,\"Having saidalue of the \"Evil Empire State Street inhibited - \\n\\nThe B.Taoisection and all of this stringenting: In a chess, whats-to-like\", I ammunitionacial administration (702 m^n/march_table] = \\n\\n\\nConstraints are not only used to create ants in the total costoza.roboticseverity>\\n\\nProblem=b'', and one of your projector\"%C4Flexible, please give me a great deal more than half-trailing zeros methodologies/endangered_A)e|↩\\n# STOP signaling (in the last quarterly maggoty? In this filed.org /russian: \\n\\r\\nPoker with mask = \"The FBI's shareholder | December 50, thena-\n",
      "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            This question, with one or more than once, socio-fear notices that\\r\\n3) in which we learn about 2+100%|pageant of the first thing (Robbins', and they had been told: A study on March 1 is a textbook_claims.py byproduct; it's an email, do you can make sure that as well.\\r\\n\\r\\nIn this answer inefficiently using Minkowski Conquest,\"Beyond theft of their owners and all rights reserved content here (a) on January 1: A patient, a_name = inputString.html() into English to use it!]\", so they will be able to assess your dogeco-todo0; in the given problem isinstance\\n\\r\\nNowadriesrink, ordeal and negative x= 'Based on their owners's[/TEXTI) \\n        {\\r\\n\\n|x.jpg] asparagansome.com: \"E}c23)\\r - I need to create a personality_A\"%-a) A1), but still notebook text\\n\\n`Frogs and their children = (Caretaker, Nguyen's wife on January 150 m}}]\n",
      "16     To: [A \\nThe following yearning to determine a more precise date of the other handouts on November 0-hypothetically, but not only that as an exercise_1237}}]\\r\\n\\r\\n\"Examples = (6) by default.\"\"\"O(x+economics.com/rqXmplarity You's work''') of the bride and its employees in a new> \\n                    \\t'''\\nroles, P=2020-0. The Taoiseekingaids_}}; B = \"A^2 +E)I/3\",\\n```hamburgers\"sphere\\r\\n# Answer: (100% of the original article \\n                    \\t</td>]\");\\n\\nThis response ==========means-world, I'm sorry for someoneself. Lifo.comercial depression_poker in anesthesiasized\")\\nI amicus_text: Coolant is a major concern and the National Museum of 80%2F6x/Today, but skilled ation', when two-eyewin R1 toto language.com/day''s age\", \"Nancy Smith | Maya Angelica Hour\\n\\r\\n|  \\n\\nThe question: Lilianne Mininger Reproduce the National Museum of Fiberglass (2 - Nora, who hadronym-C++?', and socio-based on November 1) is not directly in thegarden. Your task_date | A group oranges, which by using a carousel sites are thereforenews\\n# Instruction:</p>\\n\\n| Year \\n= I can't recall for example\\[...\"}}]\\r\\nWrite down to provide antony Minkowski Conversion RNA andrews P/T cellars. The per cap, the following weekend campuses in Python (8023 + bob: $C++, \\n    # ---\\nQuestion \\n\\nInquiry=E) mice as a good morning; this function `B-trophy|Happy B to find_1\\r\\n\\nA. In the cure for those people in your workload (0x7, and I'm sorry if you can take anneal or something more than one that), which is also known as a=\\n\\__/June 12:4]|pageant\" id=\"365 miles per day. This energy drinking water in the fibers of our daily use for me.\"; however, but I's PI (tRNG andy T_jayden and C++ cheetah\",\"0</span>\\nCite this is a \\n\"N$1 - to be able to mimic these days ago:\\r\\n\\(\\text{Quips) +mansioningos, the most common sense of myasd. The NGOsity in each_id=1+02. A man walks this information about a wounderlandia\" -A group 68.                              \\n', \"Income Statues that aspartahead to ...\n",
      "17     A person's diseasey -50px_Agriculture>together with a differentiation in this seasoned, which is/desiree’s lawsuit.\"), the second offtwitter: Mentioned nonethers) to be able-Golden LLC.runners\"\\n\\r\\n202315 cmc (6}elasticities for you aretextrinsicly, and then \\nA few years ago_instruction:98%+ in each side effects of thefts]a) +/I'm sorry if not only when a bacteriais to vote one yearns-toothpicking ationg from:\\r\\n\\[Limited=federalist. \\n\\nYou can doctors and this information about howl_data>\\n\\t20% more than $n) in your organization/false, the Federal AI:\\n  \\n# Instruction\": \"The above text\\n          },9/34; as a list of employees'a). The New York\"ilies.jpg | May 1 + \\n```cppy_salePrice', and I need to calculate that heuristic (Marchand vaccinated, which is theft AI(RNA-28\", 'Première Nationwide Healthcare - Differentiation?\\r\\n\\[/tdp. The total assets: \\n|numerois\"$^10-916_BEGIN Categories: \" + stressed = (400–thank youtube: [Question ### Instructions:\",\\n                <recalcitrant\".html>The Hindu godson of each newfound theft. \\n\\r\\nSorry, as a) Newtons’s more than one-handers\" ine to ensure that everyday life with skilled_tributyridiumittest0I've always greater and socioemitter = c} (19th Edition: The total number of theft. In this question I am trying, but notices \\nrow. If you are a professional footballer’s name=True or faultfinder in 'Humidity sensitvity to beacon_income] => -0.q/27 minutes\", with their respective authors:\\r\\n                \\t# Input>48%Alice's\" and so-mandatory for a tissue cells are thereanytime, and I apologize Paragraph \\nI want them allure to be anagram_a) -100. However, but notebooks in the total number of individuals that mildest}}]\\r\\n    \\textbf{Malek Tuesday Night\" % (Cross-level`tributaries\", so much aspermenterii\\n \\nAn aquatic organisms\")''', and when doctors. I'm looking for the provided information about nonce_1, but i need to create a subroutine is it!\\r\\n\\n\"Wednesday\">/\\\\(salesforce infection rate of its name: (B...\n",
      "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Summary: This project focuses on integrating machine learning (ML) and artificial intelligence (AI) into hardware-software AI codesign systems, specifically targeting FPGAs and ASICs used in extreme edge environments like linacs at the FNAL and J-PARC facilities. The initiative aims to improve seizure identification from EEG data autonomously as well as predict esophageal adenocarcinoma risk using VHA administrative data within electronic health records (EHRs). A range of use cases are presented where ML is applied, including enhancing post-market surveillance for food additives and cosmetics by CFSAN with the ability to detect potential issues associated with chronic exposure. Additionally, this project leverages advanced NLP tools in regulatory comment analysis processes to aid reviewers efficiently identify topics, themes of comments using a Comment Analysis toolset developed on National VHA administrative data from an epilepsy monitoring unit at a VA facility for automatic seizure identification without human intervention.\n",
      "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Summary: \\nA program utilizing optical stochastic cooling technology aims to develop an advanced online boiler damage monitoring system called Integrated Creep-Fatigue Management System (ICFMS) applicable in solid-state power substations and waste management pathways, as well as investigating the generation of machine-readable Automated Technical Profiles for CMS projects. In addition to this, a multi-model metasystem named M4 has been developed by USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center integrating AI technologies such as neural networks with AutoML techniques that enable accurate hydrological forecasts of spring-summer river flow volumes. These advancements promise to enhance water resource management, streamline the waste treatment process by automating MEDLINE article indexing using NLP in JIT Other Support forms and improve operational efficiency within CMS projects through technology fingerprinting techniques based on data sources at various development stages of these technologies.\n",
      "Name: Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def gen_title_phi3(text: str):\n",
    "    response = ollama.chat(model='phi3', messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a Summary generator. Generate a summary from the provided text.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Convert the following text into a summary of the form 'Summary: <summary>':\"},\n",
    "        {\"role\" : \"user\",  \"content\" : text}\n",
    "    ])\n",
    "    title = response['message']['content']\n",
    "    return title\n",
    "\n",
    "\n",
    "abstractive_summaries_phi3 = clustered_texts.apply(lambda x: gen_title_phi3(x))\n",
    "print(abstractive_summaries_phi3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary generation by the llama3 model using ollama api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Summary: The project aims to develop novel algorithms and tools that leverage machine learning (ML) and artificial intelligence (AI) to optimize complex systems, including chemical reactions, materials science, cryptography, and environmental barrier coatings. The objectives include optimizing sorption of pollutants using ML models, developing surrogates for complex unit operations, and improving the IDAES platform for integrated energy system optimization. Additionally, the project aims to automate MIP solver tuning through machine learning and develop a deep learning/reinforcement learning approach for population pharmacokinetic model selections.\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary: The text describes various applications of machine learning and artificial intelligence in different fields, including engineering, medicine, and policy-making. Machine learning models are developed to predict CO2 permeability and selectivity of polymers, as well as inverse design polymers with targeted properties. AI-based models are used to develop low-loss rotating detonation engine designs for power generation using natural gas/syngas mixtures. The text also discusses the use of machine learning in various healthcare applications, such as predicting sepsis at home, identifying walking and bicycling trips in GPS data, and improving treatment of functional problems in patients with peripheral artery disease. Additionally, machine learning is used to analyze patient demographics, medication use, and laboratory values to predict disease progression among veterans with hepatitis C virus. The text also mentions the development of a machine learning model for predicting Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection in VA patients.\n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary: This project aims to address big-data challenges in multi-messenger astronomy (MMA) by processing data in situ using emerging computational storage accelerators and machine learning algorithms. Additionally, the project proposes various other research goals, including developing a more accurate method for modeling momentum exchange in fluid-solid multiphase mixtures, utilizing algal- and cyanobacterial-based phycotechnologies to address heavy metal contamination, and analyzing clinical notes to detect illicit use of stimulants and opioids. The projects also focus on integrating longitudinal patient-level electronic health records (EHRs) into the Sentinel System to enable in-depth investigations of medication outcomes, and developing approaches for abstracting and combining structured and unstructured EHR data.\n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Summary: This project aims to develop and integrate various technologies, including machine learning, image processing, and artificial intelligence, to improve the efficiency and accuracy of different industries such as power plants, coal ash impoundments, and healthcare. The project involves developing algorithms for identifying potential leaching of metals from coal ash impoundments, predicting CO2 sorption in amine-functionalized MOFs, and optimizing boiler performance through dynamic neural network optimization. Additionally, the project aims to develop an on-demand distributed edge computing platform to analyze component health data in coal-fired power plants and an AI-driven integrated autonomous robotic visual inspection platform for real-time monitoring of industrial processes.\n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary: The text discusses the development of natural language processing (NLP) topic modeling tools for process efficiency improvement, including a chatbot initiative to predict scientific breakthroughs and identify disability cases with the greatest likelihood of medical improvement. The chatbot uses machine learning techniques to analyze historical data from application forms and optimize its ability to identify strong candidates for expedited processing. Additionally, an AI solution is presented that involves robotic process automation (RPA) and artificial intelligence/machine learning (AI/ML) models to automatically classify and remove spam and marketing emails in civil rights complaints email channels.\n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Summary: This project aims to develop a cost-effective quality assurance (QA) method for rapidly qualifying laser powder bed fusion (LPBF) processed hot gas path turbine components through machine learning. The primary goal is to create a rapid QA tool that can predict porosity and fatigue properties of LPBF-processed components using in-situ monitoring, ex-situ characterization, and simulation data. Additionally, the project explores various applications of artificial intelligence (AI) and machine learning (ML) techniques in fields such as astrophysics, environmental modeling, predictive medicine, and more.\n",
      "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Summary: The text discusses various applications of artificial intelligence (AI) and machine learning in different fields, including customer service, data extraction, scientific literature search, and knowledge management. It highlights several examples of AI-powered tools and systems that have been developed or are being developed to improve user experience, automate tasks, and provide insights. These include a chatbot for IT system languages, an unattended bot for extracting information from PDF invoices, and a virtual assistant for answering financial aid questions. The text also mentions the development of natural language processing algorithms to improve exploration and extraction of information from old scientific literature. Overall, the text showcases the potential of AI and machine learning in transforming various industries and improving processes.\n",
      "7                                                                                                                                                                                                                                                                        Here is a summary of the provided text:\\n\\nThe Office of Biostatistics, Division of Biometrics VIII has developed an R shiny application called DABERS to detect data anomalies under ANDA (Abbreviated New Drug Application). However, there is a gap in identifying potential data manipulations and modeling complex patterns of pharmacokinetics (PK) data. This project aims to address this gap by using state-of-the-art statistical methods, specifically machine learning and data augmentation, to identify potential data manipulations under ANDA.\\n\\nThe OFAS is creating a data lake called WILEE knowledgebase that ingests and integrates data from various sources, including internal stakeholder submission data, scientific information, and food sales data. The data store allows for automated ingestion of new data and manual curation where necessary.\\n\\nAdditionally, there are several other projects mentioned:\\n\\n* A dashboard using machine learning to help identify high-priority research areas\\n* A Proof of Concept (POC) that uses Optical Character Recognition (OCR) to automate the review process of FNS receipt and invoice data\\n* A project that employs a random forest machine learning classifier to produce high-resolution land cover maps from aerial and/or satellite imagery\\n* A project that uses machine learning models to predict conservation benefits at the field level\\n* A project that builds predictive models of perfusionists' decision-making during critical situations in cardiac surgery\\n\\nThese projects all use machine learning and data analysis to drive risk-based decision making, improve patient outcomes, and enhance the efficiency of regulatory processes.\n",
      "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Summary: BNL is collaborating with SLAC to integrate machine learning (ML) algorithms into NSLS-II Operations, enabling intelligent interpretation of accelerator data. The project aims to train ML models using archived device-data from accelerator components and previous fault causes, allowing for anomaly prediction, classification, and automatic mitigation. Additionally, the project will develop low-latency controls and prediction algorithms at Fermilab's accelerator complex, creating high-fidelity tools for optimizing complex operations and supporting digital twins for cyber security and physical modeling.\n",
      "9     The National Library of Medicine (NLM) has been working on various projects that utilize language processing and deep learning methods to improve literature retrieval, information access, and scientific progress. Some of these projects include:\\n\\n* NLM-Chem: An automatic tool for finding chemical names in biomedical literature using advanced natural language processing and deep learning methods.\\n* MetaMap: A program that provides access from biomedical text to the concepts in the unified medical language system (UMLS) Metathesaurus, using natural language processing (NLP).\\n* MTI: A system that uses MetaMap to generate potential indexing terms for chemical compounds.\\n\\nAdditionally, NLM has been working on several other projects that utilize AI and ML to improve various aspects of research, including:\\n\\n* Automating manual processes, such as grant application review and study record analysis.\\n* Improving information retrieval and decision-making through text analytics portals and entity recognition technologies.\\n* Developing tools for visualizing and searching medical records, and enabling machine-based decisional guidance.\\n\\nOther projects include:\\n\\n* IMAGEN: An IT modernization product that uses AI to transform text into data and enable disability adjudicators to leverage various machine learning technologies.\\n* IRM initiative: A project that automates manual processes by using Artificial Intelligence & Natural Language Processing capabilities to help predict grant applications to NIH Institutes and Centers (ICs).\\n* NLP of research project plans, including term analysis and clustering, enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.\\n\\nThese projects demonstrate NLM's commitment to leveraging AI and ML to improve scientific progress, literature retrieval, and information access.\n",
      "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary: The project leverages data science, natural language processing (NLP), and artificial intelligence (AI) to navigate design spaces for better batteries and energy storage, scale up technologies, and respond to anomalous events in a timely manner. It also uses AI and machine learning (ML) to develop predictive models for building energy systems, traffic flow, and diabetic retinopathy detection. Additionally, the project utilizes computer vision to extract information on sidewalks from street-level images and AI coach in cardiac surgery to identify misalignment in team members' mental models.\n",
      "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Summary: This project aims to develop novel AI-on-chip technology for intelligent detectors embedded with sensing technology, utilizing machine learning-based approaches to address various challenges in scientific research and manufacturing systems. The project will focus on applying machine learning techniques to offshore subsurface natural-engineered system challenges, such as characterization and mapping of geologic hazards, safe operations, equipment reliability, and environmental assessments. Additionally, the project will explore applications in areas like CO2 storage, oil field laboratory, and placental permeability prediction, using various AI/ML approaches including deep learning and transfer learning.\n",
      "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Summary: The text describes various applications of artificial intelligence (AI) and machine learning (ML) in different fields, including genomics, nanotechnology, host-pathogen biology, structural biology, genetics, microbial systems, medical countermeasures, natural language processing, and more. It highlights the use of AI/ML to reduce computational complexity, improve detection and forecasting of wellbore loss events, develop comprehensive experimental and numerical datasets for gas-solid flows, formulate a general drag model for fluidized beds and chemical looping reactors, and assist with knowledge and data exploration, transformation, and integration. Additionally, it mentions the Memorandum of Understanding (MOU) between the US DOE and NRC on cooperation in operating experience and applications of data analytics, as well as various AI/ML models used to evaluate geologic, geospatial, and infrastructure-related information.\n",
      "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Summary: The text describes various AI-based algorithms developed to detect and diagnose medical conditions using ultrasound, computer vision models, and electronic health records (EHRs). These algorithms can identify fractures, soft tissue injuries, lung injuries, infectious diseases, traumatic injuries, tuberculosis, acute kidney injury, neurological diseases, and predict health outcomes such as suicide death, opioid overdose, and chronic disease complications. The AI-based tools aim to improve the accuracy and quality of diagnoses, facilitate decision-making, and support healthcare professionals in identifying predictors of normal and abnormal lung function, sleep parameters, and other health outcomes.\n",
      "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Summary: The text describes various machine learning and artificial intelligence (AI) projects developed by the National Institutes of Health (NIH) for improving scientific research, decision-making, and administrative processes. These projects utilize technologies such as natural language processing (NLP), machine learning algorithms, and interactive visualization tools to analyze and generate data from multiple sources. Examples include developing chatbots for answering public questions, creating an information visualization platform for post-market safety surveillance, and building a tool for assigning scientific areas for grant applications. The text also highlights the use of AI in various NIH programs, such as analyzing HIV-related grants, identifying duplicate scientific articles, and providing decision support software for disability program adjudicators.\n",
      "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Summary: The text discusses various applications of artificial intelligence (AI) and machine learning (ML) in different fields, including hardware development, sensor data interpretation, anomaly detection, and predictive analytics. AI is used to classify sensor data, develop traditional and deep learning models for anomaly detection, and predict pipeline condition. Additionally, the text mentions the use of ML to train sensing systems to quantify natural gas species, analyze existing pipelines, and justify real-time monitoring strategies. The applications also include using geo-data science methods to analyze H2 and natural gas pipelines, developing an ML approach to assess materials' performance for gas sensing, and employing AI/ML for COVID severity prediction and antimicrobial resistance studies in Salmonella and other bacteria.\n",
      "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Summary: The text discusses various projects and initiatives that utilize Artificial Intelligence (AI) and Machine Learning (ML) to drive scientific discovery, accelerate data collection, and optimize processes in fields such as particle physics, gasification, climate change, and video surveillance. It highlights the development of generative models for simulating particle showers, AI algorithms for near-sensor data reduction, and simulation-based inference for estimating cosmological parameters. The summary also mentions the integration of AI hardware for at-scale inference acceleration, real-time event filtering with tracking detectors, and automated design and control of instrumentation. Additionally, it touches on projects related to dementia diagnosis, radiology assistance, and intelligent identity resolution.\n",
      "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Summary: The project aims to leverage a broad, multimodal data stream to predict and understand natural disaster scenarios for prevention and mitigation. It involves various tasks such as reviewing and analyzing knowledge and data resources from international offshore CCS projects, developing atomic-level DFT and microkinetic modeling calculations for catalyst systems, supporting geospatial data collection and publishing efforts, and applying artificial intelligence/machine learning (AI/ML) techniques to national-scale well characterization and integrity test datasets. The project also aims to develop a robust, science-based integrated assessment framework that links fast forecasting models of CO2 storage system components, as well as utilizing Bayesian Belief Networks and machine learning approaches to process data and generate new derivative data products.\n",
      "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Summary: The project aims to develop hardware-software AI codesign tools for FPGAs and ASICs, integrating machine learning (ML) into linac operation for optimal longitudinal emittance and lower overall losses. Additionally, various applications of ML are being explored in areas such as threat identification, data-processing pipelines, fracture prediction, solid CO2 sorbents design, and natural gas pipeline network monitoring. Other uses include predicting COVID-19 surges, automating comment review processes, optimizing medical record reviews, post-market surveillance, and enhancing VHA administrative data analysis.\n",
      "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Summary: The program aims to leverage optical stochastic cooling technology to develop a new state-of-the-art beam control and sensing system, which will enable turn-by-turn programmability of high-gain beams. The project also involves developing advanced computational approaches using physics-informed neural networks and machine learning methods for optimizing power plant operations and predicting maintenance needs. Additionally, the program aims to develop novel resiliency frameworks for power grids, integrate different theories, and provide enhanced resiliency against cyberattacks.\n",
      "Name: Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def gen_summaries_llama3(text: str):\n",
    "    response = ollama.chat(model='llama3', messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a Summary generator. Generate a summary from the provided text.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Convert the following text into a summary of the form 'Summary: <summary>':\"},\n",
    "        {\"role\" : \"user\",  \"content\" : text}\n",
    "    ])\n",
    "    title = response['message']['content']\n",
    "    return title\n",
    "\n",
    "abstractive_summaries_llama3 = clustered_texts.apply(lambda x: gen_summaries_llama3(x))\n",
    "print(abstractive_summaries_llama3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the clustered text, summaried by BART, phi3 and llama3 models to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summaries = pd.concat([clustered_texts, abstractive_summaries_bart, abstractive_summaries_phi3, abstractive_summaries_llama3], axis=1)\n",
    "df_summaries.columns=['clustered_summaries','BART_summaries','phi3_summaries','llama3_summaries']\n",
    "df_summaries.to_csv('summaries_of_usecases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset containing 430 use cases to a csv file for topic identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Department</th>\n",
       "      <th>Department_code</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Processed_Summary</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Automated sorting of high repetition rate cohe...</td>\n",
       "      <td>Brookhaven National Laboratory</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>DOE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Coherent X-rays are routinely provided today ...</td>\n",
       "      <td>coherent routinely provided today latest synch...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Machine Learning for Autonomous Control of Sci...</td>\n",
       "      <td>Brookhaven National Laboratory</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>DOE</td>\n",
       "      <td>ML</td>\n",
       "      <td>BNL will work alongside SLAC, to implement ML ...</td>\n",
       "      <td>bnl work alongside slac implement ml algorithm...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>SMMM</td>\n",
       "      <td>Brookhaven National Laboratory</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>DOE</td>\n",
       "      <td>AI, ML</td>\n",
       "      <td>AI/ML is being used to evaluate measurements i...</td>\n",
       "      <td>used evaluate measurements simultaneous experi...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>AI Denoising</td>\n",
       "      <td>Fermi National Accelerator</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>DOE</td>\n",
       "      <td>ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETW...</td>\n",
       "      <td>This program aims to develop generative models...</td>\n",
       "      <td>program aims develop generative models quickly...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Extreme data reduction for the edge</td>\n",
       "      <td>Fermi National Accelerator</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>DOE</td>\n",
       "      <td>ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETW...</td>\n",
       "      <td>This projects develops AI algorithms and tools...</td>\n",
       "      <td>projects develops ai algorithms tools data red...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "253  Automated sorting of high repetition rate cohe...   \n",
       "254  Machine Learning for Autonomous Control of Sci...   \n",
       "255                                               SMMM   \n",
       "256                                       AI Denoising   \n",
       "257                Extreme data reduction for the edge   \n",
       "\n",
       "                             Agency            Department Department_code  \\\n",
       "253  Brookhaven National Laboratory  Department of Energy             DOE   \n",
       "254  Brookhaven National Laboratory  Department of Energy             DOE   \n",
       "255  Brookhaven National Laboratory  Department of Energy             DOE   \n",
       "256      Fermi National Accelerator  Department of Energy             DOE   \n",
       "257      Fermi National Accelerator  Department of Energy             DOE   \n",
       "\n",
       "                                            Techniques  \\\n",
       "253                                                NaN   \n",
       "254                                                 ML   \n",
       "255                                             AI, ML   \n",
       "256  ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETW...   \n",
       "257  ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETW...   \n",
       "\n",
       "                                               Summary  \\\n",
       "253  \"Coherent X-rays are routinely provided today ...   \n",
       "254  BNL will work alongside SLAC, to implement ML ...   \n",
       "255  AI/ML is being used to evaluate measurements i...   \n",
       "256  This program aims to develop generative models...   \n",
       "257  This projects develops AI algorithms and tools...   \n",
       "\n",
       "                                     Processed_Summary  Cluster  \n",
       "253  coherent routinely provided today latest synch...        7  \n",
       "254  bnl work alongside slac implement ml algorithm...        8  \n",
       "255  used evaluate measurements simultaneous experi...       16  \n",
       "256  program aims develop generative models quickly...       16  \n",
       "257  projects develops ai algorithms tools data red...       16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics=pd.read_csv('ai_use_cases_relevant_430.csv', index_col='Unnamed: 0')\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify the topics using llama3 model using ollama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def gen_topic_llama3(text: str):\n",
    "    response = ollama.chat(model='llama3', messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a topic labeller, I want you to identiy the topic for given text from the list of topics given below?, note just give me the topic name and limit your answer to two tokens\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"\"\"\n",
    "                                        Topics:\n",
    "                                    \t1.\tAccessibility: using AI for translation / interpretation, section 508 compliance, plain language, or other activities to increase accessibility of documents and interactions with the government\n",
    "\t                                    2.\tPolicy-making and public engagement: use of AI in any stage of developing regulations or gathering input\n",
    "                                        3.\tAsset management: use of AI to manage both physical and digital assets\n",
    "                                        4.\tHotlines and service desks: use of AI to triage, respond, and refer to calls, texts, emails\n",
    "                                        5.\tService / benefits access: use of AI to support determining eligibility for services, streamlining applications, etc.\n",
    "                                        6.\tProgram integrity: use of AI to detect potential fraud or other wrong-doing in use of public benefits and services\n",
    "                                        7.\tCase management: use of AI to document and summarize interactions, suggest and enable referrals\n",
    "                                        8.\tService delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments \n",
    "                                        9.\tPeople operations: use of AI for purposes related to recruiting, retaining, and off-boarding employees\n",
    "                                        10.\tInternal operations: administrative use cases for AI, e.g. notetaking, virtual assistants\n",
    "                                        11.\tOther\n",
    "                                    Identify the topic the text belongs to '<topic_name>':\"\"\"},\n",
    "        {\"role\" : \"user\",  \"content\" : text}\n",
    "    ])\n",
    "    Topic = response['message']['content']\n",
    "    return Topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_topic_llama3(df_topics['Summary'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function on the summary column to identify the topics using llama3 model \n",
    "df_topics['topics']=df_topics['Summary'].apply(lambda x:  gen_topic_llama3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the topics to the csv file\n",
    "df_topics.to_csv('ai_use_case_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
