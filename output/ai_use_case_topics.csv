,Title,Agency,Department,Department_code,Techniques,Summary,Processed_Summary,Cluster,topics
253,Automated sorting of high repetition rate coherent diffraction data from XFELS,Brookhaven National Laboratory,Department of Energy,DOE,,"""Coherent X-rays are routinely provided today by the latest Synchrotron 
and X-ray Free-electron Laser Sources. When these diffract from a 
crystal containing defects, interference leads to the formation of a 
modulated diffraction pattern called """"speckle"""". When the defects move 
around, they can be quantified by a correlation analysis technique called 
X-ray Photon Correlation Spectroscopy. But the speckles also change 
when the beam moves on the sample. By scanning the beam in a 
controlled way, the overlap between the adjacent regions gives 
redundancy to the data, which allows a solution of the inherent phase 
problem. This is the basis of the coherent X-ray ptychography method 
which can achieve image resolutions of 10nm, but only if the probe 
positions are known.
The goal of this proposal will be to separate """"genuine"""" fluctuations of a 
material sample from the inherent beam fluctuations at the high data 
rates of XFELs. Algorithms will be developed to calculate the 
correlations between all the coherent diffraction patterns arriving in a 
time series, then used to separate the two sources of fluctuation using 
the criterion that the """"natural"""" thermal fluctuations do not repeat, while 
beam ones do.  We separate the data stream into image and beam 
""""modes"""" automatically.""",coherent routinely provided today latest synchrotron laser sources diffract crystal containing defects interference leads formation modulated diffraction pattern called speckle defects move around quantified correlation analysis technique called photon correlation spectroscopy speckles also change beam moves sample scanning beam controlled way overlap adjacent regions gives redundancy data allows solution inherent phase problem basis coherent ptychography method achieve image resolutions probe positions known goal proposal separate genuine fluctuations material sample inherent beam fluctuations high data rates xfels algorithms developed calculate correlations coherent diffraction patterns arriving time series used separate two sources fluctuation using criterion natural thermal fluctuations repeat beam ones separate data stream image beam modes automatically,7,"Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
254,Machine Learning for Autonomous Control of Scientific User Facilities,Brookhaven National Laboratory,Department of Energy,DOE,ML,"BNL will work alongside SLAC, to implement ML algorithm(s) into NSLS-
II Operations to interpret accelerator data more intelligently.  We intend 
to train said algorithms with 5+ years of archived device-data from 
accelerator components, records of previous fault causes (to connect to 
data-symptoms) and stored beam current.",bnl work alongside slac implement ml algorithm ii operations interpret accelerator data intelligently intend train said algorithms years archived accelerator components records previous fault causes connect stored beam current,8,Asset management
255,SMMM,Brookhaven National Laboratory,Department of Energy,DOE,"AI, ML","AI/ML is being used to evaluate measurements in real-time during 
simultaneous experiments on two beamlines and then drive subsequent 
data collection on both of the beamlines to maximize the scientific value 
generated per time.",used evaluate measurements simultaneous experiments two beamlines drive subsequent data collection beamlines maximize scientific value generated per time,16,Service delivery
256,AI Denoising,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS, HIERARCHICAL GENERATIVE MODEL","This program aims to develop generative models for quickly simulating 
showers of particles in calorimeters for LHC experiments",program aims develop generative models quickly simulating showers particles calorimeters lhc experiments,16,Topic: Asset management
257,Extreme data reduction for the edge,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS, NOVEL SPECTROSCOPIC TECHNOLOGY","This projects develops AI algorithms and tools for near-sensor data 
reduction in custom hardware.",projects develops ai algorithms tools data reduction custom hardware,16,Service delivery
258,High-Velocity AI: Generative Models,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS, HIERARCHICAL GENERATIVE MODEL","This project has two parts: 1. generating adversarial examples and then 
using domain adaptation and other techniques to improve the 
robustness of AI classification algorithms against those attacks 
(focusing on astrophysics/cosmology applications); 2. using AI 
algorithms to improve the output of low-quality classical simulation 
engines to deliver a high-quality result at high speed.",project two parts generating adversarial examples using domain adaptation techniques improve robustness ai classification algorithms attacks focusing applications using ai algorithms improve output classical simulation engines deliver result high speed,5,Topic: Internal Operations
259,hls4ml,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project develops hardware-software AI codesign tools for FPGAs 
and ASICs for algorithms running at the extreme edge.",project develops ai codesign tools fpgas asics algorithms running extreme edge,18,Asset management
260,In-pixel AI for future tracking detectors,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project explores novel  AI-on-chip technology for intelligent 
detectors embedded with sensing technology",project explores novel technology intelligent detectors embedded sensing technology,11,Service delivery
261,In-storage computing for multi- messenger astronomy in neutrino experiments and cosmological surveys,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project aims to address the big-data challenges and stringent time 
constraints facing multi-messenger astronomy (MMA) in neutrino 
experiments and cosomological surveys. Instead of following the 
traditional computing paradigm of moving data to the compute 
elements, it does the opposite to embed computation in the data where 
processing is performed in situ. This will be achieved through emerging 
computational storage accelerators on which ML algorithms may be 
deployed to execute MMA tasks quickly so alerts can be disseminated 
promptly.",project aims address challenges stringent time constraints facing astronomy mma neutrino experiments cosomological surveys instead following traditional computing paradigm moving data compute elements opposite embed computation data processing performed situ achieved emerging computational storage accelerators ml algorithms may deployed execute mma tasks quickly alerts disseminated promptly,2,Topic: Other
262,Machine Learning for Accelerator Operations Using Big Data Analytics / L-CAPE,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","Big data analytics for anomaly prediction and classification, enabling 
automatic mitigation, operational savings, and predictive maintenance of 
the Fermilab LINAC",big data analytics anomaly prediction classification enabling automatic mitigation operational savings predictive maintenance fermilab linac,8,Asset management: use of AI to manage both physical and digital assets
263,Machine Learning for Linac Improved Performance,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","In Linacs at FNAL and J-PARC, the current emittance optimization 
procedure is limited to manual adjustments of a few parameters; using 
a larger number is not practically feasible for a human operator. Using 
machine learning (ML) techniques allows lifting this restriction and 
expanding this set. Our goal is to integrate ML into linac operation - and 
in particular RF control to achieve a more optimal longitudinal emittance 
and lower overall losses.",linacs fnal current emittance optimization procedure limited manual adjustments parameters using larger number practically feasible human operator using machine learning ml techniques allows lifting restriction expanding set goal integrate ml linac operation particular rf control achieve optimal longitudinal emittance lower overall losses,18,Topic: Asset management
264,Next-Generation Beam Cooling and Control with Optical Stochastic Cooling,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This program leverages the physics and technology of optical stochastic 
cooling (OSC) to explore new possibilities in beam control and sensing.  
The planned architecture and performance of a new OSC system at 
IOTA should enable turn-by-turn programmability of the high-gain OSC.  
This capability can then be used in conjunction with other hardware 
systems as the basis of an action space for reinforcement learning (RL) 
methods.  The program aims to establish a new state of the art in beam 
cooling and a flexible set of tools for beam control and sensing at 
colliders and other accelerator facilities.",program leverages physics technology optical stochastic cooling osc explore new possibilities beam control sensing planned architecture performance new osc system iota enable programmability osc capability used conjunction hardware systems basis action space reinforcement learning rl methods program aims establish new state art beam cooling flexible set tools beam control sensing colliders accelerator facilities,19,Topic: Asset management
265,READS: Real-time Edge AI for Distributed Systems,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project will develop and deploy low-latency controls and prediction 
algorithms at the Fermilab accelerator complex",project develop deploy controls prediction algorithms fermilab accelerator complex,8,Service delivery:
266,Simulation-based inference for cosmology,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project will develop and use simulation-based inference to estimate 
cosmological parameters related to cosmic acceleration in the early and 
late universe â via the cosmic microwave background and strong 
gravitational lensing, respectively. This will produce an analysis pipeline 
that can be deployed for next-generation cosmic surveys.",project develop use inference estimate cosmological parameters related cosmic acceleration early late universe via cosmic microwave background strong gravitational lensing respectively produce analysis pipeline deployed cosmic surveys,16,Topic_name: Internal operations
267,SONIC: AI acceleration as a service,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project focuses on integration of AI hardware for at-scale inference 
acceleration for particle physics experiments.",project focuses integration ai hardware inference acceleration particle physics experiments,16,Service delivery: using AI to provide direct services either to the public or to state/local/tribal/territorial governments
268,Streamining intelligent detectors for sPHENIX/EIC,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project develops real-time algorithms for event filtering with tracking 
detectors for nuclear physics collider experiments.",project develops algorithms event filtering tracking detectors nuclear physics collider experiments,16,Topic: Asset management
269,Uncertainty Quantification and Instrument Automation to enable next generation cosmological discoveries,Fermi National Accelerator,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","This project will develop AI-based tools to enable critical sectors for near-
future cosmic applications. Uncertainty quantification is essential for 
performing discovery science now, and simulation-based inference 
offers a new approach. The automated design and control of 
instrumentation will be important for improving the efficiency of planning 
and executing cosmic experiments.",project develop tools enable critical sectors future cosmic applications uncertainty quantification essential performing discovery science inference offers new approach automated design control instrumentation important improving efficiency planning executing cosmic experiments,16,Internal operations:
270,Deep Learning Malware Analysis for reusable cyber defenses.,Idaho National Laboratory,Department of Energy,DOE,MACHINE LEARNING,"The INL uses machine learning (feed forward neural network) on a large 
data set of translated malware binaries in graph structures to identify 
commonality between malware.",inl uses machine learning feed forward neural network large data set translated malware binaries graph structures identify commonality malware,18,Service delivery:
271,Geo Threat Observable for structure cyber threat related to the energy sector,Idaho National Laboratory,Department of Energy,DOE,,"Collection of open source threat inforamtion related to cyber issues in 
the energy sector, collected stored in graphdb and used in machine 
learning for similarities of threat enabling better reuse of cyber 
protections.",collection open source threat inforamtion related cyber issues energy sector collected stored graphdb used machine learning similarities threat enabling better reuse cyber protections,18,Service Delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
272,"Advanced energy, batteries, and industrial efficiency",Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Leveraging data science to navigate design space for better batteries 
and energy storage as well as scale up of various technologies",leveraging data science navigate design space better batteries energy storage well scale various technologies,10,"""Asset management"""
273,"Advanced materials science, engineering, and exploration relevant to the other key technology focus areas",Lawrence Livermore National Laboratory,Department of Energy,DOE,MACHINE LEARNING,"Enabling machine learning based technology to specialized materials for 
superior performance for scientific research and manufacturing systems",enabling machine learning based technology specialized materials superior performance scientific research manufacturing systems,11,Asset management
274,AI/ML and other software advances,Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Model architecture development research, including workflows, 
algorithm and performance optimization",model architecture development research including workflows algorithm performance optimization,0,Service / benefits access
275,"Biology, genomics, and synthetic biology",Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Combining experimental and computational methods to perform 
fundamental and applied research in genomics, molecular toxicology, 
nanotechnology, hostâpathogen biology, structural biology, genetics, 
microbial systems, and medical countermeasures",combining experimental computational methods perform fundamental applied research genomics molecular toxicology nanotechnology biology structural biology genetics microbial systems medical countermeasures,12,Topic: Other
276,"Cyber security, data storage, and data management technologies",Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Data-processing pipelines and user interfaces to process and 
aggregate large, bulk, and possibly unstructured datasets allowing for 
search and export of data for further analysis in secure way",pipelines user interfaces process aggregate large bulk possibly unstructured datasets allowing search export data analysis secure way,18,"""Asset management: use of AI to manage both physical and digital assets"""
277,"High-performance computing, semiconductors, and advanced computer hardware",Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Novel computer hardware architecture/configurations that can perform 
at the edge and/or in harsh environments",novel computer hardware perform edge harsh environments,16,Asset management
278,"Innovation methods, processes and promising practices that can affect the speed and effectiveness of innovation processes at scale.",Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Computational approaches that lead to faster insights into the 
development and deployment of large scale operations",computational approaches lead faster insights development deployment large scale operations,18,Service Delivery
279,Natural and anthropogenic disaster prevention and mitigation,Lawrence Livermore National Laboratory,Department of Energy,DOE,,"Leveraging a broad, multimodal data stream to predict and understand 
natural disaster scenarios for the purposes of prevention and mitigation",leveraging broad multimodal data stream predict understand natural disaster scenarios purposes prevention mitigation,17,Service / benefits access
280,Quantum computing and information systems,Lawrence Livermore National Laboratory,Department of Energy,DOE,MACHINE LEARNING,"Machine learning and quantum computing applied towards optimization, 
quantum chemistry, material science, and cryptography",machine learning quantum computing applied towards optimization quantum chemistry material science cryptography,0,Service delivery
281,"Robotics, automation, and advanced manufacturing",Lawrence Livermore National Laboratory,Department of Energy,DOE,AI,"AI is being used for accelerating hardware development and 
interpretation of sensor data to improve process reliability",ai used accelerating hardware development interpretation sensor data improve process reliability,15,Service delivery
282,Advanced Image Segmentation,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","U-Net CNN segmentation to isolate pore and fluid from computed 
tomography scans of multiphase transport in cores.",cnn segmentation isolate pore fluid computed tomography scans multiphase transport cores,3,Service delivery
283,Advanced model to forecast offshore landslide risks and marine geohazards,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","This research will use data and models from the Offshore Risk Modeling 
(ORM) with intelligent databases, artificial intelligence (AI)/ML, big data, 
and other advanced computing technologies to address offshore 
subsurface natural-engineered system challenges, such as 
characterization and mapping of geologic hazards, safe operations, 
equipment reliability, and environmental assessments.",research use data models offshore risk modeling orm intelligent databases artificial intelligence ai big data advanced computing technologies address offshore subsurface system challenges characterization mapping geologic hazards safe operations equipment reliability environmental assessments,11,Service delivery
284,AI used to interpret sensor data.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"AI is being used to classify sensor data.  An AI algorithm was written 
and trained with a wide range of known sensor conditions to enable 
automatic classification of sensor data into likely constituent gas 
concentrations.",ai used classify sensor data ai algorithm written trained wide range known sensor conditions enable automatic classification sensor data likely constituent gas concentrations,15,"""Asset management"""
285,"AI/ML may be needed to extract data from text, image and tabular- based resources. NEWTS is partnering with university teams to use ML to fill in data gaps using predictive models.",National Energy Technology Laboratory,Department of Energy,DOE,"NATURAL LANGUAGE PROCESSING, OTHER","NEWTS data requirements and database structure needs will be 
established by reviewing datasets and literature on energy-water 
streams. Data sources will be identified from regulatory agencies, 
government monitoring programs, as well as open-source literature. 
Metadata of each source will be compiled into a data catalog for 
tracking and reference. Datasets, including high-quality composition 
data for relevant streams, will be collected and downloaded. Acquired 
data will be processed into a structured format based on the 
prioritization of datasets to be included in NEWTS. Data acquisition and 
processing might entail the application of ML (e.g., natural language 
processing) to efficiently resurrect data trapped in historical reports 
(e.g., PDFs) or other unstructured formats. One research product of this 
subtask will be a release of the data catalog, which will be made 
available on",newts data requirements database structure needs established reviewing datasets literature streams data sources identified regulatory agencies government monitoring programs well literature metadata source compiled data catalog tracking reference datasets including composition data relevant streams collected downloaded acquired data processed structured format based prioritization datasets included newts data acquisition processing might entail application ml natural language processing efficiently resurrect data trapped historical reports pdfs unstructured formats one research product subtask release data catalog made available,7,Topic: Asset management
286,AI/ML methodology for rapid design of sorbents tuned to specific ash impoundment and/or landfill requirements.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Computation of the descriptors (atomic property-weighted radial 
distribution functions) that will be used for the ML portion of the task; 
Fitting of a machine-learned model for the prediction of B sorption; 
Optimization and computational design of a sorbent for maximum 
sorption of B as a function of B concentration in the aqueous solution; 
Force field generation for an additional pollutant (if needed); Sorption 
calculations and ML fitting for the second pollutant (TBD); Optimization 
and computational design of a sorbent for maximum sorption of the 
second pollutant as a function of pollutant concentration in the aqueous 
solution.",computation descriptors atomic radial distribution functions used ml portion task fitting model prediction b sorption optimization computational design sorbent maximum sorption b function b concentration aqueous solution force field generation additional pollutant needed sorption calculations ml fitting second pollutant tbd optimization computational design sorbent maximum sorption second pollutant function pollutant concentration aqueous solution,0,Other
287,Analysis to Assess Offshore CCS Trends and Gaps,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Providing expertise, input, and support for the development of a DOE 
(NETL/FECM) carbon storage technical resources catalog that 
facilitates searching for information about datasets, models and tools, 
publications and reports, and competencies resulting from DOE-
FECM/NETLâs offshore and CSP activities.  this project will complete a 
review and analysis of knowledge and data resources resulting from 
international offshore CCS projects. Outcomes of this analysis are 
expected to include the integration of key data and tools into the EDX-
hosted Open Carbon Storage Database and DisCO2ver platform (in 
development via the EDX4CCS FWP), as well as geo-data science 
based analysis and recommendations on geologic and metocean 
insights from international studies and their alignment or relevance to 
U.S. Federal offshore settings.",providing expertise input support development doe carbon storage technical resources catalog facilitates searching information datasets models tools publications reports competencies resulting offshore csp activities project complete review analysis knowledge data resources resulting international offshore ccs projects outcomes analysis expected include integration key data tools hosted open carbon storage database platform development via fwp well science based analysis recommendations geologic metocean insights international studies alignment relevance federal offshore settings,17,Topic: Asset management
288,ANN Submodels of Reaction Physics,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,ANN development of flow physics for code acceleration,ann development flow physics code acceleration,16,Topic: Asset management
289,Computational capabilities to support experimental efforts,National Energy Technology Laboratory,Department of Energy,DOE,,"This subtask will leverage NETLâs in-house computational capabilities 
and existing university collaborators to support experimental efforts by 
providing atomic-level DFT and microkinetic modeling calculations for 
catalyst systems. This work provides atomic-level details on reaction 
energetics and establishes key structure-property relationships used to 
optimize catalyst structure and formulation.",subtask leverage computational capabilities existing university collaborators support experimental efforts providing dft microkinetic modeling calculations catalyst systems work provides details reaction energetics establishes key relationships used optimize catalyst structure formulation,17,Asset management: use of AI to manage both physical and digital assets
290,Computational methods for the characterization of CO2 chemisorption in amine- functionalized MOFs.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Databases of MOFs will be screened using computational methods to 
identify promising MOFs. Software will be further developed to allow for 
the addition of desirable functional groups (amines) to metal centers 
and/or ligands of MOFs. The team will calculate the reaction enthalpy for 
CO2 sorption in amine functionalized MOFs and further computational 
methods for the characterization of CO2 chemisorption in amine-
functionalized MOFs will be developed.",databases mofs screened using computational methods identify promising mofs software developed allow addition desirable functional groups amines metal centers ligands mofs team calculate reaction enthalpy sorption amine functionalized mofs computational methods characterization chemisorption functionalized mofs developed,3,Asset management
291,Creation of polymer datasets and inverse design of polymers with targeted backbones having High CO2 permeability and high CO2/N2 selectivity.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Machine learning models were developed to predict CO2 permeability 
and CO2/N2 selectivity of polymers. Novel methods were developed to 
generate polymer datasets. Furthermore, a novel machine learning 
technique is being developed to inverse design the polymers that will 
have targeted properties.",machine learning models developed predict permeability selectivity polymers novel methods developed generate polymer datasets furthermore novel machine learning technique developed inverse design polymers targeted properties,1,Asset management
292,"Data discovery, processing, and generation using machine learning for a range of CCS data and information",National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","The team will focus on supporting ongoing geospatial data collection 
and publishing efforts leveraging the new EDX++ cloud computer 
capabilities through ArcGIS Enterprise Portal. The use of Arc Enterprise 
Portal will support the development of the Carbon Matchmaker tool, as 
well as support the release of a new version of GeoCube, which will be 
host to the updated Carbon Storage Open Database and NATCARB 
completed in EY21. NETL is supporting DOE-FECM in developing and 
releasing a survey and map for the Carbon Matchmaker, a tool 
developed to enable stakeholders to self-identify carbon dioxide related 
activities (production, utilization, storage, direct air capture, and 
infrastructure/transportation) to identify and connect stakeholders and 
support national collaborative opportunities. The ArcGIS Enterprise 
Portal will be leveraged to build out a new version of GeoCube with the 
migration of hundreds of spatial data layers into the new platform. The 
migration of data to an Arc Enterprise based GeoCube will enable 
easier version control for data integration and curation.",team focus supporting ongoing geospatial data collection publishing efforts leveraging new cloud computer capabilities arcgis enterprise portal use arc enterprise portal support development carbon matchmaker tool well support release new version geocube host updated carbon storage open database natcarb completed netl supporting developing releasing survey map carbon matchmaker tool developed enable stakeholders carbon dioxide related activities production utilization storage direct air capture identify connect stakeholders support national collaborative opportunities arcgis enterprise portal leveraged build new version geocube migration hundreds spatial data layers new platform migration data arc enterprise based geocube enable easier version control data integration curation,17,Topic: Asset management
293,"Data platform to expedite access and reuse of carbon ore data for materials, manufacturing and research",National Energy Technology Laboratory,Department of Energy,DOE,"NATURAL LANGUAGE PROCESSING, OTHER","Data platform to expedite access and reuse of carbon ore data for 
materials, manufacturing and research.  Assembled using data science, 
NLP methods, and hosted in virtual, multi-cloud platform for online 
analytics.",data platform expedite access reuse carbon ore data materials manufacturing research assembled using data science nlp methods hosted virtual platform online analytics,7,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
294,Database will be utilized to demonstrate targeted biocide strategies using AI to assess large DNA datasets.,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","The team will develop a public DNA database that will advance 
knowledge in produced water management. This project consists of two 
phases: (1) the development and launching of the database, and (2) the 
demonstration of applicability of the database by conducting a network 
analysis. The work will be pursued as defined in the phases below. The 
fully characterized streams will be used by other FWPs to estimate 
overall resource recovery and will be used by other FWPs as training 
set for machine learning (ML) models to predict compositions when only 
limited measurements can or have been completed for the produced 
water.",team develop public dna database advance knowledge produced water management project consists two phases development launching database demonstration applicability database conducting network analysis work pursued defined phases fully characterized streams used fwps estimate overall resource recovery used fwps training set machine learning ml models predict compositions limited measurements completed produced water,3,Asset management: use of AI to manage both physical and digital assets
295,Demonstrate how ML-based approaches can help operators during active injection and post- injection monitoring,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"To demonstrate how ML-based approaches can help operators during 
active injection and post-injection monitoring, it is necessary to 
understand their needs and identify how ML-based approaches can 
potentially meet or support those needs. Task 4 will establish data-
sharing protocols between SMART and the operator to create an 
exchange mechanism that is not intrusive to the operator and provides 
updates from ML results designed to enhance the operator decision 
process. Demonstrate application of ML-based approaches to improve 
site-monitoring and operations efforts performed during injection and 
post-injection phases, e.g., using IL-ICCS data, and developing value of 
information guidelines.",demonstrate approaches help operators active injection monitoring necessary understand needs identify approaches potentially meet support needs task establish sharing protocols smart operator create exchange mechanism intrusive operator provides updates ml results designed enhance operator decision process demonstrate application approaches improve operations efforts performed injection phases using data developing value information guidelines,7,Service / benefits access
296,Demonstrate the robust performance of our ML method in a commercial-scale synthetic data and integrate image-to-image mapping with convolutional neural networks,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","Our method quickly incorporates streaming observations for accurate 
and timely forecasts with uncertainty quantification, taking reservoir 
simulation data as inputs and incorporating real-time observation 
streams for accurate, timely geological carbon storage forecasts.
Computation effort is distributed over many machines, facilitates 
coupled inversions using many ML models, and allows for ML-Driven 
optimization and sensitivity analysis",method quickly incorporates streaming observations accurate timely forecasts uncertainty quantification taking reservoir simulation data inputs incorporating observation streams accurate timely geological carbon storage forecasts computation effort distributed many machines facilitates coupled inversions using many ml models allows optimization sensitivity analysis,5,Service / benefits access
297,Develop and demonstrate reinforcement learning approach for time-varying control for flexible hydrogen and power production.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Efforts on IES control will include the development of a dynamic 
optimization-based nonlinear model predictive control (NMPC) 
framework. NMPC approaches for optimizing cell thermal management 
and maximizing IES efficiency under set-point transition will be 
developed for flexible operation. Reinforcement learning (RL) 
approaches will also be developed for optimal control policy selection 
and learning-based adaptive control. There are opportunities for 
improved learning through interaction with the electrolyzer in addition to 
learning from the MPC action. Multi-policy approaches will be developed 
for control, independently by RL or in concert with MPC, or even for 
scheduling the operating policy.  The ultimate goal is to develop 
operational strategies and an NMPC and RL control framework for 
optimizing IES performance under flexible hydrogen and power 
production scenarios, while minimizing physical and chemical 
degradation over long-term operation.",efforts ies control include development dynamic nonlinear model predictive control nmpc framework nmpc approaches optimizing cell thermal management maximizing ies efficiency transition developed flexible operation reinforcement learning rl approaches also developed optimal control policy selection adaptive control opportunities improved learning interaction electrolyzer addition learning mpc action approaches developed control independently rl concert mpc even scheduling operating policy ultimate goal develop operational strategies nmpc rl control framework optimizing ies performance flexible hydrogen power production scenarios minimizing physical chemical degradation operation,19,Topic: Asset management
298,Develop fast predictive models using novel machine-learning based methods.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Accurate, fast predictive ML models form the foundation for the virtual 
learning platform. Generating training data then developing ML based 
models enables a Virtual Learning Environment (VLE) for exploring and 
testing strategies to optimize reservoir development, management & 
monitoring prior to field activities.",accurate fast predictive ml models form foundation virtual learning platform generating training data developing ml based models enables virtual learning environment vle exploring testing strategies optimize reservoir development management monitoring prior field activities,7,Service delivery
299,"Develop, integrate, and automate the reduction of CFD models while preserving acceptable levels of accuracy. In general for CCSI2, this work intends to focuse on CFD applications.",National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","Will leverage state-of-the-art, physics-based deep learning (DL) models 
to learn generalizable surrogates that may be used in place of CFD 
models to predict quantities required for downstream optimization. The 
products from this subtask can be immediately leveraged by other 
subtasks that are seeking to speed up their CFD simulation models to 
streamline their downstream analyses. Addtionally, improvements to the 
ML/AI interface in FOQUS. Includes support for vector variables in the 
ML/AI plugin and support for additional surrogate model tools (e.g., 
PyTorch, Sci-kit Learn) and additional normalization function forms in 
the ML/AI plugin.",leverage deep learning dl models learn generalizable surrogates may used place cfd models predict quantities required downstream optimization products subtask immediately leveraged subtasks seeking speed cfd simulation models streamline downstream analyses addtionally improvements interface foqus includes support vector variables plugin support additional surrogate model tools pytorch learn additional normalization function forms plugin,0,Asset management
300,Development of AI/ML methods,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Develop quality, reliability, and version control standards for SMART 
software. Continue development of AI/ML methods for use by the 2A 
and 2C activities, including Modeling anomalies due to local 
heterogeneity coupled with an enhanced capacitance-resistance model 
(CRM) and Bayesian Belief Network (BBN) modeling integrated with 
geochemistry. Continue development of advanced computational 
approaches with modeling using the most advanced general purpose 
PDE/ODE physics-informed neural network (PINN) tool developed by 
NVIDIA and accelerate training PINNs using Wafer Scale Engine (WSE) 
by Cerebras Systems Inc.",develop quality reliability version control standards smart software continue development methods use activities including modeling anomalies due local heterogeneity coupled enhanced model crm bayesian belief network bbn modeling integrated geochemistry continue development advanced computational approaches modeling using advanced general purpose neural network pinn tool developed nvidia accelerate training pinns using wafer scale engine wse cerebras systems inc,19,Asset management
301,"Development of new machine learning-based process modeling capabilities that assess the viability and efficiency, with uncertainty quantification, of the chemical processes involved in the carbon fiber production and its output quality",National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Provide sub-pilot-scale verification of lab-scale developments on the 
production of isotropic and mesophase coal-tar pitch (CTP) for carbon 
fiber production, using coals from several U.S. coal-producing regions. 
An extensive database and suite of tools for data analysis and economic 
modeling, with an associated web-based community portal, will be 
developed to relate process conditions to product quality, and to assess 
the economic viability of coals from different regions for producing 
specific high-value products.",provide verification developments production isotropic mesophase pitch ctp carbon fiber production using coals several regions extensive database suite tools data analysis economic modeling associated community portal developed relate process conditions product quality assess economic viability coals different regions producing specific products,5,Asset management
302,DOE AI Data Infrastructure System,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, OTHER","Leveraging generative AI and cloud enabled data infrastructure to 
improve CCS user experience and connectivity producing an adaptive 
user interface that streamlines connection of CCS stakeholders to what 
matters to them.",leveraging generative ai cloud enabled data infrastructure improve ccs user experience connectivity producing adaptive user interface streamlines connection ccs stakeholders matters,6,Service / benefits access
303,Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, OTHER","This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.",project develop ml algorithm predict time growing fracture reach monitored well ml workflow trained distinctive tensile strain signature precedes growing fracture new workflow designed work conjunction fracture warning ml workflow developed together workflows provide early warning well communication predict measured depths communication happen provide estimated time beginning communication,18,Asset management
304,Geochemically Informed Leak Detection (GILD),National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, OTHER","A Bayesian Belief Network has been developed to interogate the altered 
geochemistry around a potential CO2 leakage site. The use of the BNN 
and site specific parameters will reduce the percentage of false 
positives with this method.",bayesian belief network developed interogate altered geochemistry around potential leakage site use bnn site specific parameters reduce percentage false positives method,17,Topic: Asset management
305,"Initial case study using regulatory compliance (well integrity testing, fluid compositionali data, geographic, and geologic information from oil and gas wells in the Wattenberg Field, Denver Basin, central Colorado, USA",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Researchers will apply artificial intelligence/machine learning (AI/ML) 
techniques to national-scale well characterization and integrity test 
datasets to yield new insights into leakage potential.",researchers apply artificial learning techniques well characterization integrity test datasets yield new insights leakage potential,17,Service delivery
306,Machine learning based identification of current hazardous offshore metocean and bathymetric conditions that can impact safe offshore energy operations,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NEURAL NETWORKS, OTHER","Build off user testing and further refine analytical logic to develop 
Version 2 of the OGA smart tool for release on EDX. Continue 
refinements to offshore hazard models, including wave and turbidity 
current models. Draft manuscripts detailing the OGA Tool models and 
algorithms. Assemble a metocean and seafloor database for release 
with the OGA Tool Version 2 online; strategize web-hosted versions of 
the OGA Tool and database.",build user testing refine analytical logic develop version oga smart tool release edx continue refinements offshore hazard models including wave turbidity current models draft manuscripts detailing oga tool models algorithms assemble metocean seafloor database release oga tool version online strategize versions oga tool database,9,Service delivery
307,Machine Learning for geophysical data inversion,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Use machine learning to generate synthetic seismic and gravity data, 
and data driven inversion for leak detection",use machine learning generate synthetic seismic gravity data data driven inversion leak detection,11,Topic 8: Service delivery
308,Machine learning for legacy well evaluation,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Use machine learning to identify common attributes that correlated to 
well integrity issues to prioritize for monitoring and remediation.",use machine learning identify common attributes correlated well integrity issues prioritize monitoring remediation,6,"""Program integrity"""
309,Machine learning to process multi- model data and information to aid in the identification of undocumented orphaned wells,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Use of machine learning to process and analyze trends and patterns in 
known well data to predict undocuemnted orphaned wells, as well as 
machine learning approached to process different imagery based data 
to further classify and characterize additional undocuemented orphaned 
wells within the Appalachain Basin",use machine learning process analyze trends patterns known well data predict undocuemnted orphaned wells well machine learning approached process different imagery based data classify characterize additional undocuemented orphaned wells within appalachain basin,15,"""Asset management"""
310,Machine learning to refine and analyze data for CCS needs,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Utilze and apply different machine learning approaches to process data 
and generate new derivative data products that help address CCS 
stakeholder data-needs for resource evaluation, risk assessment, 
supply chain, social and environmental justice evaluations, regulatory 
compliance, and more.",utilze apply different machine learning approaches process data generate new derivative data products help address ccs stakeholder resource evaluation risk assessment supply chain social environmental justice evaluations regulatory compliance,17,Service delivery
311,Machine learning to tool and model applications for CCS needs,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Utilze and apply different machine learning approaches to help model 
and analyze Class VI well regulatation data, CCS infrastructure 
optimization, CCS data visualization, and interaction with âreally bigâ 
(petabyte-scale) datasets used for CCS resource characterization and 
risk reduction (e.g., reflection seismic surveys) within the EDX multi-
cloud ecosystem.",utilze apply different machine learning approaches help model analyze class vi well regulatation data ccs infrastructure optimization ccs data visualization interaction datasets used ccs resource characterization risk reduction reflection seismic surveys within edx cloud ecosystem,7,Asset management
312,ML-based approaches to improve site characterization efforts,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Demonstrate application of ML-based approaches to improve site-
characterization efforts performed during the pre-injection phase using 
data from either IBDP (for which data are currently available) or other 
opportunistic field demonstration or commercial projects (for which data 
may become available) and develop value of information guidelines. 
Demonstrate how ML-based rapid forecasting can be used to help with 
pre-injection reservoir management decisions under data uncertainties. 
Demonstrate how a visualization platform with ML-based models can",demonstrate application approaches improve characterization efforts performed phase using data either ibdp data currently available opportunistic field demonstration commercial projects data may become available develop value information guidelines demonstrate rapid forecasting used help reservoir management decisions data uncertainties demonstrate visualization platform models,7,Topic: Asset management
313,ML-based proxy models and multi- level data driven fracture network imaging to support rapid decision making.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"ML-based proxy-models of fracture network, HF geometry, HF 
properties, bottomhole pressure and drainage volume contribute to 
fracture network, production forecast and well drainage volume 
visualizations.",fracture network hf geometry hf properties bottomhole pressure drainage volume contribute fracture network production forecast well drainage volume visualizations,5,Asset management
314,"ML-based reduced order models of reservoir response to Co2 injection into saline and/or hydrocarbon- bearing formations - as the basis for integrated assessment modeling of leakage risk (e.g., SACROC)",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Generally, the approach used by NRAP researchers to address these 
questions is to develop a robust, science-based integrated assessment 
framework that links fast forecasting models of CO2 storage system 
components (e.g., storage reservoir; leakage pathways including wells, 
faults, and fractured caprock; intermediate formations; and receptors of 
concern, including groundwater aquifers and the atmosphere). 
Superimposed on this system model are various fit-for-purpose 
analytical capabilities that support analyses in support of stakeholder 
decision making for questions related to site-specific risk evolution, risk-
based area of review delineation, conformance assessment, and post-
injection site monitoring
In Task 2.0, researchers will augment and expand this functionality to 
demonstrate relevance to industry-standard site risk management 
methods (i.e., bowtie analysis framework) and to understand 
containment performance and leakage risk for scenarios where a site 
transitions from CO2 utilization for EOR to dedicated CO2 storage. To 
ensure that risk assessment efforts are informative to real geologic 
storage deployment scenarios, NRAP researchers will engage with a 
diverse set of stakeholders to establish an appropriate modeling and 
risk assessment design basis.",generally approach used nrap researchers address questions develop robust integrated assessment framework links fast forecasting models storage system components storage reservoir leakage pathways including wells faults fractured caprock intermediate formations receptors concern including groundwater aquifers atmosphere superimposed system model various analytical capabilities support analyses support stakeholder decision making questions related risk evolution based area review delineation conformance assessment injection site monitoring task researchers augment expand functionality demonstrate relevance site risk management methods bowtie analysis framework understand containment performance leakage risk scenarios site transitions utilization eor dedicated storage ensure risk assessment efforts informative real geologic storage deployment scenarios nrap researchers engage diverse set stakeholders establish appropriate modeling risk assessment design basis,17,Topic: Asset management
315,Natural Language Processing,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","Information and articles on energy storage will be gathered and 
reviewed. Developed natural language processing (NLP) algorithms will 
be used to help categorize and understand various energy storage 
efforts in the R&D communities. Additionally, trends within the 
discovered and selected topical focus areas in energy storage will be 
examined. This will provide a view of energy storage R&D, which is not 
biased or limited to known search terms.",information articles energy storage gathered reviewed developed natural language processing nlp algorithms used help categorize understand various energy storage efforts r communities additionally trends within discovered selected topical focus areas energy storage examined provide view energy storage r biased limited known search terms,10,Service delivery
316,Neural networks used to compensate a drone-mounted magnetic sensor for maneuvering of the drone.,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","Electromagnetic technology development and optimization for cased 
wells. Scalable solutionsâgetting to 100,000 wells/year through drone 
technology and ML technology. NETL will develop ML algorithms to 
compensate magnetic data for the maneuvering of drone aircraft. 
Magnetic noise can limit sensitivity of detection and resolution of 
anomalies in the magnetic data. The ML algorithms will reduce attitude- 
and heading-induced noise in drone magnetic surveys.",electromagnetic technology development optimization cased wells scalable drone technology ml technology netl develop ml algorithms compensate magnetic data maneuvering drone aircraft magnetic noise limit sensitivity detection resolution anomalies magnetic data ml algorithms reduce noise drone magnetic surveys,18,Asset management
317,Online real time system Identification,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, OTHER","Work will focus on using SI to monitor the condition of a power plant 
boiler at different process states. SI algorithms will be implemented 
within an MPC to provide continuous adaptability as the power plant 
ramps through the entire range of operating loads. Once the control 
algorithm has been developed to be effective on representative models, 
it will be tested on a high-fidelity commercial power plant simulator or on 
a real power plant facility. The online SI techniques will be tested on 
historical power plant data, dynamic models (including a power plant 
simulator), power generating equipment including laboratory pilot-scale 
power systems, and on power plants where feasible.",work focus using si monitor condition power plant boiler different process states si algorithms implemented within mpc provide continuous adaptability power plant ramps entire range operating loads control algorithm developed effective representative models tested commercial power plant simulator real power plant facility online si techniques tested historical power plant data dynamic models including power plant simulator power generating equipment including laboratory power systems power plants feasible,3,Asset management
318,Prediction of gasification gas yield and compositions using machine learning,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","A machine learning (ML) model will be developed to aid in investigating 
and optimizing of gasification with various feedstocks like waste plastic, 
waste coal, biomass and MSW. Database on the gasification will be 
built from main resources of literature, prior experiments in NETL, and 
new generating experiments in NETL. Al/ML will be a part of the project. 
It combines with experimental study to accelerate development of 
gasification applying to variour feedstocks including waste plastics, 
waste coal, MSW and its mixture. The ML will have more impact as the 
big database will be built.",machine learning ml model developed aid investigating optimizing gasification various feedstocks like waste plastic waste coal biomass msw database gasification built main resources literature prior experiments netl new generating experiments netl part project combines experimental study accelerate development gasification applying variour feedstocks including waste plastics waste coal msw mixture ml impact big database built,16,Topic: Asset management
319,Reduce computational cost of CFD simulations that screen for more efficient intensified solvent contactor geometries.,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","Collaborate with Subtask 4.3 Machine Learning Support to reduce the 
computational complexity of validated CFD calculations using Deeper 
Fluids (DF), graph neural networks (GNNs), or similar ML approaches. 
Further development of ongoing process modeling/optimization 
ultimately informed by the CFD reduced order models (ROM) will also 
be a focus.",collaborate subtask machine learning support reduce computational complexity validated cfd calculations using deeper fluids df graph neural networks gnns similar ml approaches development ongoing process ultimately informed cfd reduced order models rom also focus,12,Topic: Asset Management
320,Rokbase Geologic Core Data Tool,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","This project will develop the platform through which the DOE OGFL data 
are easily accessible, searchable, and described, enabling future R&D, 
sustainable resource planning, and responsible stewardship of the 
teamâs national resources. NETLâs expertise in developing geo-data 
science, ML, visualization, online data mining and integration, and 
advanced analytics through scientific computing (including high 
performance computing and big data computing methods) and 
virtualized environments can be leveraged to support further intelligent 
analytics for offshore systems.",project develop platform doe ogfl data easily accessible searchable described enabling future r sustainable resource planning responsible stewardship national resources expertise developing science ml visualization online data mining integration advanced analytics scientific computing including high performance computing big data computing methods virtualized environments leveraged support intelligent analytics offshore systems,7,Asset management: use of AI to manage both physical and digital assets
321,Solving Field Equations on the Wafer Scale Engine,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","The intent is to develop a collocated, finite volume code to allow 
maximum mesh flexibility and support advanced CFD capabilities found 
in modern CFD codes like Fluent, OpenFOAM, and MFiX.
NETL will take a metered approach to development towards a fully 
reacting CFD capability on the WSE. EY22 will be filled with API 
capability expansions needed to support general purpose CFD 
applications, such as general purpose finite volume formulations, 
collocated grid capabilities (Rhie & Chow Interpolation), bit stuffing to 
save memory when dealing with cell types, general purpose boundary 
conditions, etc. In addition, the code will be benchmarked in a series of 
tests towards a fully reacting CFD capability that will support problems 
of interest to FECM.",intent develop collocated finite volume code allow maximum mesh flexibility support advanced cfd capabilities found modern cfd codes like fluent openfoam mfix netl take metered approach development towards fully reacting cfd capability wse filled api capability expansions needed support general purpose cfd applications general purpose finite volume formulations collocated grid capabilities rhie chow interpolation bit stuffing save memory dealing cell types general purpose boundary conditions etc addition code benchmarked series tests towards fully reacting cfd capability support problems interest fecm,17,Asset management
322,To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system,National Energy Technology Laboratory,Department of Energy,DOE,BIG DATA,"Commercially available models will be used to generate predictive 
scenarios",commercially available models used generate predictive scenarios,7,Service / benefits access
323,"To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies",National Energy Technology Laboratory,Department of Energy,DOE,BIG DATA,"Commercially available models will be used to generate predictive 
scenarios",commercially available models used generate predictive scenarios,7,"""Program integrity"""
324,To accelerate discovery of protection system and laser processing of protective coatings on CMC for hydrogen turbines.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The objectives of this project are to design, process, and validate a 
laser-manufactured, integrated, and graded bond coat-environmental 
barrier coat-thermal barrier coat (BC-EBC-TBC) system that can 
effectively protect and lead to the use of Silicon Carbide fiber/Silicon 
Carbide (SiCf/SiC) matrix CMCs in next-generation hydrogen-fueled 
turbines.",objectives project design process validate integrated graded bond barrier barrier coat system effectively protect lead use silicon carbide carbide matrix cmcs turbines,0,Asset management:
325,To accurately predict alloy & component performance extrapolated to conditions where experimental results to do not exist.,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","AI/ML will be used to  interrogate databases comprised of  experimental 
data,  literature data,  and  synthetic data generated improved physics 
based models  to generate reduced order models to accurate predict 
materials the performance of materials and components under extreme 
environments (temperature, atmosphere) and complex loading (cyclical, 
triaxial) for long service life durations.",used interrogate databases comprised experimental data literature data synthetic data generated improved physics based models generate reduced order models accurate predict materials performance materials components extreme environments temperature atmosphere complex loading cyclical triaxial long service life durations,7,Asset management
326,To analyze data and derive insights and improve predictions to forecast wellbore kick events to reduce loss of control events.,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","Use of neural networks and/or AI cluster data analysis methods to 
improve detection and forecasting of wellbore and drilling related loss of 
control events, known as kicks, to imrpove real-time detection and 
prediction of these conditions.",use neural networks ai cluster data analysis methods improve detection forecasting wellbore drilling related loss control events known kicks imrpove detection prediction conditions,12,Asset management
327,"To apply machine learning applications to map carbon ore, rare earth element, and critical mineral resources",National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"To identify information gaps, GIS and machine learning applications will 
be used to map carbon ore, rare earth element, and critical mineral 
resource infrastructure, and market data in consultation with NETL 
geospatial modeling activities. Research needs and technology gaps will 
be assessed, and resources targeted for sampling and characterization. 
This effort will provide a complete Northern Appalachian carbon ore, 
rare earth element, and critical mineral value chain basinal assessment 
to enable quick development of commercial projects.",identify information gaps gis machine learning applications used map carbon ore rare earth element critical mineral resource infrastructure market data consultation netl geospatial modeling activities research needs technology gaps assessed resources targeted sampling characterization effort provide complete northern appalachian carbon ore rare earth element critical mineral value chain basinal assessment enable quick development commercial projects,7,Topic 8: Service delivery
328,To apply machine learning and data analytics techniques to integrated subsurface datasets to predict key reservoir properties and compare various fields across the area of study and to correlate vintage data with new data and address the distribution of fractures and vugs.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA","Laboratory experiments will be used to optimize a CO2 flood 
composition specific to HTD rock properties, and subsequently design 
and simulate injection scenarios that offer wettability alteration, foaming, 
and reduced surface tension. This work will improve oil recovery from 
matrix porosity and mitigate the impact of fracture zones. The optimized 
design will be implemented and tested in a Trenton/Black River field. 
The results will provide strategies to improve oil recovery in complex 
carbonate formations in the Michigan Basin as well as in other 
carbonate plays.",laboratory experiments used optimize flood composition specific htd rock properties subsequently design simulate injection scenarios offer wettability alteration foaming reduced surface tension work improve oil recovery matrix porosity mitigate impact fracture zones optimized design implemented tested river field results provide strategies improve oil recovery complex carbonate formations michigan basin well carbonate plays,17,Asset management
329,To apply machine learning methods to explore the inter-well uncertainty in the Goldsmith Landreth San Andres Unit and to update reservoir models.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Engineered water can lower interfacial tension and minimize capillary 
forces that gravity can push the oil up and out of the matrix. This 
proposal is to test this technology in the field scale, in Goldsmith 
Landreth San Andres Unit. Apply history matching of flexible interface-
based reservoir models and ML methods such as generative 
adversarial networks that provide new methods to explore the inter-well 
uncertainty and to update the reservoir models.",engineered water lower interfacial tension minimize capillary forces gravity push oil matrix proposal test technology field scale goldsmith landreth san andres unit apply history matching flexible based reservoir models ml methods generative adversarial networks provide new methods explore uncertainty update reservoir models,7,Asset management
330,To automate development of proxy models for power generation combustion systems.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Detailed CFD of large combustion systems will be performed.   From 
the results, machine learning will be used to develop fast proxy models 
which can will provide results close to the CFD results, but in a small 
fraction of the time.   These fast models will then be used in real-time 
digital twin models of the power plant, which can be used to help the 
power plant operator to spot instrumentation failures or cyberattacks on 
the plant.",detailed cfd large combustion systems performed results machine learning used develop fast proxy models provide results close cfd results small fraction time fast models used digital twin models power plant used help power plant operator spot instrumentation failures cyberattacks plant,3,"""Asset management"""
331,"To automate RDE image analysis, machine learning for RDE image analysis is being employed.",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The expected outcome of this project will be extensive experimental 
data that can provide valuable insight in RDC design, coupling RDC with 
turbomachinery, model validation, and next generation combustion 
sensors that use artificial intelligence and computer vision.         Design 
of an optimized inlet to maximize pressure gain in an RDE relies on an 
understanding of the coupling between the inlet plenums (fuel and air), 
the combustor annular channel, and the exhaust diffusor. This creates a 
challenge for CFD as the models are significant and computationally 
expensive. NETL is continuing a collaboration with the University of 
Michigan to accelerate reacting flow CFD modeling using machine 
learning (ML).",expected outcome project extensive experimental data provide valuable insight rdc design coupling rdc turbomachinery model validation next generation combustion sensors use artificial intelligence computer vision design optimized inlet maximize pressure gain rde relies understanding coupling inlet plenums fuel air combustor annular channel exhaust diffusor creates challenge cfd models significant computationally expensive netl continuing collaboration university michigan accelerate reacting flow cfd modeling using machine learning ml,0,Topic: Internal operations
332,"To build the first data analytics and artificial intelligence field laboratory for unconventional resources in the Powder River Basin, focusing on optimization of hydraulic fracture stimulations through the use of multiple diagnostic technologies.",National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA","To establish a tight oil Field Laboratory in the Powder River Basin and 
accelerate the development of three major unconventional oil resources 
through detailed geologic characterization and improved geologic 
models leading to significant advances in well completion and fracture 
stimulation designs specific to these three formations. Utilize multi-
variate analysis to understand the interrelationship between completion 
and stimulation controls on well productivity.",establish tight oil field laboratory powder river basin accelerate development three major unconventional oil resources detailed geologic characterization improved geologic models leading significant advances well completion fracture stimulation designs specific three formations utilize variate analysis understand interrelationship completion stimulation controls well productivity,11,Asset management
333,To create a data-driven multiscale phytotechnology framework for identification and remediation of leached-metals-contaminated soil.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The project objectives are to integrate satellite remote sensing, machine 
learning and image processing, geological engineering models, and soil 
science and plant pathology to: 1) identify potential leaching of metals 
from coal ash impoundments (Phase I), and 2) propose locally 
adaptable phytoextraction approaches to remediate contaminated 
regions (Phase II).",project objectives integrate satellite remote sensing machine learning image processing geological engineering models soil science plant pathology identify potential leaching metals coal ash impoundments phase propose locally adaptable phytoextraction approaches remediate contaminated regions phase ii,3,Asset management
334,To create and apply machine learning algorithms to predict carbon dioxide enhanced oil revoery improvements with rich gas in the Bell Creek Field and other selected fields.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Create models with ML algorithms to predict CO2 EOR improvements 
with rich gas in the Bell Creek Field and other selected fields. The 
results of these models will be compared with the predictions of CMGâs 
reservoir simulations models.",create models ml algorithms predict eor improvements rich gas bell creek field selected fields results models compared predictions reservoir simulations models,7,"""Asset management"""
335,To create reduced order models for predicting long term performance degradation behavior of fuel cells and electrolyzers.,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Machine learning algorithms are being used to analyze large datasets of 
microstructural and perfromance degradation simulations of various 
electrode microstructres to develop reduced order models that can be 
used for long-term perfromance degradation predictions of large area 
fuel cell/electrolysis cells and cell stacks. The reduced order models can 
be used for dynamic simulations that can more accurately mimic the 
changing loading conditions of the modern grid.",machine learning algorithms used analyze large datasets microstructural perfromance degradation simulations various electrode microstructres develop reduced order models used perfromance degradation predictions large area fuel cells cell stacks reduced order models used dynamic simulations accurately mimic changing loading conditions modern grid,18,Asset management
336,To demonstrate multi-gamma based sensor technology for as-fired coal property measurement,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","Applying an advanced multigamma attenuation (MGA) sensor to 
accurately and precisely measure coal properties at the point of 
injection into burners.  
One research objective is to perform MGA testing and databases 
development for neural network developed fingerprinting of coal 
properties. This will include neural network refinement with MGA data 
and to upgrade Microbeamâs Combustion System Performance Indices 
(CSPI) â CoalTracker (CT) program with MGA-based neural network 
algorithms.",applying advanced multigamma attenuation mga sensor accurately precisely measure coal properties point injection burners one research objective perform mga testing databases development neural network developed fingerprinting coal properties include neural network refinement mga data upgrade combustion system performance indices cspi coaltracker ct program neural network algorithms,3,Asset management
337,To deploy dynamic neural network optimization to minimize heat rate during ramping for coal.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","The primary objective of the proposed work is to 1) deploy dynamic 
neural network optimization (D-NNO) to minimize heat rate during all 
phases of operation (ramping, low load, and high load) at a coal power 
plant. The project will build a high-fidelity, systems-level, dynamic model 
of the plant for a rapid prototyping environment for the D-NNO and to 
allow researchers to better understand the dynamic phenomena that 
occur during ramping and at various plant loads, and  Commercialize D-
NNO as a readily-available software application by working with an 
industry-proven software platform. The plant will be perturbed over time 
to allow machine learning (ML) models to be fitted to the plantâs 
response data.",primary objective proposed work deploy dynamic neural network optimization minimize heat rate phases operation ramping low load high load coal power plant project build dynamic model plant rapid prototyping environment allow researchers better understand dynamic phenomena occur ramping various plant loads commercialize nno software application working software platform plant perturbed time allow machine learning ml models fitted response data,3,Asset management
338,"To design, develop, and demonstrate an AI-integrated physics-based attack resilient proactive system.",National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Enable ""defense-in-depth"" cyber-physical system (CPS) security and 
resiliency for the distribution grid. The recipient will design, develop, and 
demonstrate a vendor-agonistic scalable Artificial Intelligence Integrated 
Attack-Resilient Proactive System (AI-ARPS) for utility distribution grid 
systems including advanced distribution management system (ADMS) 
and DER management system (DERMS) applications.",enable system cps security resiliency distribution grid recipient design develop demonstrate scalable artificial intelligence integrated proactive system utility distribution grid systems including advanced distribution management system adms der management system derms applications,7,Service delivery
339,"To design, proto-type and demonstrate a miniaturized implementation of a multi-process, high-spatial-resolution monitoring system for boiler condition management.",National Energy Technology Laboratory,Department of Energy,DOE,,"Project will develop control logic for automated control of bituminous 
coal-fired boiler. Plant operational data will be compared against 
monitoring data to determine when different sensor output from a 
miniaturized high temperature multi-process, high-spatial-resolution 
monitoring system signifies damaging conditions in that region of the 
boiler, and what operational changes can be made to eliminate the 
damaging condition. The control logic will be developed for automated 
control of soot-blowing and other boiler operations",project develop control logic automated control bituminous boiler plant operational data compared monitoring data determine different sensor output miniaturized high temperature monitoring system signifies damaging conditions region boiler operational changes made eliminate damaging condition control logic developed automated control boiler operations,19,Asset management
340,To detect leaks and creaks.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The relevant research has been focused on demonstrating applicability 
of novel machine learning based approaches to two major challenges 
associated with safe management of large-scale geologic CO2 storage 
operations, early detection of leaks (i.e., by detecting small leaks) and 
early detection of induced seismicity (i.e. by detecting small seismic 
signals).",relevant research focused demonstrating applicability novel machine learning based approaches two major challenges associated safe management geologic storage operations early detection leaks detecting small leaks early detection induced seismicity detecting small seismic signals,11,"Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
341,To develop 5G integrated edge computing platform for efficient component monitoring in coal-fired power plants,National Energy Technology Laboratory,Department of Energy,DOE,BIG DATA,"Develop an on-demand distributed edge computing platform to gather, 
process, and efficiently analyze the component health data in coal-fired 
power plants. Given that edge computing servers are closer to the field 
devices in modernized power plants, the efficiency of edge computing 
service with respect to dynamic orchestration, resource data collection, 
and health information monitoring will be investigated for timely detection 
of remote faults and to perform diagnosis.",develop distributed edge computing platform gather process efficiently analyze component health data power plants given edge computing servers closer field devices modernized power plants efficiency edge computing service respect dynamic orchestration resource data collection health information monitoring investigated timely detection remote faults perform diagnosis,3,Asset management
342,To develop a deep-learning Artificial Intelligence model for analysis of fundamental combustion characteristics,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","A deep-learning Artificial Intelligence model will be pursued for rapid 
analysis of detailed fundamental combustion characteristics that support 
the design and troubleshooting process of H2-containing fuel combustor 
development.",artificial intelligence model pursued rapid analysis detailed fundamental combustion characteristics support design troubleshooting process fuel combustor development,9,Asset management
343,To develop a general drag model for assemblies of non-spherical particles created with artificial neural networks,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","The project plans to develop a more accurate artificial neural network 
(ANN)-based method for modeling the momentum exchange in fluid-
solid multiphase mixtures to significantly improve the accuracy and 
reduce the uncertainty of multiphase numerical codes and, in particular, 
of MFiX, by developing and providing a general and accurate method for 
determining the drag coefficients of assemblies of non-spherical 
particles for wide ranges of Reynolds numbers, Stokes numbers, and 
fluid-solid properties and characteristics. The research team will achieve 
this goal by conducting numerical computations with a validated in-
house CFD code and using artificial intelligence methods to develop an 
ANN that will be implemented in TensorFlow and linked with the MFiX 
code.",project plans develop accurate artificial neural network ann method modeling momentum exchange solid multiphase mixtures significantly improve accuracy reduce uncertainty multiphase numerical codes particular mfix developing providing general accurate method determining drag coefficients assemblies particles wide ranges reynolds numbers stokes numbers properties characteristics research team achieve goal conducting numerical computations validated house cfd code using artificial intelligence methods develop ann implemented tensorflow linked mfix code,2,"""Other"""
344,"To develop a novel platform for secure data logging and processing in fossil fuel power generation systems using blockchain and machine learning to reduce down time for fossil energy power plants, limit reductions of power and reduce cost for repairs.",National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","Machine learning model development will consist of traditional machine 
learning and deep learning algorithms implementation for anomaly 
detection.  Machine learning server will be used to develop the 
traditional models using One-Class Support Vector Machine (SVM) and 
K-Mean Clustering and deep learning models using Recurrent Neural 
Network (RNN) and its various implementations like Long Short-Term 
Memory (LSTM), Gated Recurrent Unit (GRU), Generative Adversarial 
Network (GAN), and Autoencoders using the sensor data collected from 
secure sensor network.",machine learning model development consist traditional machine learning deep learning algorithms implementation anomaly detection machine learning server used develop traditional models using support vector machine svm clustering deep learning models using recurrent neural network rnn various implementations like long memory lstm gated recurrent unit gru generative adversarial network gan autoencoders using sensor data collected secure sensor network,15,Topic: 10. Internal operations
345,"To develop a wireless, distributed data acquisition and interpretation system foe seismic monitoring and carbon storage characterization.",National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Resensys plans to develop a wireless, distributed data acquisition and 
interpretation system tailored for monitoring and characterization of 
seismic activity at carbon storage sites.  The seismicity data collected in 
real time during the CO2 storage site characterization and sequestration 
processes combined with advanced signal processing and Artificial 
Intelligence and Machine Learning (AI/ML) methodologies provide an 
understanding of natural seismicity risks prior to any CO2 injection, prior 
to making large investments in developing the storage project.",resensys plans develop wireless distributed data acquisition interpretation system tailored monitoring characterization seismic activity carbon storage sites seismicity data collected real time storage site characterization sequestration processes combined advanced signal processing artificial intelligence machine learning methodologies provide understanding natural seismicity risks prior injection prior making large investments developing storage project,17,Asset management
346,To develop an AI-driven integrated autonomous robotic visual inspection (RVI) platform.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, ROBOTIC PROCESSING AUTOMATION (RPA)","The overall objective of the research is to develop an AI-driven 
integrated autonomous robotic visual inspection (RVI) platform that can 
perform real-time defect identification, dynamic path planning, and safe 
navigation in a closed-loop manner. The",overall objective research develop integrated autonomous robotic visual inspection rvi platform perform defect identification dynamic path planning safe navigation manner,3,Asset management
347,To develop an Artificial intelligence- based model for rotating detonation engine designs,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"An artificial intelligence-based model will be used to develop low-loss 
rotating detonation engine (RDE) designs for use in power generation 
using natural gas/syngas mixtures. The model formulation will enable full-
scale RDE calculations over 100-1000 detonation cycles.",artificial model used develop rotating detonation engine rde designs use power generation using natural mixtures model formulation enable scale rde calculations detonation cycles,1,Asset management
348,To develop and create an autonomous robotic inspection system.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, ROBOTIC PROCESSING AUTOMATION (RPA)","The goal of the project is to prevent negative environmental and 
socioeconomic impacts of coal waste (coal ash and tailings) by 
developing an aerial robot-enabled inspection and monitoring system of 
active and abandoned coal ash and tailings storage facilities. The first 
objective of this project is the development of a programmable drone, 
equipped with several complementary sensors, that will autonomously 
inspect several structures of a storage facility. The second objective of 
this project is to create artificial intelligence-based hazard detection 
algorithms that will use multispectral and georeferenced images (i.e., 
thermal and visual) and 3D Point Clouds data collected by an 
autonomous drone to detect hazards in the storage facility structure that 
would indicate uncontrolled leakage to the environment or lead to the 
potential failure of the structure.",goal project prevent negative environmental socioeconomic impacts coal waste coal ash tailings developing aerial inspection monitoring system active abandoned coal ash tailings storage facilities first objective project development programmable drone equipped several complementary sensors autonomously inspect several structures storage facility second objective project create artificial hazard detection algorithms use multispectral georeferenced images thermal visual point clouds data collected autonomous drone detect hazards storage facility structure would indicate uncontrolled leakage environment lead potential failure structure,17,Service delivery
349,To develop and demonstrate drone- based geophysical and remote- sensing technologies to quantify critical minerals (CM).,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, ROBOTIC PROCESSING AUTOMATION (RPA)","To develop and demonstrate drone-based geophysical and remote-
sensing technologies to quantify critical minerals (CM) in coal, coal 
related, unconventional and secondary sources or energy related waste 
streams. Drone-based geophysical surveys and remote sensing 
combined with artificial intelligence/machine learning (AI/ML) analytics 
for real-time integration and analytics has potential to transform 
characterization and monitoring for CM from conventional and 
secondary resources.",develop demonstrate geophysical sensing technologies quantify critical minerals cm coal coal related unconventional secondary sources energy related waste streams geophysical surveys remote sensing combined artificial learning analytics integration analytics potential transform characterization monitoring cm conventional secondary resources,7,Asset management
350,To develop and evaluate a general drag model for gas-solid flows via physics-informed deep machine learning,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","The project will evaluate the performance of several ANN algorithms for 
machine learning, pertinent to the deep neural network (DNN) 
algorithms. The DNN candidates will include random forest (RF), BPNN, 
XGBoost, and other supervised deep neural network algorithms. The 
best DNN algorithm will be identified by ranking of these algorithmsâ 
performance. The Recipient will integrate the deep learning ANN model 
(DNN model) into the multiphase flow simulation software MFiX-DEM, 
which is part of the NETLâs open source CFD suite of software MFiX. 
The DNN based drag model developed on TensorFlow will be 
implemented using NETLâs existing software links between MFiX and 
TensorFlow.",project evaluate performance several ann algorithms machine learning pertinent deep neural network dnn algorithms dnn candidates include random forest rf bpnn xgboost supervised deep neural network algorithms best dnn algorithm identified ranking performance recipient integrate deep learning ann model dnn model multiphase flow simulation software part open source cfd suite software mfix dnn based drag model developed tensorflow implemented using existing software links mfix tensorflow,3,"Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
351,To develop and validate sensor hardware and analytical algorithms to lower plant operating expenses for the pulverized coal utility boiler fleet,National Energy Technology Laboratory,Department of Energy,DOE,,"The objective is to develop and validate sensor hardware and analytical 
algorithms to lower plant operating expenses for the pulverized coal 
utility boiler fleet. The focus is on relatively inexpensive new âInternet of 
Thingsâ technologies to minimize capital investment. Three technologies 
will be explored for demonstration and full-scale testing in a coal-fired 
power plant. The first focuses on gas and steam temperature control 
issues at low load. The second uses sensors and analytic algorithms for 
monitoring coal pulverizer operation at lower loads to reduce the 
minimum firing capability of coal burners. The third investigates new 
sensors and advanced controls to better balance air and fuel at each 
burner enabling reduction in the minimum firing capability of coal 
burners.",objective develop validate sensor hardware analytical algorithms lower plant operating expenses pulverized coal utility boiler fleet focus relatively inexpensive new technologies minimize capital investment three technologies explored demonstration testing power plant first focuses gas steam temperature control issues low load second uses sensors analytic algorithms monitoring coal pulverizer operation lower loads reduce minimum firing capability coal burners third investigates new sensors advanced controls better balance air fuel burner enabling reduction minimum firing capability coal burners,3,Asset management
352,To develop artificial intelligence- enabled tools (ArtIT) for cyber hardening of power grids.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"To develop a novel resiliency framework for power grids by integrating 
different theories, such as closed-loop controls, security, agility, formal 
reasoning and synthesis, machine learning, and laboratory setup 
demonstration. The framework will provide enhanced resiliency to wide-
area control operations in cyberattacks.",develop novel resiliency framework power grids integrating different theories controls security agility formal reasoning synthesis machine learning laboratory setup demonstration framework provide enhanced resiliency area control operations cyberattacks,19,Service delivery
353,To develop drag models for non- spherical particles through machine learning,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","Produce comprehensive experimental and numerical datasets for gas-
solid flows in well-controlled settings to understand the aerodynamic 
drag of non-spherical particles in the dense regime. The datasets and 
the gained knowledge will train deep neural networks to formulate a 
general drag model for use directly in NETL MFiX-DEM module. This will 
help to advance the accuracy and prediction fidelity of the computational 
tools that will be used in designing and optimizing fluidized beds and 
chemical looping reactors",produce comprehensive experimental numerical datasets solid flows settings understand aerodynamic drag particles dense regime datasets gained knowledge train deep neural networks formulate general drag model use directly netl module help advance accuracy prediction fidelity computational tools used designing optimizing fluidized beds chemical looping reactors,12,Asset management
354,To develop high fidelity tools which run in near real time not only help in the field to guide and optimize complex operations but can be used as digital twins,National Energy Technology Laboratory,Department of Energy,DOE,BIG DATA,"To develop high fidelity tools which run in near real time not only help in 
the field to guide and optimize complex operations but can be used as 
digital twins for cyber security and cyber-physical modeling.",develop high fidelity tools run near real time help field guide optimize complex operations used digital twins cyber security modeling,8,Service delivery
355,To develop innovative biomonitoring and remediation of heavy metals using phytotechnologies.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The objective of the work is to utilize algal- and cyanobacterial-based 
phycotechnologies to address pervasive heavy metal contamination 
from coal combustion product (CCP) impoundments at the Savannah 
River Site. Novel bioindicators will be developed to gauge the potential 
for phytoremediation to restore legacy impoundment sites.",objective work utilize phycotechnologies address pervasive heavy metal contamination coal combustion product ccp impoundments savannah river site novel bioindicators developed gauge potential phytoremediation restore legacy impoundment sites,2,Topic: Asset management
356,To develop low cost conversion of coal to graphene,National Energy Technology Laboratory,Department of Energy,DOE,"NATURAL LANGUAGE PROCESSING, NEURAL NETWORKS","Demonstrate the techno-economical feasibility of a 250 ton/day 
manufacturing facility to convert coal to high-quality graphene. The core 
technology is based on flash joule heating (FJH) to convert various 
coals to graphene. Machine learning algorithms will map out the 
correlation of processing parameters with the final product (graphene 
yield, quality, dimensions).",demonstrate feasibility manufacturing facility convert coal graphene core technology based flash joule heating fjh convert various coals graphene machine learning algorithms map correlation processing parameters final product graphene yield quality dimensions,7,Asset management
357,"To drive insights on emissions from natural gas production, storage, and transmission to determine how best to reduce emissions",National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","AI/ML will be used to recognice patterns in well integrity records that 
could predict failure events",used recognice patterns well integrity records could predict failure events,1,"""Program integrity"""
358,To drive insights on environmental performance of the natural gas system to inform effective mitigation strategies,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Life Cycle Analysis models will be used to define and estimate 
environmental parameters/performance",life cycle analysis models used define estimate environmental,9,Asset management
359,To drive insights on pipeline maintenance and repair strategies to reduce incidents of pipeline leakage; support evaluation of use and reuse strategies,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","ML will be used to develop a pipeline risk assessment geospatial model 
and support evaluation of use and reuse opportunities.",ml used develop pipeline risk assessment geospatial model support evaluation use reuse opportunities,17,Asset management
360,To drive insights on water recovery from cooling tower plumes,National Energy Technology Laboratory,Department of Energy,DOE,,"Study of plume formation and collection on mechanical (induced) draft 
cooling towers, partly in a high-fidelity controlled environment and partly 
on a full-scale industrial cooling tower. It will start by building the needed 
laboratory setup and installing various sensors on the lab cooling tower. 
At the same time a computational fluid dynamics (CFD) model will be 
implemented to get precise full-scale plume models. Using the insights 
into power-plant plume characteristics the project will iterate on and 
experimentally test electrodes and collectors, which make up modular 
panels, on the lab cooling tower. What has been learned from the full-
scale plume modeling and sensor data analysis will then be applied to 
develop a design model to build the optimal collection apparatus for 
given working conditions",study plume formation collection mechanical induced draft cooling towers partly controlled environment partly industrial cooling tower start building needed laboratory setup installing various sensors lab cooling tower time computational fluid dynamics cfd model implemented get precise plume models using insights plume characteristics project iterate experimentally test electrodes collectors make modular panels lab cooling tower learned scale plume modeling sensor data analysis applied develop design model build optimal collection apparatus given working conditions,15,Topic: Asset management
361,To drive insights through data-driven predictive modeling to forecast the remaining lifespan and future risk of offshore production platforms.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS, OTHER","An Artificial Neural Network and Gradient Boosted Regression Tree 
were developed and applied to predict the remaining lifespan of 
production platforms. These big data-driven models resulted in 
predictions with scored accuracies of 95â97%.",artificial neural network gradient boosted regression tree developed applied predict remaining lifespan production platforms big models resulted predictions scored accuracies,5,Asset management
362,"To drive insights using machine learning-based dynamics, control, and health models and tools developed by NETL to gain valuable operational data, insights, and",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"ML will be used to develop dynamics, controls, and health models for 
operating power generation facilities",ml used develop dynamics controls health models operating power generation facilities,8,Service Delivery
363,To employ machine learning to study the dependence of electrochemical performance on microstructural details,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","With a significant number of images. The Recipient will build deep 
learning methods at the object detection stage using the Region Based 
Convolutional Neural Network (RCNN) or You Only Look Once (YOLO) 
class of algorithms, the heart of which is a deep learning image 
classifier. Deep learning algorithms will also be built using convolutional 
layers followed by residual layers to extract feature vector descriptors in 
the second stage. In the third and fourth stages of affinity and 
association, a recurrent neural network approach can be used to build a 
tracker. All of these approaches require a large training set that will 
enable sophisticated models to be built to handle the complexity of the 
application.
With a limited number of images. In the case that there is are a limited 
number of images, the Recipient will still be able to follow the processing 
pipeline. The recipient will determine a suitable approach, with 
concurrence from the project manager. Two potential approaches 
include:
â¢ Transfer learning: training the image classifier in the object detector on 
images of similar quality and appearance, and 
â¢ Match filtering: detection, feature extraction, and matching based on 
traditional image processing and computer vision techniques.",significant number images recipient build deep learning methods object detection stage using region based convolutional neural network rcnn look yolo class algorithms heart deep learning image classifier deep learning algorithms also built using convolutional layers followed residual layers extract feature vector descriptors second stage third fourth stages affinity association recurrent neural network approach used build tracker approaches require large training set enable sophisticated models built handle complexity application limited number images case limited number images recipient still able follow processing pipeline recipient determine suitable approach concurrence project manager two potential approaches include transfer learning training image classifier object detector images similar quality appearance match filtering detection feature extraction matching based traditional image processing computer vision techniques,11,Topic: Asset management
364,To enhance the SimCCS toolset to better account for existent infrastructure and to more broadly engage other user bases to improve toolset performance and applicability.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Continue development of the SimCCS toolset, which is utilized to 
determine optimal placement for CO2 pipeline rights of way (ROW) and 
infrastructure in a machine-learning driven methodology that that 
considers environmentally sensitive areas, Justice40 considerations, 
and utilization of existent infrastructure.",continue development simccs toolset utilized determine optimal placement pipeline rights way row infrastructure driven methodology considers environmentally sensitive areas considerations utilization existent infrastructure,5,Asset management
365,To evaluate current infrastructure throughout a study area and evaluating future infrastructure needs to accelerate the deployment of CCUS,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"One key task focuses on evaluating current infrastructure throughout the 
Initiative study area and evaluating future infrastructure needs to 
accelerate the deployment of CCUS. LANL will utilize its unique 
technologies for this project focusing on SimCCS, with a minor 
consulting role using NRAP and machine learning algorithms.",one key task focuses evaluating current infrastructure throughout initiative study area evaluating future infrastructure needs accelerate deployment ccus lanl utilize unique technologies project focusing simccs minor consulting role using nrap machine learning algorithms,16,Asset management
366,To expore and analtze hydrogen- fueled rotating detonation engines using advanced turbulent combustion modeling and high- fidelity simultion tools.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"(1) analysis of injector design effects on RDE parasitic combustion; (2) 
understanding the impact of RDE ignition mechanism and initial 
transients on the ensuing detonation wave behavior; (3) deployment and 
assessment of machine learning assisted turbulent combustion models 
for predictive and computationally-efficient RDE CFD simulations; and 
(4) development of a highly scalable high-order CFD modeling 
framework for scale-resolving simulations of full-scale RDEs and 
investigation of TCI and wall boundary layer effects.(1) analysis of 
injector design effects on RDE parasitic combustion; (2) understanding 
the impact of RDE ignition mechanism and initial transients on the 
ensuing detonation wave behavior; (3) deployment and assessment of 
machine learning assisted turbulent combustion models for predictive 
and computationally-efficient RDE CFD simulations; and (4) 
development of a highly scalable high-order CFD modeling framework 
for scale-resolving simulations of full-scale RDEs and investigation of 
TCI and wall boundary layer effects.",analysis injector design effects rde parasitic combustion understanding impact rde ignition mechanism initial transients ensuing detonation wave behavior deployment assessment machine learning assisted turbulent combustion models predictive rde cfd simulations development highly scalable cfd modeling framework simulations rdes investigation tci wall boundary layer effects analysis injector design effects rde parasitic combustion understanding impact rde ignition mechanism initial transients ensuing detonation wave behavior deployment assessment machine learning assisted turbulent combustion models predictive rde cfd simulations development highly scalable cfd modeling framework simulations rdes investigation tci wall boundary layer effects,17,Topic: 11. Other
367,To fill critical data gaps in big data analytics and machine learning applications to inform decision making and improve the ultimate recovery of unconventional oil and natural gas resources.,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA","Project will conduct numerical analysis of all-digital pressure sensing 
technology will be used to create a synthetic dataset with downhole 
pressure sensor readings for each stage and will be analyzed 
statistically with DA to integrate with software.",project conduct numerical analysis pressure sensing technology used create synthetic dataset downhole pressure sensor readings stage analyzed statistically da integrate software,15,Asset management
368,"To help automate data discovery and preparations to support a range of CS models, tools, and products",National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","AI & ML are used to help collect and process data from multipel sources 
to further integrate and characterize infromation to provide additional 
data and infromation to support a range of carbon storage work",ai ml used help collect process data multipel sources integrate characterize infromation provide additional data infromation support range carbon storage work,15,Service delivery
369,To help automate data integration and exploration for geologic core properties related information.,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","Using natural language processing, deep learning neural networks, and 
possibly tensor flow for image analytics.",using natural language processing deep learning neural networks possibly tensor flow image analytics,12,Service / benefits access
370,To identify and characterization REE- CM hot zones using machine learning-aided multi-physics.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Develop and field demonstrate a machine learning (ML)-aided multi-
physics approach for rapid identification and characterization of REE-
CM hot zones in mine tailings with a focus on coal and sulfide mine 
tailings or other processing or utilization byproducts, such as fly ash and 
refuse deposits.",develop field demonstrate machine learning ml physics approach rapid identification characterization cm hot zones mine tailings focus coal sulfide mine tailings processing utilization byproducts fly ash refuse deposits,7,Asset management
371,To implement boiler health monitoring using a hybrid first principles-artificial intelligence model,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Develop methodologies and algorithms to yield (1) a hybrid first-
principles artificial intelligence (AI) model of a PC boiler, (2) a physics-
based approach to material damage informed by ex-service component 
evaluation, and (3) an online health-monitoring framework that 
synergistically leverages the hybrid models and plant measurements to 
provide the spatial and temporal profile of key transport variables and 
characteristic measures for plant health.",develop methodologies algorithms yield hybrid principles artificial intelligence ai model pc boiler based approach material damage informed component evaluation online framework synergistically leverages hybrid models plant measurements provide spatial temporal profile key transport variables characteristic measures plant health,3,Topic: Asset management
372,To implement machine learning to predict aerodynamic and combustion characteristics in hydrogen turbine,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Design rules and reduced models will be formulated by combining high 
fidelity simulations of chemically reacting flow, stochastic modeling 
techniques, reduced modeling through machine learning and testing of 
injector configurations. These can be used in an industrial setting to 
predict the aerodynamic and combustion characteristics in hydrogen 
turbine combustors based upon which design decisions are made.",design rules reduced models formulated combining high fidelity simulations chemically reacting flow stochastic modeling techniques reduced modeling machine learning testing injector configurations used industrial setting predict aerodynamic combustion characteristics hydrogen turbine combustors based upon design decisions made,0,Asset management
373,To implement novel SSC-CCS sensing technology and associated condition-based monitoring (CBM) software for improved understanding of the boiler tube failure mechanisms,National Energy Technology Laboratory,Department of Energy,DOE,,"A preliminary condition-based monitoring (CBM) package with graphic 
user interface (GUI) will be developed. This CUI will allow the operators 
to view the current and historical signals of temperature profiles of the 
boiler tube at specific sensor locations. Combining the pre-existing 
conditions and the opinions from designers/operators/expertsâ 
experiences, the system will be integrated with EPRIâs Boiler Failure 
Reduction Program to provide assessments on the health conditions of 
the boiler tubes, warnings/diagnoses on potential failures and locations, 
and suggestions on maintenance locations and schedules.",preliminary monitoring cbm package graphic user interface gui developed cui allow operators view current historical signals temperature profiles boiler tube specific sensor locations combining conditions opinions experiences system integrated boiler failure reduction program provide assessments health conditions boiler tubes potential failures locations suggestions maintenance locations schedules,19,Asset management
374,To implement sensor-driven deep learning/artificial intelligence for power plant monitoring,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","Sensor-driven deep learning/artificial intelligence for intelligent health 
monitoring capabilities that occur at the sensor (embedded computing) 
or base station (edge computing). Will give power plant operators more 
prediction tools about scheduling maintenance. Focus is on a high-
priority in-situ boiler temperature measurement system that relies on 
chipless RFID technology and much-needed temperature, pressure, 
environmental, and water quality industrial sensors.",deep intelligence intelligent health monitoring capabilities occur sensor embedded computing base station edge computing give power plant operators prediction tools scheduling maintenance focus priority boiler temperature measurement system relies chipless rfid technology temperature pressure environmental water quality industrial sensors,19,Service delivery:
375,To implement unsupervised learning based interaction force model for nonspherical particles in incompressible flows,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS","Develop a neural network-based interaction (drag and lifting) force 
model. A database will be constructed of the interaction force between 
the non-spherical particles and the fluid phase based on the particle-
resolved direct numerical simulation (PR-DNS) with immersed boundary-
based lattice Boltzmann method (IB-LBM). An unsupervised learning 
method, i.e., variational auto-encoder (VAE), will be used to improve the 
diversity of the non-spherical particle library and to extract the primitive 
shape factors determining the drag and lifting forces. The interaction 
force model will be trained and validated with a simple but effective multi-
layer feed-forward neural network: multi-layer perceptron (MLP), which 
will be concatenated after the encoder of the previously trained VAE for 
geometry feature extraction.",develop neural interaction drag lifting force model database constructed interaction force particles fluid phase based resolved direct numerical simulation immersed based lattice boltzmann method unsupervised learning method variational vae used improve diversity particle library extract primitive shape factors determining drag lifting forces interaction force model trained validated simple effective layer neural network perceptron mlp concatenated encoder previously trained vae geometry feature extraction,5,Asset management
376,To improve control of hybrid SOFC- gas turbine power systems.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Machine learning algorithms are being developed and compared to 
other control methods for SOFC-gas turbine hybrid  power generation 
systems.",machine learning algorithms developed compared control methods turbine hybrid power generation systems,19,Service delivery
377,"To leverage disparate data to update assessments, analytics, and infromation for NATCARB and CS Atlas",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"ML Is utilized to parse and generate additional data and information that 
can be parsed and labeled to provide additional inputs for geologic 
carbon storgae assessments from multiple sources.",ml utilized parse generate additional data information parsed labeled provide additional inputs geologic carbon storgae assessments multiple sources,14,Topic: Asset management
378,To leverage machine learning and predictive analytics to advance the state of the art in pipline infrastructure integrity management.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The purpose of this project is to leverage advances in machine learning 
and predictive analytics to advance the state of the art in pipeline 
infrastructure integrity management using forecasted (predicted) 
pipeline condition, using large sets of pipeline integrity data (periodic 
nondestructive inspection, NDI) and continuous operational data (e.g., 
sensor data used to monitor flow rate and temperature) generated by oil 
and gas (O&G) transmission pipeline operators.",purpose project leverage advances machine learning predictive analytics advance state art pipeline infrastructure integrity management using forecasted predicted pipeline condition using large sets pipeline integrity data periodic nondestructive inspection ndi continuous operational data sensor data used monitor flow rate temperature generated oil gas g transmission pipeline operators,15,Asset management
379,To leverage ML models to increase the size and complexity of problems that can be optimized within IDAES.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The objective is to leverage ML models as surrogates for complex unit 
operations or to bridge between scales to increase the size and 
complexity of models that can be optimized within IDAES.",objective leverage ml models surrogates complex unit operations bridge scales increase size complexity models optimized within idaes,0,Topic: Asset management
380,To perform reconstruction of the 3D temperature field using Neural Networks with measured and known propagation paths.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The sensor will first be tested up to 300 ï°C. For high-temperature tests, 
the Recipient will use Alstomâs Industrial Size Burner Test Facility (ISBF) 
or another appropriate facility. The high-temperature sensor will be first 
tested from room temperature to 1,800 ï°C. The results will be 
compared with data obtained using other methods such as surface 
acoustic wave (SAW), thermocouples, and optical fiber sensors. A 3D 
temperature mapping will be created by fusing the high-temperature 
sensor data. The Recipient will test the systemâs survivability in a boiler 
environment. A high-temperature sensing array will be tested to map the 
temperature distribution within an exhaust pipe. The sensor array will be 
tested at one 6ââ port or a similar location. The Recipient will also 
perform reconstruction of the 3D temperature field using Neural 
Networks with measured and known propagation paths.",sensor first tested tests recipient use industrial size burner test facility isbf another appropriate facility sensor first tested room temperature results compared data obtained using methods surface acoustic wave saw thermocouples optical fiber sensors temperature mapping created fusing sensor data recipient test survivability boiler environment sensing array tested map temperature distribution within exhaust pipe sensor array tested one port similar location recipient also perform reconstruction temperature field using neural networks measured known propagation paths,15,Asset management: use of AI to manage both physical and digital assets
381,To provide an effective quality assurance method for additively manufactured gas,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The primary goal of this project is to develop a cost-effective quality 
assurance (QA) method that can rapidly qualify laser powder bed fusion 
(LPBF) processed hot gas path turbine components (HGPTCs) through 
a machine learning framework which would assimilate in-situ monitoring 
and measurement, ex-situ characterization, and simulation data.  The 
project technical deliverable will be a rapid QA tool capable of: i) building 
a metadata package of process-structure-property data and models 
intended for LPBF-processed HGPTCs by mining both simulation and in-
situ/ex-situ characterization data; and ii) qualifying online/offline a 
manufactured component by inputting simulation with/without in-situ 
monitoring data to the developed algorithms to predict porosity and 
fatigue properties. The target application of this QA tool will be 
advanced HGPTC produced by LPBF in Inconel 718. Data mining 
techniques will be developed to consolidate and analyze the 
heterogeneous big data stemmed from the aforementioned methods of 
upfront simulation, online monitoring and post-build characterization, and 
thus enabling a collaborative learning about the process-microstructure-
properties relationship. The resultant QA package includes a process-
structure-property database and machine learning tools for using LPBF 
metal AM to fabricate HGPTC. The developed metadata package 
enables online/offline qualification of additively manufactured turbine 
components by inputting simulation with/without in-situ monitoring data 
to the developed machine learning algorithms to predict porosity and 
fatigue properties.",primary goal project develop quality assurance qa method rapidly qualify laser powder bed fusion lpbf processed hot gas path turbine components hgptcs machine learning framework would assimilate monitoring measurement characterization simulation data project technical deliverable rapid qa tool capable building metadata package data models intended hgptcs mining simulation characterization data ii qualifying manufactured component inputting simulation monitoring data developed algorithms predict porosity fatigue properties target application qa tool advanced hgptc produced lpbf inconel data mining techniques developed consolidate analyze heterogeneous big data stemmed aforementioned methods upfront simulation online monitoring characterization thus enabling collaborative learning properties relationship resultant qa package includes database machine learning tools using lpbf metal fabricate hgptc developed metadata package enables qualification additively manufactured turbine components inputting simulation monitoring data developed machine learning algorithms predict porosity fatigue properties,5,Asset management
382,To provide combustion performance and emissions optimization through integration of a miniaturized high- temperature multi process monitoring system,National Energy Technology Laboratory,Department of Energy,DOE,,"Project will develop control logic for automated control of lignite coal-
fired boiler. Plant operational data will be compared against monitoring 
data to determine when different sensor output from a miniaturized high 
temperature multi-process, high-spatial-resolution monitoring system 
signifies damaging conditions in that region of the boiler, and what 
operational changes can be made to eliminate the damaging condition. 
The control logic will be developed for automated control of soot-blowing 
and other boiler operations",project develop control logic automated control lignite fired boiler plant operational data compared monitoring data determine different sensor output miniaturized high temperature monitoring system signifies damaging conditions region boiler operational changes made eliminate damaging condition control logic developed automated control boiler operations,19,Asset management
383,To provide insights into opportunities to beneficiate and use hydrocarbon infrastructure for alternative uses such as offshore carbon storage.,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Multiple big data-driven AI/ML models will be used to evaluate geologic, 
geospatial, and infrastructure related information to inform predictions 
using natural language processing, Artificial Neural Networks, and 
possibly bayesian networks as well.",multiple big models used evaluate geologic geospatial infrastructure related information inform predictions using natural language processing artificial neural networks possibly bayesian networks well,12,Service delivery
384,To provide integrated boiler management through advanced condition monitoring and component assessment.,National Energy Technology Laboratory,Department of Energy,DOE,,"The Integrated Creep-Fatigue Management System represents an 
online boiler damage monitoring system applicable to creep and fatigue.  
The system will be configured to allow connectivity to the plant data 
historian (e.g., OSISoft:PI) and to commercial finite element software 
(e.g., ANSYS and Abaqus). In addition to configuring interaction with 
finite element software, existing damage mechanism monitoring 
modules will also be deployed using online analytical calculations. This 
functionality will be applied to terminal tubes entering the boiler header 
for which the combined mechanisms of creep and oxidation can be 
calculated without the need for a finite element analysis.",integrated management system represents online boiler damage monitoring system applicable creep fatigue system configured allow connectivity plant data historian osisoft pi commercial finite element software ansys abaqus addition configuring interaction finite element software existing damage mechanism monitoring modules also deployed using online analytical calculations functionality applied terminal tubes entering boiler header combined mechanisms creep oxidation calculated without need finite element analysis,19,Asset management
385,To provide natural gas leak detection and quality control,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Employing machine learning techniques to train sensing systems to 
quantify the concentration of natural gas species, distinguish between 
natural gas at different parts of the processing pipeline, and distinguish 
natural gas from natural and man-made interfering sources such as 
wetlands and agriculture.",employing machine learning techniques train sensing systems quantify concentration natural gas species distinguish natural gas different parts processing pipeline distinguish natural gas natural interfering sources wetlands agriculture,15,Asset management
386,To realize next generation solid-state power substation.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The objective of the proposed project is to realize next generation solid-
state power substation (SSPS) incorporating machine learning, cyber-
physical anomaly detection, and multi-agent distributed networked 
control. The project will have the following capabilities: distributed control 
and coordination coupled with localized intelligence and sensing, 
autonomous control for plug-and-play, automatic reconfiguration, 
recovery, and restoration enabling decoupled, asynchronous, and fractal 
systems.",objective proposed project realize next generation state power substation ssps incorporating machine learning physical anomaly detection distributed networked control project following capabilities distributed control coordination coupled localized intelligence sensing autonomous control automatic reconfiguration recovery restoration enabling decoupled asynchronous fractal systems,19,"""Asset management"""
387,To research and develop physics- aware and AI-enabled cyber- physical intrusion response for the power grid.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Responding to anomalous cyber and physical events in a timely manner 
requires fusing data from both cyber and physical sensors into 
actionable information. Thus, cyber-physical intrusion response research 
will be conducted that leverages cyber and physical side data and 
models with artificial intelligence (AI) as a scalable approach to maintain 
or regain power system resilience under anomalous incidents such as 
cyber threats.",responding anomalous cyber physical events timely manner requires fusing data cyber physical sensors actionable information thus intrusion response research conducted leverages cyber physical side data models artificial intelligence ai scalable approach maintain regain power system resilience anomalous incidents cyber threats,10,Topic: Asset management
388,To use advanced machine learning techniques to analyze static and dynamic measurements of proppant distribution and fracture geometry data.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"The project will use advanced ML techniques to analyze static and 
dynamic measurements of proppant distribution and fracture geometry 
data from thousands of microchips injected with proppant near the 
wellbore.",project use advanced ml techniques analyze static dynamic measurements proppant distribution fracture geometry data thousands microchips injected proppant near wellbore,3,Asset management
389,To use AI to calibrate the simulation model by matching simulation data with production history data.,National Energy Technology Laboratory,Department of Energy,DOE,ARTIFICIAL INTELLIGENCE UNKNOWN,"Task 2 - Together with GEM, CMGâs intelligent optimization and analysis 
tool, CMOST Artificial Intelligence (AI), will be used to calibrate the 
simulation model by matching simulation results with production history 
data. . Based on the data sets, a series of simulation cases will be 
generated to perform parameter estimation using a systematic 
approach. As simulation jobs complete, the results will be analyzed 
using CMOST AI to determine how well they match production history. 
An optimizer will then determine parameter values for new simulation 
jobs.",task together gem intelligent optimization analysis tool cmost artificial intelligence ai used calibrate simulation model matching simulation results production history data based data sets series simulation cases generated perform parameter estimation using systematic approach simulation jobs complete results analyzed using cmost ai determine well match production history optimizer determine parameter values new simulation jobs,5,Asset management
390,To use computational tools to optimize the design of solid CO2 sorbents.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The objective of this project is to use computational tools to optimize the 
design of solid CO2 sorbents based on functionalized PIM-1 (or other 
porous, glassy polymers) impregnated with molecular primary amines. 
The expected outcome of this project is to inform, via computational 
methods, which polymer structure and which molecular amines can lead 
to a solid sorbent in which CO2 loading capacity, CO2 heat of 
adsorption, and overall CO2 mass transfer rate are optimal at extremely 
low CO2 partial pressures while amine leaching has been minimized.",objective project use computational tools optimize design solid sorbents based functionalized porous glassy polymers impregnated molecular primary amines expected outcome project inform via computational methods polymer structure molecular amines lead solid sorbent loading capacity heat adsorption overall mass transfer rate optimal extremely low partial pressures amine leaching minimized,18,Asset management
391,To use data analytics and machine learning techniques to advance understanding of the characteristics of the Emerging Paradox Oil Play,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, NEURAL NETWORKS","Using data analytics and machine learning techniques to advance 
understanding of the characteristics of the entire Parardox oil play 
through integration of geologic and log-derived âelectrofaciesâ models 
and upscaling to 3D seismic data and propagation through the seismic 
volume.",using data analytics machine learning techniques advance understanding characteristics entire parardox oil play integration geologic models upscaling seismic data propagation seismic volume,11,Asset Management
392,To use ML to help identify promising oxygen carrier materials.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"A combination of experimental data and computational results  will be 
used both to understand O2 production and to develop a machine 
learning model that can be used to identify promising carrier 
compositions. These compositions will be evaluated on two primary 
criteria, performance and ability to be synthesized. Once the model has 
identified promising candidates, these materials will be synthesized and 
compared to existing carriers. This new data will then be used to refine 
the models.",combination experimental data computational results used understand production develop machine learning model used identify promising carrier compositions compositions evaluated two primary criteria performance ability synthesized model identified promising candidates materials synthesized compared existing carriers new data used refine models,1,Asset management
393,To verify and validate testing of advanced power generation technologies,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA","Verification and validation testing with direct support and collaboration 
from operating power plants with advanced power generation 
technologies and prime mover and downstream systems using near-
real-time data, resulting in better informed plant operators, and reduced 
disruptions, while meeting changing service demands based on 
enhanced operating flexibility",verification validation testing direct support collaboration operating power plants advanced power generation technologies prime mover downstream systems using data resulting better informed plant operators reduced disruptions meeting changing service demands based enhanced operating flexibility,3,Service delivery
394,"Transform reservoir management decisions through rapid analysis of real time data to visualize forecasted behavior in an advanced control room ""human-in-the-loop"" format.",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"Improve low-fidelity model performance by transfer-learning with high-
fidelity data, and reduce uncertainty by combining high-fidelity and lower-
fidelity models for improved UQ performance.",improve model performance fidelity data reduce uncertainty combining fidelity models improved uq performance,7,Internal operations
395,UNET and other approaches for ML- based inversion,National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, OTHER","Researchers will develop a design basis for risk-based monitoring 
considering data dimensionality, uncertainty, and inter-tool/module 
connectivity, and define the components of the monitoring design 
optimization tool (DREAM) to be incorporated into NRAP-Open-IAM and 
the SMART platform.",researchers develop design basis monitoring considering data dimensionality uncertainty connectivity define components monitoring design optimization tool dream incorporated smart platform,17,Internal operations: administrative use cases for AI
396,Use AI to process large sensor datasets for identification and classification of NG pipeline conditions and methane leaks,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","Focused on development of advanced data analytic techniques and 
methods for distributed OFS technology, including AI and ML, for 
identification of signatures and patterns representative of hazards, 
defects, and operational parameters of the natural gas pipeline network.",focused development advanced data analytic techniques methods distributed ofs technology including ai ml identification signatures patterns representative hazards defects operational parameters natural gas pipeline network,18,Asset management
397,Use ML to analyze the existing H2 and natural gas pipelines to identify the key parameters that can enable the H2 transport and storage at a large scale,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, OTHER","This task aims to use geo-data science methods and geospatial 
information science to analyze the existing H2 and natural gas pipelines 
to identify the key parameters that can enable the H2 transport and 
storage at a large scale. The results can help to justify the importance of 
real-time pipeline monitoring and recommend optimized sensor 
deployment strategies to support smart maintenance and methane 
emissions reduction goals.",task aims use science methods geospatial information science analyze existing natural gas pipelines identify key parameters enable transport storage large scale results help justify importance pipeline monitoring recommend optimized sensor deployment strategies support smart maintenance methane emissions reduction goals,15,Topic: Asset Management
398,"Use ML to enable a geophysical monitoring toolkit, and assimilate real-time modeling and data.",National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"ML-enabled rapid and autonomous geophysical monitoring and real-
time modeling and data assimilation tools (along with visualization and 
decision-support frameworks), work together to radically improve 
pressure and stress imaging.",rapid autonomous geophysical monitoring time modeling data assimilation tools along visualization frameworks work together radically improve pressure stress imaging,7,Service delivery
399,Use ML to reduce high-fidelity physical models to a fast calculation that requires minimal effort to initiate.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The platform will combine an intuitive user interface and visualization 
capabilities from gaming software with the speed and enhanced detail in 
evaluating reservoir dynamics and processes through ML /reduced 
order model approaches. Advancements made with ML will alleviate the 
need for both the expert user and the computational infrastructure and 
make understanding subsurface fluid flow accessible to the everyday 
user with a moderate level of understanding of the physics of the 
system. ML will allow the experts to reduce the high-fidelity physical 
models to a fast calculation that requires a minimal amount of effort to 
initiate, but allows a user to investigate their own scenarios without the 
need for predetermined models. Application of the platform will rapidly 
enhance the experience base required for deploying and managing 
commercial-scale projects, particularly for CO2 storage projects where 
field experience is limited, because of the anticipated intuitive translation 
of subsurface dynamics in real-time.",platform combine intuitive user interface visualization capabilities gaming software speed enhanced detail evaluating reservoir dynamics processes ml order model approaches advancements made ml alleviate need expert user computational infrastructure make understanding subsurface fluid flow accessible everyday user moderate level understanding physics system ml allow experts reduce physical models fast calculation requires minimal amount effort initiate allows user investigate scenarios without need predetermined models application platform rapidly enhance experience base required deploying managing projects particularly storage projects field experience limited anticipated intuitive translation subsurface dynamics,7,Topic 8: Service delivery
400,Use of machine learning models to produce surrogates for efficient optimization,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"We consider the use of machine learning models to produce surrogates 
for efficient optimization. The IDAES implementation will be 
demonstrated on a real-scale design problem focused on carbon 
capture (e.g., rigorous MEA model), or an integrated energy system.",consider use machine learning models produce surrogates efficient optimization idaes implementation demonstrated design problem focused carbon capture rigorous mea model integrated energy system,0,Asset management
401,"Using AI to improve predcitions of subsurface properties, analyze multi- variate inputs, address knowledge and information gaps to improve predictions and modeli",National Energy Technology Laboratory,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, BIG DATA, OTHER","Use of AI methods such as fuzzy logic, neural networks, tensor flow, 
and natural language processing to assist with knowledge and data 
exploration, transformation and integration, as well as modeling and 
analysis of multi-variate data used in the resource assessment method 
to improve outputs and predictions.",use ai methods fuzzy logic neural networks tensor flow natural language processing assist knowledge data exploration transformation integration well modeling analysis data used resource assessment method improve outputs predictions,12,Asset management
402,Using AI/ML to replace conventional geophysics inversion - does the process quicker than the typical method. Make geophysical results more user-friendly.,National Energy Technology Laboratory,Department of Energy,DOE,NEURAL NETWORKS,"The project will deploy a high sensitivity atomic magnetometer 
(potassium magnetometer or helium 4 magnetometer) on a sUAS 
platform. Baseline surveys using the sUAS platform with the magnetic 
receiver payload will be flown at the same CarbonSAFE site that 
baseline ground surveys were performed in EY21. Results of the 
forward modeling performed in EY20 will determine whether MT or 
CSEM (or both) methods will be tested. Using AI/ML to replace 
conventional geophysics inversion - does the process quicker than the 
typical method. Make geophysical results more user-friendly.",project deploy high sensitivity atomic magnetometer potassium magnetometer helium magnetometer suas platform baseline surveys using suas platform magnetic receiver payload flown carbonsafe site baseline ground surveys performed results forward modeling performed determine whether mt csem methods tested using replace conventional geophysics inversion process quicker typical method make geophysical results,7,"Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
403,Using ML to build predictive models of branching processes and develop novel algorithms for automated MIP solver tuning,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"We will collect dual gaps obtained as a result of using different 
branching strategies and feed them into ALAMO, Pysmo, and other 
machine learning approaches to build predictive models of branching 
processes as a function of carefully chosen instance features. These 
models will then be deployed as part of the IDAES platform to facilitate 
optimization of advanced integrated energy systems.  o Currently, tuning 
MIP solvers for a particular application is approached by ad-hoc trial-and-
error methods that are tedious and often ineffective, limiting design 
engineers to solution of small problems. To address this challenge and 
facilitate the solution of energy systems currently intractable, we 
propose to develop novel algorithms for automated MIP solver tuning 
through the use of machine learning.",collect dual gaps obtained result using different branching strategies feed alamo pysmo machine learning approaches build predictive models branching processes function carefully chosen instance features models deployed part idaes platform facilitate optimization advanced integrated energy systems currently tuning mip solvers particular application approached error methods tedious often ineffective limiting design engineers solution small problems address challenge facilitate solution energy systems currently intractable propose develop novel algorithms automated mip solver tuning use machine learning,0,"Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
404,Using ML to design sensing materials which can work under harsh environments.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The team proposes to develop an ML approach that relies upon 
established experimental and theoretical evidence to gain a 
comprehensive ML model and boost the gas sensing material design. 
The essence of this approach will be to assess materialsâ optimal 
performance at a specific condition, such as temperature, pressure, and 
radiation levels. The development of the package will occur in several 
steps: (1) building a materials database from various sources; (2) using 
ML techniques to build, evaluate, and optimize an ML model; (3) 
predicting the temperature dependence of sensing properties, such as 
gas selectivity, for FECM relevant gas species to screen the materials in 
the material bank, or proposing new sensing materials; and (4) exploring 
the gas sensing mechanisms suited for high-temperature application for 
those predicted most promising gas sensing materials.",team proposes develop ml approach relies upon established experimental theoretical evidence gain comprehensive ml model boost gas sensing material design essence approach assess optimal performance specific condition temperature pressure radiation levels development package occur several steps building materials database various sources using ml techniques build evaluate optimize ml model predicting temperature dependence sensing properties gas selectivity fecm relevant gas species screen materials material bank proposing new sensing materials exploring gas sensing mechanisms suited application predicted promising gas sensing materials,15,Asset management
405,Using natural language processing to explore and extract information from historical literature/pdfs,National Energy Technology Laboratory,Department of Energy,DOE,"BIG DATA, NATURAL LANGUAGE PROCESSING, OTHER","Training and adaptation of natural lanaguage processing algorithms to 
improve exploration and extraction of information from old, historical 
scientific literature.  Extraction of knowledge and data, as well as 
preservation of key information.",training adaptation natural lanaguage processing algorithms improve exploration extraction information old historical scientific literature extraction knowledge data well preservation key information,6,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
406,Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.,National Energy Technology Laboratory,Department of Energy,DOE,"NEURAL NETWORKS, OTHER","This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.",project develop ml algorithm predict time growing fracture reach monitored well ml workflow trained distinctive tensile strain signature precedes growing fracture new workflow designed work conjunction fracture warning ml workflow developed together workflows provide early warning well communication predict measured depths communication happen provide estimated time beginning communication,18,Asset management
407,Using time-series classification to assist in automated analysis of sensor data taken during experiments on the MHD test channel.,National Energy Technology Laboratory,Department of Energy,DOE,OTHER,"The measurements of chemical composition will be combined with 
resistance measurements to validate CFD models of the MHD channel 
system. Specifically, validated CFD models will be able to separate the 
contribution of the bulk and boundary layer resistance to the overall 
resistance of the MHD channel.",measurements chemical composition combined resistance measurements validate cfd models mhd channel system specifically validated cfd models able separate contribution bulk boundary layer resistance overall resistance mhd channel,0,Asset management
408,"With sensor technologies and network developed, in the future, AI/ML may be used to accelerate data processing of sensor data from the sensor network.",National Energy Technology Laboratory,Department of Energy,DOE,"AI, ML","With sensor technologies and network developed, in the future, AI/ML 
may be used to accelerate data processing of sensor data from the 
sensor network to identify and predict risks and failures in plugged wells.",sensor technologies network developed future may used accelerate data processing sensor data sensor network identify predict risks failures plugged wells,15,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
409,Applications of Natural Language Processing and Similarity Measures for Similarity Ranking,"Office of Environment, Health, Safety & Security",Department of Energy,DOE,NLP,"""EHSS has been developing applications of natural language 
processing (NLP) and similarity measures for advanced information 
retrieval and searching of datasets (e.g., SQL databases, CSV files, 
reports) as well as estimating similarities between records within a 
dataset or records between different datasets.  Similarity search has 
been successfully applied to efficiently search DOE COVID-19 Hotline 
questions and answer database, searching DOE annual site 
environmental reports, similarity between DOE occurrence reporting and 
processing system and lessons learned, and AIX data.  Similarity 
measures can also be used to identify opportunities for resource 
prioritization and prediction.
As of October 2021, the tool runs locally by the principal investigator on 
project based, as requested or as a desktop application.  Initial 
developments were initiated to move to a web-based application but not 
completed due to lack of user need and resources.""",ehss developing applications natural language processing nlp similarity measures advanced information retrieval searching datasets sql databases csv files reports well estimating similarities records within dataset records different datasets similarity search successfully applied efficiently search doe hotline questions answer database searching doe annual site environmental reports similarity doe occurrence reporting processing system lessons learned aix data similarity measures also used identify opportunities resource prioritization prediction october tool runs locally principal investigator project based requested desktop application initial developments initiated move application completed due lack user need resources,6,"""Hotlines and service desks"""
410,"Data Analytics and Machine Learning (DAMaL) Tools for Analysis of Environment, Safety and Health (ES&H) data: Similarity Based Information Retrieval","Office of Environment, Health, Safety & Security",Department of Energy,DOE,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING, ARTIFICIAL INTELLIGENCE, AI, NLP, DECISION-MAKING","""The EHSS Data Analytics Machine Learning (DAMaL) tools, similarity-
based information retrieval tool, uses natural language processing 
(NLP) and cosine similarity to leverage artificial intelligence (AI) to 
increase the efficiency of a user to find important records in the DOE 
environment, safety, and health (ES&H) datasets (e.g., occurrence 
reporting and processing system, fire protection, lessons learned, 
accident and injury reporting system, contractor assurance system 
CAS).  The tool has no restriction on the text query, provides NLP 
options to the user (e.g., stemming or lemmatization) and could be used 
to improve decision-making in job planning activities, identifying hazards, 
and obtaining insights from operating experience and lessons learned 
data discovery and analysis, accident investigations among other areas.
As of October 2021, Tool developed and deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.",ehss data analytics machine learning damal tools based information retrieval tool uses natural language processing nlp cosine similarity leverage artificial intelligence ai increase efficiency user find important records doe environment safety health es h datasets occurrence reporting processing system fire protection lessons learned accident injury reporting system contractor assurance system cas tool restriction text query provides nlp options user stemming lemmatization could used improve job planning activities identifying hazards obtaining insights operating experience lessons learned data discovery analysis accident investigations among areas october tool developed deployed damal tools website expected continue maintain develop documentation users analysis guides improve enhance increase data sources,9,Service delivery
411,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Classification, Robotic Process Automation and Data Visualization","Office of Environment, Health, Safety & Security",Department of Energy,DOE,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING, ROBOTIC PROCESS AUTOMATION, CLASSIFICATION, ARTIFICIAL INTELLIGENCE, VISUALIZATION, AI, NLP","""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
classification, robotic process automation and data visualization tool, 
uses natural language processing (NLP) and classification algorithms 
(i.e., random forests) to automate the classification of records, visually 
provide insights in the trends and provide an indication of importance 
and risk.   The tool leverages artificial intelligence (AI) to analyze the text 
of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, accident and injury reporting 
system, contractor assurance system CAS) and identifies important 
topics that can be used by an analyst to drill down and further explore 
potential safety issues in the DOE operations.
As of October 2021, the tool has been deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.",ehss data analytics machine learning damal tools classification robotic process automation data visualization tool uses natural language processing nlp classification algorithms random forests automate classification records visually provide insights trends provide indication importance risk tool leverages artificial intelligence ai analyze text doe environment safety health es h operating experience dataset records occurrence reporting processing system fire protection lessons learned accident injury reporting system contractor assurance system cas identifies important topics used analyst drill explore potential safety issues doe operations october tool deployed damal tools website expected continue maintain develop documentation users analysis guides improve enhance increase data sources,9,Topic: Asset management
412,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Unsupervised Machine Learning Text Clustering","Office of Environment, Health, Safety & Security",Department of Energy,DOE,"MACHINE LEARNING, CLUSTERING, AI, NLP","""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
unsupervised machine learning clustering tool, uses natural language 
processing (NLP) and clustering algorithms (i.e., k means, DBSCAN 
and dimensionality reduction approaches) to leverage AI to analyze the 
text of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, and accident and injury 
reporting system, contractor assurance system CAS).  The tool 
identifies recurrent and important topics that can be used by an analyst 
to drill down and further explore potential recurrent safety issues in the 
DOE operations.
As of October 2021, the tool has been partially deployed in the DAMaL 
tools website.  Development is mostly complete with use case in Fire 
Protection Trending and Analysis completed and undergoing review of 
report.  Expected to continue to maintain, develop documentation (e.g., 
users analysis guides), improve and enhance, and increase data 
sources.",ehss data analytics machine learning damal tools unsupervised machine learning clustering tool uses natural language processing nlp clustering algorithms k means dbscan dimensionality reduction approaches leverage ai analyze text doe environment safety health es h operating experience dataset records occurrence reporting processing system fire protection lessons learned accident injury reporting system contractor assurance system cas tool identifies recurrent important topics used analyst drill explore potential recurrent safety issues doe operations october tool partially deployed damal tools website development mostly complete use case fire protection trending analysis completed undergoing review report expected continue maintain develop documentation users analysis guides improve enhance increase data sources,9,Topic: Asset management
413,Memorandum of Understanding Between the US DOE and US NRC on Cooperation in the Area of Operating Experience and Applications of Data Analytics (Signed June 2021),"Office of Environment, Health, Safety & Security",Department of Energy,DOE,"MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, VISUALIZATION, DECISION-MAKING","The purpose of the Memorandum of Understanding (MOU) between the 
US DOE and US NRC on cooperation in the area of operating 
experience and applications of data analytics (Signed June 2021) is to 
efficiently use resources and to avoid needless duplication of effort by 
sharing data, technical information, lessons learned, and, in some 
cases, the costs related to the development of approaches and tools, 
whenever such cooperation and cost sharing may be done in a mutually 
beneficial fashion.  The technical areas for collaboration include, those 
related to operating experience and safety data collection and analysis, 
including operational events, occupational injuries, hazardous substance 
releases, nuclear safety, radiation protection, equipment failure, 
accidents and accident precursors, trending analysis, and risk-informed 
decision-making.  Applications of data analytics in the analysis of 
operating experience and safety data, including data visualization and 
analysis, artificial intelligence, machine learning, natural language 
processing, predictive analytics, and other advanced analysis 
techniques, user interface design, and deployment, and decision-
making using data analytics tools.",purpose memorandum understanding mou us doe us nrc cooperation area operating experience applications data analytics signed june efficiently use resources avoid needless duplication effort sharing data technical information lessons learned cases costs related development approaches tools whenever cooperation cost sharing may done mutually beneficial fashion technical areas collaboration include related operating experience safety data collection analysis including operational events occupational injuries hazardous substance releases nuclear safety radiation protection equipment failure accidents accident precursors trending analysis applications data analytics analysis operating experience safety data including data visualization analysis artificial intelligence machine learning natural language processing predictive analytics advanced analysis techniques user interface design deployment making using data analytics tools,12,Topic 8: Service delivery
414,Groundwater Modeling,Office of Legacy Management,Department of Energy,DOE,,Groundwater modeling includes parameter estimation,groundwater modeling includes parameter estimation,5,Asset management
415,Soil Moisture Modeling,Office of Legacy Management,Department of Energy,DOE,MACHINE LEARNING,"Use multisource machine learning to model soil moisture within the 
lysimeter embedded within a disposal cell",use multisource machine learning model soil moisture within lysimeter embedded within disposal cell,1,Asset management
416,AI-Based Chat Bot,Office of the Chief Information Officer,Department of Energy,DOE,AI,"The OCIO EITS Service Desk is exploring the ability to use AI chat bots 
to interact with end-users. We are looking to have a single bot 
architecture that is highly tuned to IT system languages to properly 
handle the terms that may be used in an enterprise environment. The 
primary benefit would be to make knowledge more available to the end-
users in a consumable manner. Additionally, it would connect to ITSM 
workflows that could automate basic functions such as request an 
account, provide permissions, or create an MS Teams site as 
examples. Additionally, the technology needs to provide a significant 
amount of feedback to the EITS Service Desk on unanswered 
questions, questions dropped, ineffective responses, incorrect 
responses, etc.",ocio eits service desk exploring ability use ai chat bots interact looking single bot architecture highly tuned system languages properly handle terms may used enterprise environment primary benefit would make knowledge available users consumable manner additionally would connect itsm workflows could automate basic functions request account provide permissions create ms teams site examples additionally technology needs provide significant amount feedback eits service desk unanswered questions questions dropped ineffective responses incorrect responses etc,6,"Hotlines and service desks: use of AI to triage, respond, and refer to calls, texts, emails"
417,Adaptive Cyber-Physical Resilience for Building Control Systems,Pacific Northwest National Laboratory,Department of Energy,DOE,DEEP LEARNING,"Deep learning models are used for predicting the operation of building 
energy systems, and detecting and diagnosing the health state or cyber 
attack presence, and for optimizing the building energy system 
response to provide resilient operation and sustained energy efficiency.",deep learning models used predicting operation building energy systems detecting diagnosing health state cyber attack presence optimizing building energy system response provide resilient operation sustained energy efficiency,10,Asset management
418,Advancing Market-Ready Building Energy Management by Cost- Effective Differentiable Predictive Control,Pacific Northwest National Laboratory,Department of Energy,DOE,"AI, DEEP LEARNING","An AI based differentiable programming framework for domain aware 
data efficient predictive modeling and AI based control policy synthesis 
as well as methods for safety verification and online learning. Domain 
aware deep learning models are used for learning and predicting the 
response of building systems and components and for optimizing the 
building energy system response to provide resilient operation and 
sustained energy efficiency.",ai based differentiable programming framework domain aware data efficient predictive modeling ai based control policy synthesis well methods safety verification online learning domain aware deep learning models used learning predicting response building systems components optimizing building energy system response provide resilient operation sustained energy efficiency,10,Topic: Internal operations
419,AI techniques for identification of suitable delivery parking spaces in an urban scenario,Pacific Northwest National Laboratory,Department of Energy,DOE,AI,"We are using AI (Graph Neural Network) to determine importance of 
parking spaces in a city network for curb management to promote 
adoption of electric vehicles for freight delivery",using ai graph neural network determine importance parking spaces city network curb management promote adoption electric vehicles freight delivery,5,Service / benefits access
420,AI used for predictive modeling and real time control of traffic systems,Pacific Northwest National Laboratory,Department of Energy,DOE,DEEP LEARNING,"Domain aware deep learning models are used for predictive modeling of 
traffic. Deep learning based predictive controllers are trained from 
simulated data to optimize the traffic signaling and coordination for 
improved traffic flow and reduced energy consumption and GHG 
emissions",domain aware deep learning models used predictive modeling traffic deep learning based predictive controllers trained simulated data optimize traffic signaling coordination improved traffic flow reduced energy consumption ghg emissions,10,Asset management
421,APT Analytics,Pacific Northwest National Laboratory,Department of Energy,DOE,"AI, ML",Development of AI/ML for automated analysis of APT data.,development automated analysis apt data,19,Service / benefits access
422,Elucidating Genetic and Environmental Risk Factors for Antipsychotic-induced Metabolic Adverse Effects Using AI,Pacific Northwest National Laboratory,Department of Energy,DOE,AI,"Develop AI methids to  find phenotypes that capture complex interation 
between human genome, chronic diseases and a drug's chemical 
signature to predict adverse side-effects of a mental health drug on 
human population",develop ai methids find phenotypes capture complex interation human genome chronic diseases drug chemical signature predict adverse mental health drug human population,9,"Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments 

Note: This topic is not exact but it's the closest match as the text seems to be about using AI for predicting adverse side-effects of a mental health drug on human population, which can be considered providing direct services to the public."
423,Laboratory Automation,Pacific Northwest National Laboratory,Department of Energy,DOE,MACHINE LEARNING,"Employing machine learning to identify regions of interest in SEM and 
TEM data. Automating data acquisition to improve efficiencies.",employing machine learning identify regions interest sem tem data automating data acquisition improve efficiencies,7,"""Asset management"""
424,Managing curb allocation in cities,Pacific Northwest National Laboratory,Department of Energy,DOE,,"This project's goal is to develop a city-scale dynamic curb use 
simulation tool and an open-source curb management platform that 
address the challenge of increased demand for curb-side parking.",project goal develop dynamic curb use simulation tool curb management platform address challenge increased demand parking,5,Service delivery
425,Physics-Informed Learning Machines for Multiscale and Multiphysics Problems (PhILMs),Pacific Northwest National Laboratory,Department of Energy,DOE,DEEP LEARNING,"PhILMs investigators are developing physics-informed learning 
machines by encoding physics knowledge into deep learning networks",philms investigators developing learning machines encoding physics knowledge deep learning networks,16,"Topic_name: ""Asset management"""
426,Regional waste feedstock conversion to biofuels,Pacific Northwest National Laboratory,Department of Energy,DOE,ML,"Unsupervised ML is used sequentially to group waste sources into 
different regions.  Calibrated game theoretic models are used to assess 
the behavior and economic viability of different waste-to-energy 
pathways within a region.",unsupervised ml used sequentially group waste sources different regions calibrated game theoretic models used assess behavior economic viability different pathways within region,19,Asset management
427,"Scalable, Efficient and Accelerated Causal Reasoning Operators, Graphs and Spikes for Earth and Embedded Systems (SEA-CROGS)",Pacific Northwest National Laboratory,Department of Energy,DOE,REGRESSION,"Establish a center for scalable and efficient physics-informed machine 
learning for science and engineering that will accelerate modeling, 
inference, causal reasoning, etiology and pathway discovery for earth 
systems and embedded systems. Advances will lead to a higher level of 
abstraction of operator regression to be implemented in next generation 
neuromorphic computers.",establish center scalable efficient machine learning science engineering accelerate modeling inference causal reasoning etiology pathway discovery earth systems embedded systems advances lead higher level abstraction operator regression implemented next generation neuromorphic computers,16,Service / benefits access
428,Surrogate models for probabilistic Bayesian inference,Pacific Northwest National Laboratory,Department of Energy,DOE,"AI, ML","We are using AI/ML to build surrogate models of the observable 
response of complex physical systems. These surrogate models will be 
used for probabilistic model inversion of these systems with the goal of 
estimating unknown model parameters from indirect observations.",using build surrogate models observable response complex physical systems surrogate models used probabilistic model inversion systems goal estimating unknown model parameters indirect observations,10,Asset management
429,Universal MCEG,Thomas Jefferson Laboratory,Department of Energy,DOE,ML,"R&D on ML based MC event generator that serves as data 
compatification utility.",r ml based mc event generator serves data compatification utility,18,Service delivery
430,FIMS - Invoice BOT - Employee Reimbursements FIMS - Invoice BOT - Purchase Power,Western Area Power Administration,Department of Energy,DOE,"ARTIFICIAL INTELLIGENCE, DOCUMENT UNDERSTANDING","PROCESS - Invoices are sent to the RPA Invoice Intake email box 
(RPAInvoiceIntake@WAPA.GOV). Once a day, unattended bot will 
extract information from PDF invoices. The invoice is classified to 
determine whether the invoice is an Employee Reimbursement or a 
Purchase Power Invoice.  The information extracted from the invoice is 
then review/validated by the Accounts Payable Technician. After 
validation, the bot will load the information into the WAPA Financial 
Management System.",process invoices sent rpa invoice intake email box rpainvoiceintake day unattended bot extract information pdf invoices invoice classified determine whether invoice employee reimbursement purchase power invoice information extracted invoice accounts payable technician validation bot load information wapa financial management system,6,Service delivery
536,Aidan Chat-bot,Federal Student Aid,Department of Education,ED,"NATURAL LANGUAGE PROCESSING, VIRTUAL ASSISTANT","FSA's virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov.
In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.",fsa virtual assistant uses natural language processing answer common financial aid questions help customers get information federal aid two years aidan interacted million unique customers resulting million user messages,6,Service delivery
552,Information Gateway OneReach Application,ACF,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, AI","The Information Gateway hotline connects to a phone IVR managed by OneReach AI. OneReach maintains a database of state hotlines for reporting child abuse and neglect that it can connect a caller to based on their inbound phone area code. Additionally, OneReach offers a limited FAQ texting service that utilizes natural language processing to answer user queries. User queries are used for reinforcement training by a human AI trainer and to develop additional FAQs.",information gateway hotline connects phone ivr managed onereach ai onereach maintains database state hotlines reporting child abuse neglect connect caller based inbound phone area code additionally onereach offers limited faq texting service utilizes natural language processing answer user queries user queries used reinforcement training human ai trainer develop additional faqs,9,4. Hotlines and service desks
553,AHRQ Search,AHRQ,Department of Health and Human Services,HHS,,"Organization wide search that includes Relevancy Tailoring, Auto-generation Synonyms, Automated Suggestions,  Suggested Related Content ,Auto Tagging, and Did you mean to allow visitors to find specific content",organization wide search includes relevancy tailoring synonyms automated suggestions suggested related content auto tagging mean allow visitors find specific content,6,Service delivery
554,Chatbot,AHRQ,Department of Health and Human Services,HHS,,Provide interface to allow user to conversationally ask questions about AHRQ content to replace public inquiry telephone line,provide interface allow user conversationally ask questions ahrq content replace public inquiry telephone line,3,"""Policy-making and public engagement: use of AI in any stage of developing regulations or gathering input"""
555,R+2:18eDIRECT: Clarivate,ASPR,Department of Health and Human Services,HHS,AI,AI to identify drug repurposing candidates,ai identify drug repurposing candidates,9,Service delivery
556,ReDIRECT: AriScience,ASPR,Department of Health and Human Services,HHS,AI,AI to identify drug repurposing candidates,ai identify drug repurposing candidates,9,Service delivery
557,Burn & Blast MCMs: Rivanna,ASPR,Department of Health and Human Services,HHS,AI,AI Based algorithms on Accuro XV to detect and highlight fractures and soft tissue injuries,ai based algorithms accuro xv detect highlight fractures soft tissue injuries,13,Service delivery
558,Burn & Blast MCMs: Philips,ASPR,Department of Health and Human Services,HHS,AI,AI-based algorithms on Lumify handheld ultrasound system to detect lung injury and infectious diseases,algorithms lumify handheld ultrasound system detect lung injury infectious diseases,13,Service delivery
559,Burn & Blast MCMs: Philips,ASPR,Department of Health and Human Services,HHS,AI,AI-based algorithms on Lumify handheld ultrasound system to detect traumatic injuries,algorithms lumify handheld ultrasound system detect traumatic injuries,13,Service delivery
560,Burn & Bast MCMs: SpectralMD,ASPR,Department of Health and Human Services,HHS,,Determination of burn depth severity and burn size of injuries ,determination burn depth severity burn size injuries,3,Service Delivery
561,Digital MCM: Virufy,ASPR,Department of Health and Human Services,HHS,AI,Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 using AI.,using forced cough vocalization fcv smartphone detect presence using ai,10,Service delivery
562,Current Health,ASPR,Department of Health and Human Services,HHS,AI,Continuous monitoring platform and AI algorithm for COVID severity,continuous monitoring platform ai algorithm covid severity,15,Service Delivery
563,Digital MCM: Raisonance,ASPR,Department of Health and Human Services,HHS,AI,Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 and Influenza using AI.,using forced cough vocalization fcv smartphone detect presence influenza using ai,10,Service delivery
564,Digital MCM: Visual Dx,ASPR,Department of Health and Human Services,HHS,AI,Using smartphone image with AI to detect the presence of mPox,using smartphone image ai detect presence mpox,10,Topic: Accessibility
565,Host-Based Diagnostics: Patchd,ASPR,Department of Health and Human Services,HHS,AI,Wearable device and AI model to predict sepsis at home.,wearable device ai model predict sepsis home,1,Service delivery
566,Data Modernization,ASPR,Department of Health and Human Services,HHS,"MACHINE LEARNING, ML",Develop open data management architecture that enables optimized business intelligence (BI) and machine learning (ML) on all ASPR data.,develop open data management architecture enables optimized business intelligence bi machine learning ml aspr data,7,Service / benefits access
567,Cyber Threat Detection/ Predictive analytics,ASPR,Department of Health and Human Services,HHS,"AI, ML",Use AI and ML tools for processing of extremely large threat data,use ai ml tools processing extremely large threat data,18,Topic: Program integrity
568,emPOWER,ASPR,Department of Health and Human Services,HHS,AI,Using the AI capabilities to rapidly develop the empower COVID-19 At Risk Population data tools and program,using ai capabilities rapidly develop empower risk population data tools program,18,Service / benefits access
569,Community Access to Testing,ASPR,Department of Health and Human Services,HHS,ML,Utilizing several ML models to forecast a surge in the pandemic,utilizing several ml models forecast surge pandemic,18,"""Service delivery"""
570,Modeling & Simulation,ASPR,Department of Health and Human Services,HHS,,Create modeling tools and perform analyses in advance of biothreat events and be able to refine them during emergent events,create modeling tools perform analyses advance biothreat events able refine emergent events,12,Topic: Service Delivery
571,Ventilator Medication Model,ASPR,Department of Health and Human Services,HHS,,Leveraging generalized additive model to project ventilated rate of COVID inpatients,leveraging generalized additive model project ventilated rate covid inpatients,3,Service / benefits access
572,Product redistribution optimization,ASPR,Department of Health and Human Services,HHS,AI,"Using AI and models, allow partners (jurisdictions, pharmacies, federal entities) to optimize redistribution of products based on various factors like distance, ordering/admins, equity, etc.",using ai models allow partners jurisdictions pharmacies federal entities optimize redistribution products based various factors like distance equity etc,3,"""Service delivery"""
573,Highly Infectious Patient Movement optimization,ASPR,Department of Health and Human Services,HHS,DECISION-MAKING,"Given a limited number of highly infectious patient transport containers, optimize US location based on various factors like distance, population, etc. Use as a planning tool for decision-making.",given limited number highly infectious patient transport containers optimize us location based various factors like distance population etc use planning tool,13,Service delivery
574,TowerScout:Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation,CDC,Department of Health and Human Services,HHS,"CLASSIFICATION, OBJECT DETECTION","TowerScout scans aerial imagery and uses object detection and image classification models to detect cooling towers, which can be sources of community outbreaks of Legionnaires' Disease. ",towerscout scans aerial imagery uses object detection image classification models detect cooling towers sources community outbreaks legionnaires disease,1,Service delivery
575,HaMLET: Harnessing Machine Learning to Eliminate Tuberculosis,CDC,Department of Health and Human Services,HHS,COMPUTER VISION,HaMLET uses computer vision models to detect TB from chest x-rays to improve the quality of overseas health screenings for immigrants and refugees seeking entry to the U.S.,hamlet uses computer vision models detect tb chest improve quality overseas health screenings immigrants refugees seeking entry,13,Service delivery
576,Zero-shot learning to identify menstrual irregularities reported after COVID-19 vaccination,CDC,Department of Health and Human Services,HHS,ZERO-SHOT LEARNING,Zero-shot learning was used to identify and classify reports of menstrual irregularities after receiving COVID-19 vaccination,learning used identify classify reports menstrual irregularities receiving vaccination,15,Service / benefits access
577,Validation Study of Deep Learning Algorithms to Explore the Potential Use of Artificial Intelligence for Public Health Surveillance of Eye Diseases,CDC,Department of Health and Human Services,HHS,DEEP LEARNING,Applying deep learning algorithms for detecting diabetic retinopathy to the NHANES retinal photos. The purpose of this project is to determine whether these algorithms could be used in the future to replace ophthalmologist grading and grade retinal photos collected for surveillance purposes through the National Health and Nutrition Examination Survey (NHANES).,applying deep learning algorithms detecting diabetic retinopathy nhanes retinal photos purpose project determine whether algorithms could used future replace ophthalmologist grading grade retinal photos collected surveillance purposes national health nutrition examination survey nhanes,10,Service delivery
578,Automating extraction of sidewalk networks from street-level images,CDC,Department of Health and Human Services,HHS,COMPUTER VISION,A team of scientists participating in CDC's Data Science Upskilling Program are building a computer vision model to extract information on the presence of sidewalks from street-level images from Mapillary.,team scientists participating cdc data science upskilling program building computer vision model extract information presence sidewalks images mapillary,10,"""Asset management: use of AI to manage both physical and digital assets"""
579,"Identify walking and bicycling trips in location-based data, including global-positioning system data from smartphone applications",CDC,Department of Health and Human Services,HHS,MACHINE LEARNING,"The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is developing machine learning techniques to identify walking and bicycling trips in GPS-based data sources. Inputs would include commercially-available location-based data similar to those used to track community mobility during the COVID-19 pandemic. Outputs could include geocoded data tables, GIS layers, and maps.",division nutrition physical activity obesity national center chronic disease prevention health promotion developing machine learning techniques identify walking bicycling trips data sources inputs would include data similar used track community mobility pandemic outputs could include geocoded data tables gis layers maps,1,Asset management: use of AI to manage both physical and digital assets
580,Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images,CDC,Department of Health and Human Services,HHS,MACHINE LEARNING,"The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting machine learning techniques to identify sidewalks, bicycle lanes, and other infrastructure in images, both satellite and roadway images. The inputs would include image-based data. The outputs could be geocoded data tables, maps, GIS layers, or summary reports. ",division nutrition physical activity obesity national center chronic disease prevention health promotion interested developing promoting machine learning techniques identify sidewalks bicycle lanes infrastructure images satellite roadway images inputs would include data outputs could geocoded data tables maps gis layers summary reports,1,Asset management
581,Identifying state and local policy provisions that promote or inhibit creating healthy built environments,CDC,Department of Health and Human Services,HHS,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING","The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting natural language processing and machine learning techniques to improve the efficiency of policy surveillance. Inputs are the text of state and local policies, including law (e.g., statute, legislation, regulation, court opinion), procedure, administrative action, etc. and outputs are datasets that capture relevant aspects of the policy as quantifiable information. To date (Apr 2023), DNAPO has not performed this work in-house, but is working with a contractor on various experiments comparing machine learning with traditional methods and identifying CDC, academic and other groups doing related work.",division nutrition physical activity obesity national center chronic disease prevention health promotion interested developing promoting natural language processing machine learning techniques improve efficiency policy surveillance inputs text state local policies including law statute legislation regulation court opinion procedure administrative action etc outputs datasets capture relevant aspects policy quantifiable information date apr dnapo performed work working contractor various experiments comparing machine learning traditional methods identifying cdc academic groups related work,1,Policy-making and public engagement
582,Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking,CDC,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, CLUSTERING, TOPIC MODELING",Development of a Natural Language Processing Topic Modeling tool to improve efficiency for the process of clustering public comments to a 'notice of proposed rulemaking' ,development natural language processing topic modeling tool improve efficiency process clustering public comments proposed rulemaking,4,Policy-making and public engagement
583,Semi-Automated Nonresponse Detection for Surveys (SANDS),CDC,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, NLP","NCHS has developed and release an item nonresponse detection model, to identify cases of item nonresponse (e.g., gibberish, uncertain/don't know, refusals, or high-risk) among open-text responses to help improve survey data and question and questionnaire design. The system is a Natural Language Processing (NLP) model pre-trained using Contrastive Learning and fine-tuned on a custom dataset from survey responses. ",nchs developed release item nonresponse detection model identify cases item nonresponse gibberish know refusals among responses help improve survey data question questionnaire design system natural language processing nlp model using contrastive learning custom dataset survey responses,1,Service delivery
584,Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage,CDC,Department of Health and Human Services,HHS,"MACHINE LEARNING, ML","CDC's National Center for Health Statistics (NCHS) Data Linkage Program has implemented both supervised and unsupervised machine learning (ML) techniques in their linkage algorithms. The Sequential Coverage Algorithm (SCA), a supervised ML algorithm, is used to develop joining methods (or blocking groups) when working with very large datasets. The unsupervised partial Expectation-Maximization (EM) estimation is used to estimate the proportion of pairs that are matches within each block. Both methods improve linkage accuracy and efficiency.",cdc national center health statistics nchs data linkage program implemented supervised unsupervised machine learning ml techniques linkage algorithms sequential coverage algorithm sca supervised ml algorithm used develop joining methods blocking groups working large datasets unsupervised partial em estimation used estimate proportion pairs matches within block methods improve linkage accuracy efficiency,18,Service delivery
585,Coding cause of death information on death certificates to ICD-10,CDC,Department of Health and Human Services,HHS,,MedCoder ICD-10 cause of death codes to the literal text cause of death description provided by the cause of death certifier on the death certificate.  This includes codes for the underlying and contributing causes of death.,medcoder cause death codes literal text cause death description provided cause death certifier death certificate includes codes underlying contributing causes death,9,"""Accessibility"""
586,Detecting Stimulant and Opioid Misuse and Illicit Use,CDC,Department of Health and Human Services,HHS,,Analyze clinical notes to detect illicit use and miscue of stimulants and opioids,analyze clinical notes detect illicit use miscue stimulants opioids,2,"""Program integrity"""
587,AI/ML Model Release Standards,CDC,Department of Health and Human Services,HHS,"AI, ML","NCHS is creating a set of model release standards for AI/ML projects that should be adhered to throughout the Center, and could serve as a starting point for broader standards across the AI/ML development lifecycle to be created at NCHS and throughout CDC.",nchs creating set model release standards projects adhered throughout center could serve starting point broader standards across development lifecycle created nchs throughout cdc,9,Internal operations
588,PII detection using Private AI,CDC,Department of Health and Human Services,HHS,"AI, NLP","NCHS has been evaluating Private AI's NLP solution designed to identify, redact, and replace PII in text data. This suite of models is intended to be used to safely identify and remove PII from free text data sets across platforms within the CDC network.",nchs evaluating private ai nlp solution designed identify redact replace pii text data suite models intended used safely identify remove pii free text data sets across platforms within cdc network,9,Asset management
589,Transcribing Cognitive Interviews with Whisper,CDC,Department of Health and Human Services,HHS,AI,"Current transcription processes for cognitive interviews are limited. Manual transcription is time-consuming and the current automated solution is low quality. Recently, open-sourced AI models have been released that appear to perform substantially better than previous technologies in automated transcription of video/audio. Of note is the model by OpenAI named Whisper (publication, code, model card) which has been made available for under a fully permissive license. Although Whisper is currently considered state-of-the-art compared to other AI models in standard benchmarks, it has not been tested with cognitive interviews. We hypothesize Whisper will produce production quality transcriptions for NCHS. We plan to do a comparison against both VideoBank and a manual transcription. If the results are encouraging, we plan to transcribe all videos from the CCQDER archive. ",current transcription processes cognitive interviews limited manual transcription current automated solution low quality recently ai models released appear perform substantially better previous technologies automated transcription note model openai named whisper publication code model card made available fully permissive license although whisper currently considered compared ai models standard benchmarks tested cognitive interviews hypothesize whisper produce production quality transcriptions nchs plan comparison videobank manual transcription results encouraging plan transcribe videos ccqder archive,5,Service Delivery
590,Named Entity Recognition for Opioid Use in Free Text Clinical Notes from Electronic Health Records,CDC,Department of Health and Human Services,HHS,"NLP, ENTITY RECOGNITION",A team of scientists participating in CDC's Data Science Upskilling Program are developing an NLP Named Entity Recognition model to detect the assertion or negation of opioid use in electronic medical records from the National Hospital Care Survey,team scientists participating cdc data science upskilling program developing nlp named entity recognition model detect assertion negation opioid use electronic medical records national hospital care survey,2,Service delivery:
591,Nowcasting Suicide Trends,CDC,Department of Health and Human Services,HHS,MACHINE LEARNING,"An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' suicide death trends nationally on a week-to-week basis. ",interactive dashboard incorporating multiple traditional datasets machine learning pipeline suicide death trends nationally basis,14,Service delivery:
592,NCIRD SmartFind ChatBots - Public and Internal,CDC,Department of Health and Human Services,HHS,CHATBOTS,"Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search,ï¿½QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps.",develop conversational chatbots public flu public vaccination internal analyze free text questions entered public healthcare providers partners internal staff provide answers best match question developed collaboration microsoft staff pandemic using cognitive services search maker azure healthcare bot power automate sharepoint webapps,14,Service delivery
593,Amazon Lex and Amazon Polly for the Marketplace Appeals Call Center,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,CHATBOTS,"CMS/OHI: Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center. Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information by designing chatbots using existing call center transcripts. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products.",amazon lex amazon polly used conjunction amazon connect phone system cloud based marketplace appeals call center amazon lex offers capabilities virtual contact center agents interactive voice response ivr information response automation maximizing information designing chatbots using existing call center transcripts amazon polly turns text speech allowing program create applications talk build entirely new categories products,14,Service / benefits access
594,Feedback Analysis Solution (FAS),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING, ML, NLP","The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  ",feedback analysis solution system uses cms publicly available data review public comments analyze information internal external stakeholders fas uses natural language processing nlp tools aggregate sort identify duplicates create efficiencies comment review process fas also uses machine learning ml tools identify topics themes sentiment outputs targeted dataset,18,Policy-making and public engagement: use of AI in any stage of developing regulations or gathering input
595,Predictive Intelligence - Incident Assignment for Quality Service Center (QSC).,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,PREDICTIVE INTELLIGENCE,Predictive Intelligence (PI) is used for incident assignment within the Quality Service Center (QSC). The solution runs on incidents created from the ServiceNow Service Portal (https://cmsqualitysupport.servicenowservices.com/sp_ess). The solution analyzes the short description provided by the end user in order to find key words with previously submitted incidents and assigns the ticket to the appropriate assignment group. This solution is re-trained with the incident data in our production instance every 3-6 months based on need.,predictive intelligence pi used incident assignment within quality service center qsc solution runs incidents created servicenow service portal https solution analyzes short description provided end user order find key words previously submitted incidents assigns ticket appropriate assignment group solution incident data production instance every months based need,5,"""Hotlines and service desks"""
596,Fraud Prevention System Alert Summary Report Priority Score,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,"This model will use Medicare administrative, claims, and fraud alert and investigations data to predict the likelihood of an investigation leading to an administrative action (positive outcome), supporting CMS in prioritizing their use of investigations resources. This analysis is still in development and the final model type has not been determined yet.",model use medicare administrative claims fraud alert investigations data predict likelihood investigation leading administrative action positive outcome supporting cms prioritizing use investigations resources analysis still development final model type determined yet,1,Topic: Program integrity
597,"Center for Program Integrity (CPI) Fraud Prevention System Models (e.g. DMEMBITheftML, HHAProviderML)",Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,RANDOM FOREST,"These models use Medicare administrative and claims  data to identify potential cases of fraud, waste, and abuse for future investigation using random forest techniques. Outputs are used to alert investigators of the potential fraud scheme and associated providers.",models use medicare administrative claims data identify potential cases fraud waste abuse future investigation using random forest techniques outputs used alert investigators potential fraud scheme associated providers,2,Program integrity
598,Priority Score Model - ranks providers within the Fraud Prevention System using logistic regression based on program integrity guidelines.,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"REGRESSION, LOGISTIC REGRESSION","Inputs - Medicare Claims data, Targeted Probe and Educate (TPE) Data, Jurisdiction information
Output -  ranks providers within the FPS system using logistic regression based on program integrity guidelines.",inputs medicare claims data targeted probe educate tpe data jurisdiction information output ranks providers within fps system using logistic regression based program integrity guidelines,7,Service / benefits access
599,"Priority Score Timeliness - forecast the time needed to work on an alert produced by Fraud Prevention System (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)",Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"REGRESSION, RANDOM FOREST","Inputs - Medicare Claims data, TPE Data, Jurisdiction information
Output -  forecast the time needed to work on an alert produced by FPS (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)",inputs medicare claims data tpe data jurisdiction information output forecast time needed work alert produced fps random forest decision tree gradient boost generalized linear regression,2,Service delivery
600,CCIIO Enrollment Resolution and Reconciliation System (CERRS),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"CLASSIFICATION, AI",CERRS AI for Classification,cerrs ai classification,15,Asset Management
601,Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"AI, ML, NLP","Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits",intake pa uses advanced capabilities nlp ocr ai ml automate modernize reduce manual efforts related medical record review functions within radv audits,18,"Here is the identified topic:

Case management"
602,CMS Connect (CCN),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,AI,CCN AI for Global Search ,ccn ai global search,6,Service delivery
603,CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,AI,CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management,cms enterprise portal ai process efficiency knowledge management,4,Topic: Service delivery
604,Federally Facilitated Marketplaces (FFM),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"CLASSIFICATION, AI",FFM AI for Anomaly Detection and Correction| Classification| Forecasting and Predicting Time Series,ffm ai anomaly detection forecasting predicting time series,12,Service delivery
605,Marketplace Learning Management System (MLMS),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,AI,MLMS AI for Language Interpretation and Translation,mlms ai language interpretation translation,9,Accessibility
606,Medicaid And CHIP Financial (MACFin) Anomaly Detection Model for DSH Audit,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"MACHINE LEARNING, AI","MACFin AI team developed machine learning model to predict anomalies within DSH audit data. The model flags top outliers in the submitted DSH hospitals data in terms of extreme behavior in the data based on amounts and other characteristics of the data to isolate the most outliers in the data. For example, out of all DSH allocations, the model can identify the top 1-5% outliers in the data for further review and auditing. Such model facilitates targeted investigations for gaps and barriers. In addition, the model can support the process by minimizing overpayment and/or underpayment and amounts redistribution",macfin ai team developed machine learning model predict anomalies within dsh audit data model flags top outliers submitted dsh hospitals data terms extreme behavior data based amounts characteristics data isolate outliers data example dsh allocations model identify top outliers data review auditing model facilitates targeted investigations gaps barriers addition model support process minimizing overpayment underpayment amounts redistribution,1,Topic: Program integrity
607,Medicaid And CHIP Financial (MACFin) DSH Payment Forecasting model,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,MACHINE LEARNING,"Forecasting model to predict future DSH payment (next 1 year) based on historical data and trends (ex: last 1-3 years). Multiple models were trained based on time series (i.e., statistical models) and machine learning based model and compared for best performance in terms of average means error on DSH payment amount across all hospitals. DSH data were highly disorganized, the team spent time cleaning and combing the data from over 6 years for all states to conduct full model implementation and meaningful analysis. Predicting future DSH payment facilitates early planning and recommendations around trends, redistributions, etc. Modified models can also be built to predict other DSH-related metrics like payment-to-uncompensated ratio, underpayment, or overpayment",forecasting model predict future dsh payment next year based historical data trends ex last years multiple models trained based time series statistical models machine learning based model compared best performance terms average means error dsh payment amount across hospitals dsh data highly disorganized team spent time cleaning combing data years states conduct full model implementation meaningful analysis predicting future dsh payment facilitates early planning recommendations around trends redistributions etc modified models also built predict metrics like ratio underpayment overpayment,1,Service delivery
608,Performance Metrics Database and Analytics (PMDA),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,AI,PMDA AI for Anomaly Detection and Correction| Language Interpretation and Translation| Knowledge Management,pmda ai anomaly detection language interpretation knowledge management,12,"""Service Delivery"""
609,"Relationships, Events, Contacts, and Outreach Network (RECON)",Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,AI,RECON AI for Recommender System| Sentiment Analysis,recon ai recommender sentiment analysis,12,Service Delivery
610,Risk Adjustment Payment Integrity Determination System (RAPIDS),Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,"CLASSIFICATION, AI",RAPIDS AI for Classification| Process Efficiency Improvement,rapids ai process efficiency improvement,4,Service delivery
611,Drug Cost Increase Predictions,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,Use Historical drug costs increases to predict future increases,use historical drug costs increases predict future increases,9,"""Asset management"""
612,Brand vs Generic Market Share,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,Analyze generic drugs compared to brand drugs over time and forecast future market shares based on Part D claims volume,analyze generic drugs compared brand drugs time forecast future market shares based part claims volume,2,"""Service / benefits access"""
613,Drug cost anomaly detection,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,Identify anomalies in drug costs on Part D claims,identify anomalies drug costs part claims,9,"""Program integrity"""
614,Artificial Intelligence (AI) Explorers Program Pilot - Automated Technical Profile,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,90 day Pilot is to engage in research and development to investigate applications in the generation of a machine-readable Automated Technical Profile for CMS systems with the goal of inferring the technology fingerprint of CMS projects based on multiple data sources at different stages of their development lifecycle,day pilot engage research development investigate applications generation automated technical profile cms systems goal inferring technology fingerprint cms projects based multiple data sources different stages development lifecycle,19,Asset management
615,Artificial Intelligence (AI) Explorers Program Pilot - Section 508 accessibility Testing,Centers for Medicare & Medicaid Services (CMS),Department of Health and Human Services,HHS,,90 day Pilot is to better inform CMS technical leads and Application Development Organizations (ADOs) to conduct a comprehensive analysis on the data from the test result documents in support of the CMS Section 508 Program.,day pilot better inform cms technical leads application development organizations ados conduct comprehensive analysis data test result documents support cms section program,9,Accessibility
616,Process Large Amount of Submitted Docket Comments,FDA,Department of Health and Human Services,HHS,"AI, ML","Provide an automated process to transfer, deduplicate, summarize and cluster docket comments using AI/ML",provide automated process transfer deduplicate summarize cluster docket comments using,12,Service delivery
617,To develop novel approaches to expand and/or modify the vaccine AESI phenotypes in order to further improve adverse event detection,FDA,Department of Health and Human Services,HHS,ML,Developing a BERT-like ML model to improve detection of adverse events of special interest by applying a clinical-oriented language models pre-trained using the clinical documents from UCSF,developing ml model improve detection adverse events special interest applying language models using clinical documents ucsf,12,Topic: Asset management
618,"BEST Platform improves post-market surveillance efforts through the semi-automated detection, validation and reporting of adverse events.",FDA,Department of Health and Human Services,HHS,"ML, NLP","The BEST Platform employs a suite of applications and techniques to improve the detection, validation and reporting of  biologics-related adverse events from electronic health records (EHRs). The Platform utilizes ML and NLP to detect potential adverse events, and extract the important features for clinicians to validate.  ",best platform employs suite applications techniques improve detection validation reporting adverse events electronic health records ehrs platform utilizes ml nlp detect potential adverse events extract important features clinicians validate,12,Service / benefits access
619,Development of Machine Learning Approaches to Population Pharmacokinetic Model Selection and Evaluation of Application to Model-Based Bioequivalence Analysis,FDA,Department of Health and Human Services,HHS,"REINFORCEMENT LEARNING, DEEP LEARNING","1. Development of a deep learning/reinforcement learning approach to population pharmacokinetic model selections
2. Implementation of an established Genetic algorithm approach to population pharmacokinetic model selections in Python.",development deep learning approach population pharmacokinetic model selections implementation established genetic algorithm approach population pharmacokinetic model selections python,0,"""Asset management"""
620,Machine-Learning based Heterogeneous Treatment Effect Models for Prioritizing Product-Specific Guidance Development,FDA,Department of Health and Human Services,HHS,"MACHINE LEARNING, DATA-DRIVEN","In this project, we propose to develop and implement a novel machine learning algorithm
for estimating heterogeneous treatment effects to prioritize PSG development.
Specifically, we propose three major tasks. First, we will address an important problem in
treatment effect estimation from observational data, where the observed variables may
contain confounders, i.e., variables that affect both the treatment and the outcome. We
will build on recent advances in variational autoencoder to introduce a data-driven method
to simultaneously estimate the hidden confounders and the treatment effect. Second, we
will evaluate our model on both synthetic datasets and previous treatment effect
estimation benchmarks. The ground truth data enable us to investigate model
interpretability. Third, we will validate the model with the real-world PSG data and explain
model output for a particular PSG via collaborating with FDA team. The real-world
datasets are crucial to validate our model, which may include Orange Book, FDAï¿½ï¿½s PSGs,
National Drug Code directory database, Risk Evaluation and Mitigation Strategies
(REMS) data and IQVIA National Sales Perspectives that are publicly available, as well
as internal ANDA submission data.",project propose develop implement novel machine learning algorithm estimating heterogeneous treatment effects prioritize psg development specifically propose three major tasks first address important problem treatment effect estimation observational data observed variables may contain confounders variables affect treatment outcome build recent advances variational autoencoder introduce method simultaneously estimate hidden confounders treatment effect second evaluate model synthetic datasets previous treatment effect estimation benchmarks ground truth data enable us investigate model interpretability third validate model psg data explain model output particular psg via collaborating fda team datasets crucial validate model may include orange book psgs national drug code directory database risk evaluation mitigation strategies rems data iqvia national sales perspectives publicly available well internal anda submission data,9,Topic: People operations
621,Developing Tools based on Text Analysis and Machine Learning to Enhance PSG Review Efficiency,FDA,Department of Health and Human Services,HHS,TEXT SUMMARIZATION,"1. Develop a novel neural summarization model in tandem with information retrieval system, tailored for PSG review, with dual attention over both sentence-level and word-level outputs by taking advantage of both extractive and abstractive summarization.
2. Evaluate the new model with the PSG data and the large CNN/Daily Mail dataset. 
3. Develop an open-source software package for text summarization model and the information retrieval system.",develop novel neural summarization model tandem information retrieval system tailored psg review dual attention outputs taking advantage extractive abstractive summarization evaluate new model psg data large mail dataset develop software package text summarization model information retrieval system,9,"""Asset management"" and ""Internal operations"""
622,BEAM (Bioequivalence Assessment Mate) - a Data/Text Analytics Tool to Enhance Quality and Efficiency of Bioequivalence Assessment,FDA,Department of Health and Human Services,HHS,"MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, AI, ML","We aim to develop BEAM using verified data analytics packages, text mining, and artificial intelligence (AI) toolsets (including machine learning (ML)), to streamline the labor-intensive work during BE assessments to facilitate high-quality and efficient regulatory assessments.
",aim develop beam using verified data analytics packages text mining artificial intelligence ai toolsets including machine learning ml streamline work assessments facilitate efficient regulatory assessments,2,Service / benefits access
623,Application of Statistical Modeling and Natural Language Processing for Adverse Event Analysis,FDA,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, NLP","Drug-induced adverse events (AEs) are difficult to predict for early signal detection, and there is a need to develop new tools and methods to monitor the safety of marketed drugs, including novel approaches for evidence generation. This project will utilize natural language processing (NLP) and data mining (DM) to extract information from approved drug labeling that can be used for statistical modeling to determine when the selected AEs are generally labeled (pre- or post-market) and identify patterns of detection, such as predictive factors, within the first 3 years of marketing of novel drugs. This project is intended to increase our understanding of timing/early detection of AEs, which can be applied to targeted monitoring of novel drugs. Funding will be used to support an ORISE fellow.",adverse events aes difficult predict early signal detection need develop new tools methods monitor safety marketed drugs including novel approaches evidence generation project utilize natural language processing nlp data mining dm extract information approved drug labeling used statistical modeling determine selected aes generally labeled identify patterns detection predictive factors within first years marketing novel drugs project intended increase understanding detection aes applied targeted monitoring novel drugs funding used support orise fellow,11,Topic_name: Program integrity
624,Centers of Excellence in Regulatory Science and Innovation (CERSI) project - Leveraging AI for improving remote interactions.,FDA,Department of Health and Human Services,HHS,SEQ2SEQ,"This project aims to improve four major areas identified by FDA, including transcription, translation, document and evidence management, and co-working space. Automatic speech recognition has been widely used in many applications. Its cutting-edge technology is transformer-based sequence to sequence (seq2seq) model, which is trained to generate transcripts autoregressively and has been fine-tuned on certain datasets. Using pre-trained language models directly may not be suitable because they might not work properly with different accents and specialized regulatory and scientific terminologies. This is because the models were trained on a specific type of data and may not be able to handle data that is significantly different from what they were trained on. To address this, researchers plan to manually read a set of video/audio to obtain their true transcripts, upon which they fine-tune the model to make it adapt to this new domain. Machine translation converts a sequence of text from one language to another. Researchers usually use a method called ""seq2seq,"" where original text is codified into a language that a computer can understand. Then, we use this code to generate the translated version of the text. It's like a translator who listens to someone speak in one language and then repeats what they said in another language. Similarly, it is not appropriate to directly apply the existing pre-trained seq2seq models, because (a) some languages used in the FDA context might not exist in existing models. (b) domain specific terms used in FDA are very different from general human languages. To tackle these challenges, models are trained for some unusual languages and fine-tune pre-trained models for major languages. For both situations, researchers prepare high-quality training set labeled by experts. University of Maryland CERSI (M-CERSI) plans to build a system to manage different documents and evidence, by implementing three sub-systems: (a) document classifier, (b) video/audio classifier, and (c) an interactive middleware that connects the trained model at the backend and the input at the frontend. With this, all documents created during co-working can be shared and accessed by all participants.",project aims improve four major areas identified fda including transcription translation document evidence management space automatic speech recognition widely used many applications technology sequence sequence model trained generate transcripts autoregressively certain datasets using language models directly may suitable might work properly different accents specialized regulatory scientific terminologies models trained specific type data may able handle data significantly different trained address researchers plan manually read set obtain true transcripts upon model make adapt new domain machine translation converts sequence text one language another researchers usually use method called original text codified language computer understand use code generate translated version text like translator listens someone speak one language repeats said another language similarly appropriate directly apply existing models languages used fda context might exist existing models b domain specific terms used fda different general human languages tackle challenges models trained unusual languages models major languages situations researchers prepare training set labeled experts university maryland cersi plans build system manage different documents evidence implementing three document classifier b classifier c interactive middleware connects trained model backend input frontend documents created shared accessed participants,9,Topic 8: Service Delivery
625,Opioid Data Warehouse Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics,FDA,Department of Health and Human Services,HHS,,"The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics use publicly available social media and forensic chemistry data to identify novel referents to drug products in social media text. It uses the FastText library to create vector models of each known NSO-related term in a large social media corpus, and provides users with similarity scores and expected prevalence estimates for lists of terms that could be used to enhance future data gathering efforts. ",term identification novel synthetic opioid detection evaluation analytics use publicly available social media forensic chemistry data identify novel referents drug products social media text uses fasttext library create vector models known term large social media corpus provides users similarity scores expected prevalence estimates lists terms could used enhance future data gathering efforts,9,Service / benefits access
626,Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS),FDA,Department of Health and Human Services,HHS,NATURAL LANGUAGE PROCESSING,The deduplication algorithm is applied to nonpublic data in the FDA Adverse Event Reporting System (FAERS) to identify duplicate individual case safety reports (ICSRs). Unstructured data in free text FAERS narratives is processed through a natural language processing system to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record linkage approach to identify duplicates. Application of the deduplication algorithm is optimized for processing entire FAERS database to support datamining. ,deduplication algorithm applied nonpublic data fda adverse event reporting system faers identify duplicate individual case safety reports icsrs unstructured data free text faers narratives processed natural language processing system extract relevant clinical features structured unstructured data used probabilistic record linkage approach identify duplicates application deduplication algorithm optimized processing entire faers database support datamining,9,Topic: Asset management
627,Information Visualization Platform (InfoViP) to support analysis of individual case safety reports,FDA,Department of Health and Human Services,HHS,"ARTIFICIAL INTELLIGENCE, VISUALIZATION","Developed the Information Visualization Platform (InfoViP) for post market safety surveillance, to improve the efficiency and scientific rigor of Individual Case Study Reports (ICSRs) review and evaluation process. InfoViP incorporates artificial intelligence and advanced visualizations to detect duplicate ICSRs, create temporal data visualization, and classify ICSRs for useability. ",developed information visualization platform infovip post market safety surveillance improve efficiency scientific rigor individual case study reports icsrs review evaluation process infovip incorporates artificial intelligence advanced visualizations detect duplicate icsrs create temporal data visualization classify icsrs useability,14,Topic: Asset management
628,Using Unsupervised Learning to Generate Code Mapping Algorithms to Harmonize Data Across Data Systems,FDA,Department of Health and Human Services,HHS,,The goal of this project is to assess the potential of dataï¿½ï¿½driven statistical methods for detecting and reducing coding differences between healthcare systems in Sentinel. Findings will inform development and deployment of methods and computational tools for transferring knowledge learned from one site to another and pave the way towards scalable and automated harmonization of electronic health records data.,goal project assess potential statistical methods detecting reducing coding differences healthcare systems sentinel findings inform development deployment methods computational tools transferring knowledge learned one site another pave way towards scalable automated harmonization electronic health records data,2,Internal operations
629,Augmenting date and cause of death ascertainment in observational data sources,FDA,Department of Health and Human Services,HHS,,"The objective of this project is to develop a set of algorithms to augment assessment of mortality through probabilistic linkage of alternative data sources with EHRs. Development of generalizable approaches to improve death ascertainment is critical to improve validity of Sentinel investigations using mortality as an endpoint, and these algorithms may also be usable in supplementing death ascertainment in claims data as well. Specifically, we propose the following Aims.
Specific Aim 1: We propose to leverage online publicly available data to detect date of death for patients seen at two healthcare systems.
Specific Aim 2: We propose to augment cause of death data using healthcare system narrative text and administrative codes to develop probabilistic estimates for common causes of death",objective project develop set algorithms augment assessment mortality probabilistic linkage alternative data sources ehrs development generalizable approaches improve death ascertainment critical improve validity sentinel investigations using mortality endpoint algorithms may also usable supplementing death ascertainment claims data well specifically propose following aims specific aim propose leverage online publicly available data detect date death patients seen two healthcare systems specific aim propose augment cause death data using healthcare system narrative text administrative codes develop probabilistic estimates common causes death,2,Service delivery
630,Scalable automated NLP-assisted chart abstraction and feature extraction tool,FDA,Department of Health and Human Services,HHS,NLP,"The overall goal of this study is to demonstrate the usability and value of currently available data sources and techniques in electronic medical records by harnessing claims and EHR data, including structured, semi-structured, and unstructured data, in a pharmacoepidemiology study. This study will use real-world longitudinal data from the Cerner Enviza Electronic Health Records (CE EHR) linked to claims with NLP technology applied to physician notes. NLP methods will be used to identify and contextualize pre-exposure confounding variables, incorporate unstructured EHR data into confounding adjustment, and for outcome ascertainment. Use case study; This study will seek to understand the relationship between use of montelukast among patients with asthma and neuropsychiatric events.",overall goal study demonstrate usability value currently available data sources techniques electronic medical records harnessing claims ehr data including structured unstructured data pharmacoepidemiology study study use longitudinal data cerner enviza electronic health records ce ehr linked claims nlp technology applied physician notes nlp methods used identify contextualize confounding variables incorporate unstructured ehr data confounding adjustment outcome ascertainment use case study study seek understand relationship use montelukast among patients asthma neuropsychiatric events,7,Internal operations
631,MASTER PLAN Y4,FDA,Department of Health and Human Services,HHS,NATURAL LANGUAGE PROCESSING,"The overall mission of the Innovation Center is to integrate longitudinal patient-level EHR data into the Sentinel System to enable in-depth investigations of medication outcomes using richer clinical data than are generally not available in insurance claims data. The Master Plan lays out a five-year roadmap for the Sentinel Innovation Center to achieve this vision through four key strategic areas: (1) data infrastructure; (2) feature engineering; (3) causal inference; and (4) detection analytics. The projects focus on utilizing emerging technologies including feature engineering, natural language processing, advanced analytics, and data interoperability to improve Sentinel's capabilities.",overall mission innovation center integrate longitudinal ehr data sentinel system enable investigations medication outcomes using richer clinical data generally available insurance claims data master plan lays roadmap sentinel innovation center achieve vision four key strategic areas data infrastructure feature engineering causal inference detection analytics projects focus utilizing emerging technologies including feature engineering natural language processing advanced analytics data interoperability improve sentinel capabilities,2,"Topic 10. Internal operations: administrative use cases for AI, e.g. notetaking, virtual assistants"
632,Onboarding of EHR data partners,FDA,Department of Health and Human Services,HHS,,"In the currently proposed project (DI6), structured fields from EHRs and linked claims data from two identified commercial data partners will be converted to the Sentinel Common Data Model (SCDM). The SCDM is an organizing CDM that preserves the original information from a data source and has been successfully used in the Sentinel system for over a decade. While originally built for claims data, SCDM was expanded in 2015 to accommodate some information commonly found in EHRs in separate clinical data tables to capture laboratory test results of interest and vital signs. We selected the SCDM over other CDMs because data formatted in the SCDM enables analyses that can leverage the standardized active risk identification and analysis (ARIA) tools. Operationally, both Data Partners will share SCDM transformed patient-level linked EHR-claims data with the IC after quality assessments are passed. This is a substantial advantage in this early stage of understanding how to optimally analyze such data. It will allow Sentinel investigators to directly work with the data, adapt existing analytic programs, and test algorithms. In sum, transformation of structured data from the proposed sources to SCDM format will be a key first step for potential future incorporation of these Data Partners into Sentinel to provide access to EHR-claims linked data for >10 million patients, which will be critical to meet the need identified in the 5-year Sentinel System strategic plan of 2019.",currently proposed project structured fields ehrs linked claims data two identified commercial data partners converted sentinel common data model scdm scdm organizing cdm preserves original information data source successfully used sentinel system decade originally built claims data scdm expanded accommodate information commonly found ehrs separate clinical data tables capture laboratory test results interest vital signs selected scdm cdms data formatted scdm enables analyses leverage standardized active risk identification analysis aria tools operationally data partners share scdm transformed linked data ic quality assessments passed substantial advantage early stage understanding optimally analyze data allow sentinel investigators directly work data adapt existing analytic programs test algorithms sum transformation structured data proposed sources scdm format key first step potential future incorporation data partners sentinel provide access linked data million patients critical meet need identified sentinel system strategic plan,2,Internal operations
633,Creating a development network,FDA,Department of Health and Human Services,HHS,,"This project has the following specific Aims:
Aim 1: To convert structured data from EHRs and linked claims into Sentinel Common Data Model at each of the participating sites
Aim 2: To develop a standardized process for storage of free text notes locally at each site and develop steps for routine meta data extraction from these notes for facilitating direct investigator access for timely execution of future Sentinel tasks",project following specific aims aim convert structured data ehrs linked claims sentinel common data model participating sites aim develop standardized process storage free text notes locally site develop steps routine meta data extraction notes facilitating direct investigator access timely execution future sentinel tasks,2,Topic: Case management
634,Empirical evaluation of EHR-based signal detection approaches,FDA,Department of Health and Human Services,HHS,NATURAL LANGUAGE PROCESSING,"This project will develop approaches for abstracting and combining structured and unstructured EHR data as well as expanding TBSS methods to also identify signals for outcomes identifiable only through EHR data (e.g. natural language processing, laboratory values).",project develop approaches abstracting combining structured unstructured ehr data well expanding tbss methods also identify signals outcomes identifiable ehr data natural language processing laboratory values,2,Asset management
635,Label comparison tool to support identification of safety-related changes in drug labeling,FDA,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, AI","A tool with AI capabilities used to assist humans in their review and comparison of drug labeling in PDF format to identify safety-related changes occurring over time. The FDA uses postmarket data to update drug labeling, which can include new and a broad range safety-related issues; safety updates may be added to various sections of drug labeling. The tool's BERT natural language processing was trained to identify potential text related to newly added safety issues between drug labeling. ",tool ai capabilities used assist humans review comparison drug labeling pdf format identify changes occurring time fda uses postmarket data update drug labeling include new broad range issues safety updates may added various sections drug labeling tool bert natural language processing trained identify potential text related newly added safety issues drug labeling,9,Service delivery
636,Artificial Intelligence (AI) Supported Annotation of FAERS Reports,FDA,Department of Health and Human Services,HHS,NLP,"Develop a prototype software application to support the humanï¿½review of FAERS data by developing computational algorithms to semi-automatically categorizing FAERS reports into meaningful medication error categories based on report free text. Leveraged existing annotated reports and worked with subject matter experts to annotate subsets of FAERS reports, to generate initial NLP algorithms that can classify any report as being medication related and with an identified type of medication error. An innovative active learning approach was then used to annotate reports and build more robust algorithms for more accurate categorization. ",develop prototype software application support faers data developing computational algorithms categorizing faers reports meaningful medication error categories based report free text leveraged existing annotated reports worked subject matter experts annotate subsets faers reports generate initial nlp algorithms classify report medication related identified type medication error innovative active learning approach used annotate reports build robust algorithms accurate categorization,8,"""Program integrity"""
637,Community Level Opioid Use Dynamics Modeling and Simulation,FDA,Department of Health and Human Services,HHS,"MACHINE LEARNING, CLASSIFICATION, ARTIFICIAL INTELLIGENCE, ML","The OUD project leverages artificial intelligence techniques, specifically Agent-Based Modeling (ABM), to design and carry out Community Level Opioid Use Dynamics Modeling and Simulation with a cohort of datasets and to investigate the propagation mechanisms involving various factors including geographical and social influences and more, and their impacts at a high level. The project also leveraged Machine Learning (ML), such as Classification, to identify data entry types (e.g., whether a particular data entry is entered by a person in the target population, e.g., a woman of child-bearing ages) as part of the training data generation task. ",oud project leverages artificial intelligence techniques specifically modeling abm design carry community level opioid use dynamics modeling simulation cohort datasets investigate propagation mechanisms involving various factors including geographical social influences impacts high level project also leveraged machine learning ml classification identify data entry types whether particular data entry entered person target population woman ages part training data generation task,5,Topic: Internal operations
638,Automatic Recognition of Individuals by Pharmacokinetic Profiles to Identify Data Anomalies,FDA,Department of Health and Human Services,HHS,MACHINE LEARNING,"In efforts to detect data anomalies under ANDA, Office of Biostatistics, Division of Biometrics VIII created an R shiny application, DABERS (Data Anomalies in BioEquivalence R Shiny) to support OSIS and OGD. Despite its demonstrated effectiveness, a major drawback is that the pharmacokinetics and pharmacodynamics may be too complicated to describe with a single statistic. Indeed, the current practice offers no practical guidelines regarding how similar PK profiles from different subjects can be in order to be considered valid. This makes it difficult to assess the adequacy of data to be accepted for an ANDA and requires additional information requests to applicants. This project will address the current gap in identifying the data anomalies and potential data manipulations by use of state-of-the-art statistical methods, specifically focusing on machine learning and data augmentation. The purpose of the project is twofold.  First, from a regulatory perspective, our project will provide a data driven method that can model complex patterns of PK data to identify potential data manipulations under an ANDA. Second, from a public health research and drug development point of view, the proposed study can potentially be used to understand and quantify the variability in drug response, to guide stratification and targeting of patient subgroups, and to provide insight into what the right drug and right range of doses are for those subgroups.",efforts detect data anomalies anda office biostatistics division biometrics viii created r shiny application dabers data anomalies bioequivalence r shiny support osis ogd despite demonstrated effectiveness major drawback pharmacokinetics pharmacodynamics may complicated describe single statistic indeed current practice offers practical guidelines regarding similar pk profiles different subjects order considered valid makes difficult assess adequacy data accepted anda requires additional information requests applicants project address current gap identifying data anomalies potential data manipulations use statistical methods specifically focusing machine learning data augmentation purpose project twofold first regulatory perspective project provide data driven method model complex patterns pk data identify potential data manipulations anda second public health research drug development point view proposed study potentially used understand quantify variability drug response guide stratification targeting patient subgroups provide insight right drug right range doses subgroups,7,Topic: Asset management
639,CluePoints CRADA,FDA,Department of Health and Human Services,HHS,MACHINE LEARNING,"This project uses unsupervised machine learning to detect and identify data anomalies in clinical trial data at the site, country and subject levels.  This project will consider multiple use cases with the goals of improving data quality and data integrity, assist site selection for inspection, and assist reviewers by identifying potentially problematic sites for sensitivity analyses. ",project uses unsupervised machine learning detect identify data anomalies clinical trial data site country subject levels project consider multiple use cases goals improving data quality data integrity assist site selection inspection assist reviewers identifying potentially problematic sites sensitivity analyses,2,Topic: Service / benefits access
640,Clinical Study Data Auto-transcribing Platform (AI Analyst) for Generating Evidence to Support Drug Labelling,FDA,Department of Health and Human Services,HHS,AI,"The AI Analyst platform is trained to auto-author clinical study reports from the source data to assess the strength and robustness of analytical evidence for supporting drug labelling languages.  The platform directly transcribes SDTM (Study Data Tabulation Model) datasets of phase I/II studies into full-length clinical study reports autonomously with minimal human input.  The underlying AI algorithm mimics the subject matter experts (e.g., clinicians, statisticians, and data managers) thinking process to decipher the full details of study design and conduct, and interpret the study results according to the study design.  It consists of multiple layers of data pattern recognitions.  The algorithm addresses the challenging nature of assessing clinical study results, including huge variety of study designs, unpredictable study conduct, variations of data reporting nomenclature/format, and wide range of study-specific analysis methods.  The platform has been trained and tested with hundreds of NDA/BLA submissions and over 1500 clinical trials.  The compatible study types include most drug label supporting studies, such as drug interaction, renal/hepatic impairment, and bioequivalence.  In 2022, the Office of Clinical Pharmacology (OCP/OTS/CDER) initiated the RealTime Analysis Depot (RAD) project aiming to routinely apply the AI platform to support the review of NME, 505b2 and 351K submissions.",ai analyst platform trained clinical study reports source data assess strength robustness analytical evidence supporting drug labelling languages platform directly transcribes sdtm study data tabulation model datasets phase studies clinical study reports autonomously minimal human input underlying ai algorithm mimics subject matter experts clinicians statisticians data managers thinking process decipher full details study design conduct interpret study results according study design consists multiple layers data pattern recognitions algorithm addresses challenging nature assessing clinical study results including huge variety study designs unpredictable study conduct variations data reporting wide range analysis methods platform trained tested hundreds submissions clinical trials compatible study types include drug label supporting studies drug interaction impairment bioequivalence office clinical pharmacology initiated realtime analysis depot rad project aiming routinely apply ai platform support review nme submissions,9,Topic: Asset Management
641,Data Infrastructure Backbone for AI applications,FDA,Department of Health and Human Services,HHS,DECISION MAKING,"OFAS is creating a data lake (WILEE knowledgebase) that ingests and integrates data from a variety of data sources to assist our use of advance analytics in driving risked based decision making. The sources of data include, internal stakeholder submission data, data generated by OFAS staff, scientific information from PubMed, NIH and other scientific publications, CFSAN generated data such as the total diet study, news articles and blog posts, publications from sister agencies, food ingredient and packaging data, food sales data etc. The design of this data store allows for the automated ingestion of new data while allowing for manual curation where necessary. It is also designed to enable the identification, acquisition and integration of new data sources as they become available. The design of the data lake centralizes information about CFSAN regulated products, food additives, color additives, GRAS substances and food contact substance and integrates the different sources of information with stakeholder submission information contained in FARM and cheminformatics information in CERES enabling greater insights and a more efficient knowledge discovery during review of premarket submissions and post market monitoring of the U.S food supply. ",ofas creating data lake wilee knowledgebase ingests integrates data variety data sources assist use advance analytics driving risked based decision making sources data include internal stakeholder submission data data generated ofas staff scientific information pubmed nih scientific publications cfsan generated data total diet study news articles blog posts publications sister agencies food ingredient packaging data food sales data etc design data store allows automated ingestion new data allowing manual curation necessary also designed enable identification acquisition integration new data sources become available design data lake centralizes information cfsan regulated products food additives color additives gras substances food contact substance integrates different sources information stakeholder submission information contained farm cheminformatics information ceres enabling greater insights efficient knowledge discovery review premarket submissions post market monitoring food supply,7,Topic: Asset management
642,"AI Engine for Knowledge discovery, Post-market Surveillance and Signal Detection",FDA,Department of Health and Human Services,HHS,"ARTIFICIAL INTELLIGENCE, AI, DECISION-MAKING","The use of Artificial Intelligence in post-market surveillance and signal detection will enhance CFSAN's ability to detect potential problems associated with CFSAN commodities, including leveraging data to investigate potential issues with chronic, long-term exposure to food additives, color additives, food contact substances and contaminants or long-term use of cosmetics. OFAS Warp Intelligent Learning Engine (WILEE) project seeks establish an intelligent knowledge discovery and analytic agent for the Office. WILEE (pronounced Wiley) provides a horizon-scanning solution, analyzing data from the WILEE knowledgebase, to enable the Office to maintain a proactive posture and the capacity to forecast industry trends so that the Office can stay ahead of the development cycle and prepare for how to handle a large influx of submissions (operational risk - e.g., change in USDA rules regarding antimicrobial residue levels in poultry processing), prioritize actions based on risk or stakeholder perceived risk regarding substances under OFAS purview (e.g., yoga mat incident). WILEE will provide the Office with an advanced data driven risked based decision-making tool, that leverages AI technologies to integrate and process a large variety of data sources, generating reports with quick insights that will significantly improve our time-to-results. ",use artificial intelligence surveillance signal detection enhance cfsan ability detect potential problems associated cfsan commodities including leveraging data investigate potential issues chronic exposure food additives color additives food contact substances contaminants use cosmetics ofas warp intelligent learning engine wilee project seeks establish intelligent knowledge discovery analytic agent office wilee pronounced wiley provides solution analyzing data wilee knowledgebase enable office maintain proactive posture capacity forecast industry trends office stay ahead development cycle prepare handle large influx submissions operational risk change usda rules regarding antimicrobial residue levels poultry processing prioritize actions based risk stakeholder perceived risk regarding substances ofas purview yoga mat incident wilee provide office advanced data driven risked based tool leverages ai technologies integrate process large variety data sources generating reports quick insights significantly improve,18,"""Program integrity"""
643,Emerging Chemical Hazard Intelligence Platform (ECHIP - completed),FDA,Department of Health and Human Services,HHS,AI,"This is an AI solution designed to identify emerging, potential chemical hazards or emerging stakeholder concerns regarding potential hazards associated with substances of interest to CFSAN. Implementation of this solution will enable CFSAN to take proactive measures to protect and/or address concerns from our stakeholders. ECHIP uses data from the news and social media, and the scientific literature to identify potential issues that may require CFSAN's attention. Real world examples without the ECHIP AI solution have taken 2-4 weeks for signal identification and verification depending on the number of scientists dedicated to reviewing the open literature, news and social media.  Results from pilot studies indicate that ECHIP could reduce the overall signal detection and validation process to about 2 hours. ECHIP accomplishes this reduction by automatically ingesting, reviewing, analyzing and presenting data from multiple sources to scientists in such a way that signal detection and verification can be done an a very short time period.",ai solution designed identify emerging potential chemical hazards emerging stakeholder concerns regarding potential hazards associated substances interest cfsan implementation solution enable cfsan take proactive measures protect address concerns stakeholders echip uses data news social media scientific literature identify potential issues may require cfsan attention real world examples without echip ai solution taken weeks signal identification verification depending number scientists dedicated reviewing open literature news social media results pilot studies indicate echip could reduce overall signal detection validation process hours echip accomplishes reduction automatically ingesting reviewing analyzing presenting data multiple sources scientists way signal detection verification done short time period,12,Topic: Program integrity
644,OSCAR,FDA,Department of Health and Human Services,HHS,CHATBOT,"OSCAR (Office of Science Customer Assistance Response) is a chatbot with predefined intents for customers to get help from Customer Service Center. It offers a 24/7 user interface allowing users to input questions and view previous responses, as well as a dashboard offering key metrics for admin users.",oscar office science customer assistance response chatbot predefined intents customers get help customer service center offers user interface allowing users input questions view previous responses well dashboard offering key metrics admin users,6,"""Hotlines and service desks"""
645,SSTAT,FDA,Department of Health and Human Services,HHS,ASSOCIATED TOPICS,Self-Service Text Analytics Tool (SSTAT) is used to explore the topics of a set of documents. Documents can be submitted to the tool in order to generate a set of topics and associated keywords. A visual listing of the documents and their associated topics is automatically produced to help quickly snapshot the submitted documents.,text analytics tool sstat used explore topics set documents documents submitted tool order generate set topics associated keywords visual listing documents associated topics automatically produced help quickly snapshot submitted documents,9,Internal operations
646,ASSIST4TOBACCO,FDA,Department of Health and Human Services,HHS,,ASSIST4Tobacco is a semantic search system that helps CTP stakeholders find tobacco authorization applications more accurately and efficiently.,semantic search system helps ctp stakeholders find tobacco authorization applications accurately efficiently,6,Service / benefits access
647,Using XGBoost Machine Learning Method to Predict Antimicrobial Resistance from WGS data,FDA,Department of Health and Human Services,HHS,"MACHINE LEARNING, XGBOOST, ARTIFICIAL INTELLIGENCE, AI, ML","Genomic data and artificial intelligence/machine learning (AI/ML) are used to study antimicrobial resistance (AMR) in Salmonella, E. coli, Campylobacter, and Enterococcus, isolated from retail meats, humans, and food producing animals. The Boost Machine Learning Model (XGBoost) is implemented to improve upon categorical resistance vs susceptible predictions by predicting antimicrobial Minimum Inhibitory Concentrations (MICs) from WGS data.",genomic data artificial learning used study antimicrobial resistance amr salmonella coli campylobacter enterococcus isolated retail meats humans food producing animals boost machine learning model xgboost implemented improve upon categorical resistance vs susceptible predictions predicting antimicrobial minimum inhibitory concentrations mics wgs data,15,Internal operations
648,Development of virtual animal models to simulate animal study results using Artificial Intelligence (AI),FDA,Department of Health and Human Services,HHS,AI,"Testing data from animal models provides crucial evidence for the safety evaluation of chemicals. These data have been an essential component in regulating drug, food, and chemical safety by regulatory agencies worldwide including FDA. As a result, a wealth of animal data is available from the public domain and other sources. As the toxicology community and regulatory agencies move towards a reduction, refinement, and replacement (3Rs principle) of animal studies, we proposed an AI-based generative adversarial network (GAN) architecture to learn from existing animal studies so that it can generate animal data for new and untested chemicals without conducting further animal experiments. The FDA has developed guidelines and frameworks to modernize toxicity assessment with alternative methods, such as the FDA Predictive Toxicology Roadmap and the Innovative Science and Technology Approaches for New Drugs (ISTAND). These programs facilitate the development and evaluation of alternative methodologies to expand the FDA's toxicology predictive capabilities, to reduce the use of animal testing, and to facilitate drug development. A virtual animal model with capability of simulating animal studies could serve as an alternative to animal studies to support the FDA mission.",testing data animal models provides crucial evidence safety evaluation chemicals data essential component regulating drug food chemical safety regulatory agencies worldwide including fda result wealth animal data available public domain sources toxicology community regulatory agencies move towards reduction refinement replacement principle animal studies proposed generative adversarial network gan architecture learn existing animal studies generate animal data new untested chemicals without conducting animal experiments fda developed guidelines frameworks modernize toxicity assessment alternative methods fda predictive toxicology roadmap innovative science technology approaches new drugs istand programs facilitate development evaluation alternative methodologies expand fda toxicology predictive capabilities reduce use animal testing facilitate drug development virtual animal model capability simulating animal studies could serve alternative animal studies support fda mission,9,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
649,Assessing and mitigating bias in applying Artificial Intelligence (AI) based natural language processing (NLP) of drug labeling documents,FDA,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, TRANSFER LEARNING, AI","As use of AI in biomedical sciences increases, significant concerns are raised regarding bias, stereotype, or prejudice in some AI systems. An AI system trained on inappropriate or inadequate data may reinforce biased patterns and thus provide biased predictions. Particularly, when the AI model was trained on dataset from different domains and then transferred to a new application domain, the system needs to be evaluated properly to avoid potential bias risks.
Given the increased number of transfer learning and AI applications in document analysis to support FDA review, this proposal is to conduct a comprehensive study to understand and assess the bias in applying AI based natural language processing of drug labeling documents, and to the extension of developing a strategy to mitigate such a bias.",use ai biomedical sciences increases significant concerns raised regarding bias stereotype prejudice ai systems ai system trained inappropriate inadequate data may reinforce biased patterns thus provide biased predictions particularly ai model trained dataset different domains transferred new application domain system needs evaluated properly avoid potential bias risks given increased number transfer learning ai applications document analysis support fda review proposal conduct comprehensive study understand assess bias applying ai based natural language processing drug labeling documents extension developing strategy mitigate bias,9,Accessibility: using AI for translation / interpretation
650,Identify sex disparities in opioid drug safety signals in FDA adverse events report systems (FAERS) and social media Twitter to improve women health,FDA,Department of Health and Human Services,HHS,,"This proposal aims to address OWH 2023 Priority Area: Use of real world data and evidence to inform regulatory processes.

We propose to analyze sex differences in adverse events for opioid drugs in social media (Twitter) and the FDA Adverse Events Report Systems (FAERS). We will compare sex disparities identified from FAERS and Twitter to assess whether Twitter data can be used as an early warning system to signal the opioid-related issues specific to women. The identified sex disparities in adverse events for opioid drugs from this project could help improve women health.",proposal aims address owh priority area use real world data evidence inform regulatory processes propose analyze sex differences adverse events opioid drugs social media twitter fda adverse events report systems faers compare sex disparities identified faers twitter assess whether twitter data used early warning system signal issues specific women identified sex disparities adverse events opioid drugs project could help improve women health,9,Policy-making and public engagement: use of AI in any stage of developing regulations or gathering input
651,Prediction of adverse events from drug - endogenous ligand - target networks generated using 3D-similarity and machine learning methods.,FDA,Department of Health and Human Services,HHS,AI,"Excluding areas of the biochemical space near activity cliffs [1], molecular similarity [2] has long proven to be an outstanding tool in virtual screening [3], absorption, distribution, metabolism, and excretion (ADME) [4], drug design [5] and toxicology [6]. Among these, the toxicological response is the most challenging task due to its immense complexity involving multiple pathways and protein targets. Although many adverse drug reactions (ADRs) result from genetic polymorphisms and factors such as the patient's medical history and the treatment dosage and regimen, on a fundamental level all ADRs are initiated by the binding of a drug molecule to a target, whether intended (therapeutic target) or non-intended (off-target interactions with promiscuous proteins) [7]. While molecular similarity approaches designed to identify off-target interaction sites have been explored since the late 2000s [8, 9], most have been focused on drug design, repurposing and more generally, efficacy, whereas relatively few have been applied to toxicology [10, 11].
Since there are multiple approaches to molecular similarity (structural, functional, whole molecule, pharmacophore, etc. [12]), the performance of any of the above applications depends strongly on the metrics by which similarity is quantified. For the past 10 years, DSB has been working on creating a universal molecular modeling approach utilizing unique three-dimensional fingerprints encoding both the steric and electrostatic fields governing the interactions between ligands and receptors. It has been demonstrated that these fingerprints could quantify reliably both the structural and functional similarities between molecules [13, 14] and their application for prediction of adverse events from AI generated drug - endogenous ligand - target networks could provide new insights into yet unknown mechanisms of toxicity.",excluding areas biochemical space near activity cliffs molecular similarity long proven outstanding tool virtual screening absorption distribution metabolism excretion adme drug design toxicology among toxicological response challenging task due immense complexity involving multiple pathways protein targets although many adverse drug reactions adrs result genetic polymorphisms factors patient medical history treatment dosage regimen fundamental level adrs initiated binding drug molecule target whether intended therapeutic target interactions promiscuous proteins molecular similarity approaches designed identify interaction sites explored since late focused drug design repurposing generally efficacy whereas relatively applied toxicology since multiple approaches molecular similarity structural functional whole molecule pharmacophore etc performance applications depends strongly metrics similarity quantified past years dsb working creating universal molecular modeling approach utilizing unique fingerprints encoding steric electrostatic fields governing interactions ligands receptors demonstrated fingerprints could quantify reliably structural functional similarities molecules application prediction adverse events ai generated drug endogenous ligand target networks could provide new insights yet unknown mechanisms toxicity,9,Topic: Asset management
652,Predictive toxicology models of drug placental permeability using 3D-fingerprints and machine learning,FDA,Department of Health and Human Services,HHS,,"The human placenta plays a pivotal role in fetal growth, development, and fetal exposure to chemicals and therapeutics. The ability to predict placental permeability of chemicals during pregnancy is an important factor that can inform regulatory decisions related to fetal safety and clinical trials with women of child-bearing potential (WOCBP). The human placenta contains transport proteins, which facilitate the transfer of various endogenous substances and xenobiotics. Several mechanisms allow this transfer: i) passive diffusion, ii) active transport, iii) facilitated diffusion, iv) pinocytosis, and v) phagocytosis. Among these, passive and active transport are the two major routes. Small, non-ionized, highly lipophilic drugs cross the placenta via passive diffusion; however, relatively large molecules (MW > 500 Da) with low lipophilicity are carried by transporters. While prediction of the ability of drugs to cross the placenta via diffusion is straight-forward, the complexity of molecular interactions between drugs and transporters has proven to be a challenging problem to solve. Virtually, all QSARs (Quantitative Structure Activity Relationships) published to date model small datasets (usually not exceeding 100 drugs) and utilize weak validation strategies [1-5].
In this proposal, 3D-molecular similarities of endogenous placental transporter ligands to known drug substrates will be used to identify the most likely mode of drug transportation (active/passive) and build predictive, quantitative and categorical 3D-SDAR models by linking their molecular characteristics to placental permeability. Permeability data will be collected via mining the literature, the CDER databases, and conducting empirical assessments using in vitro NAMs with confirmation using rodent models. Predictability will be validated using: i) blind test sets including known controls and ii) a small set of drugs with unknown permeabilities, which will be tested in in vitro and in vivo models.",human placenta plays pivotal role fetal growth development fetal exposure chemicals therapeutics ability predict placental permeability chemicals pregnancy important factor inform regulatory decisions related fetal safety clinical trials women potential wocbp human placenta contains transport proteins facilitate transfer various endogenous substances xenobiotics several mechanisms allow transfer passive diffusion ii active transport iii facilitated diffusion iv pinocytosis v phagocytosis among passive active transport two major routes small highly lipophilic drugs cross placenta via passive diffusion however relatively large molecules mw da low lipophilicity carried transporters prediction ability drugs cross placenta via diffusion complexity molecular interactions drugs transporters proven challenging problem solve virtually qsars quantitative structure activity relationships published date model small datasets usually exceeding drugs utilize weak validation strategies proposal similarities endogenous placental transporter ligands known drug substrates used identify likely mode drug transportation build predictive quantitative categorical models linking molecular characteristics placental permeability permeability data collected via mining literature cder databases conducting empirical assessments using vitro nams confirmation using rodent models predictability validated using blind test sets including known controls ii small set drugs unknown permeabilities tested vitro vivo models,11,Topic Name: Other
653,Opioid agonists/antagonists knowledgebase (OAK) to assist review and development of analgesic products for pain management and opioid use disorder treatment,FDA,Department of Health and Human Services,HHS,,"The number of deaths caused by opioid overdose in the United States has been increasing dramatically for the last decade. misuse and abuse continue at alarmingly high rates. Opioid use disorder (OUD) often starts with use of prescription opioid analgesics. Therefore, the development of abuse-deterrent analgesic products may significantly impact the trajectory of the opioid crisis. In addition, FDA is making new efforts to support novel product innovation for pain management and the treatment of OUD to combat this opioid crisis. 
Opioid agonists bind and activate opioid receptors to decrease calcium influx and  cyclic adenosine monophosphate (cAMP), leading to hyperpolarization that inhibits pain transmission. Opioid antagonists bind and inhibit or block opioid receptors. Both opioid agonists and antagonists are used in drug products for pain management and treatment of opioid addiction. An opioid agonists/antagonists knowledgebase (OAK) would be useful for FDA reviewers to inform evaluation and to assist development of analgesics and of additional treatments for OUD.
To create a comprehensive OAK, we propose to curate the experimental data on opioid agonist/antagonist activity from the public domain, experimentally test some 2800 drugs in functional opioid receptor assays using quantitative high-throughput screen (qHTS) platform, and develop and validate in silico models to predict opioid agonist/antagonist activity. The created OAK knowledgebase could be used for retrieving experimental opioid agonist/antagonist activity data and the related experimental protocols. For chemicals without experimental data, read-across methods could be used to find similar chemicals in OAK to estimate the opioid agonist/antagonist activity, and the in silico models in OAK could be used to predict the opioid agonist/antagonist activity. The retrieved or predicted activity data can then be used to inform regulatory review or to assist in the development of analgesics.",number deaths caused opioid overdose united states increasing dramatically last decade misuse abuse continue alarmingly high rates opioid use disorder oud often starts use prescription opioid analgesics therefore development analgesic products may significantly impact trajectory opioid crisis addition fda making new efforts support novel product innovation pain management treatment oud combat opioid crisis opioid agonists bind activate opioid receptors decrease calcium influx cyclic adenosine monophosphate camp leading hyperpolarization inhibits pain transmission opioid antagonists bind inhibit block opioid receptors opioid agonists antagonists used drug products pain management treatment opioid addiction opioid knowledgebase oak would useful fda reviewers inform evaluation assist development analgesics additional treatments oud create comprehensive oak propose curate experimental data opioid activity public domain experimentally test drugs functional opioid receptor assays using quantitative screen qhts platform develop validate silico models predict opioid activity created oak knowledgebase could used retrieving experimental opioid activity data related experimental protocols chemicals without experimental data methods could used find similar chemicals oak estimate opioid activity silico models oak could used predict opioid activity retrieved predicted activity data used inform regulatory review assist development analgesics,9,People operations
654,Development of a Comprehensive Open Access Molecules with Androgenic Activity Resource (MAAR) to Facilitate Assessment of Chemicals,FDA,Department of Health and Human Services,HHS,DECISION MAKING,"Androgen receptor (AR) is a ligand-dependent transcription factor and a member of the nuclear receptor superfamily, which is activated by androgens. AR is the target for many drugs but it could also act as an off target for drugs and other chemicals. Therefore, detecting androgenic activity of drugs and other FDA regulated chemicals is critical for evaluation of drug safety and assessment of chemical risk. There is a large amount of androgenic activity data in the public domain, which could be an asset for the scientific community and regulatory science. However, the data are distributed across different and diverse sources and stored in different formats, limiting the use of the data in research and regulation. Therefore, a comprehensive, reliable resource to provide open access to the data and enable modeling and prediction of androgenic activity for untested chemicals is in urgent need. This project will develop a high-quality open access Molecules with Androgenic Activity Resource (MAAR) including data and predictive models fully compliant with the FAIR (Findable, Accessible, Interoperable, and Reusable) principles.  MAAR can be used to facilitate research on androgenic activity of chemicals and support regulatory decision making concerning efficacy and safety evaluation of drugs and chemicals in the FDA regulated products.",androgen receptor ar transcription factor member nuclear receptor superfamily activated androgens ar target many drugs could also act target drugs chemicals therefore detecting androgenic activity drugs fda regulated chemicals critical evaluation drug safety assessment chemical risk large amount androgenic activity data public domain could asset scientific community regulatory science however data distributed across different diverse sources stored different formats limiting use data research regulation therefore comprehensive reliable resource provide open access data enable modeling prediction androgenic activity untested chemicals urgent need project develop open access molecules androgenic activity resource maar including data predictive models fully compliant fair findable accessible interoperable reusable principles maar used facilitate research androgenic activity chemicals support regulatory decision making concerning efficacy safety evaluation drugs chemicals fda regulated products,9,Service delivery
655,Artificial Intelligence (AI)-based Natural Language Processing (NLP) for FDA labeling documents,FDA,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, CLASSIFICATION, ARTIFICIAL INTELLIGENCE, AI, NLP, TEXT SUMMARIZATION","FDA has historically generated and continues to generate a variety of documents during the product-review process, which are typically unstructured text and often not follows the use of standards. Therefore, analysis of semantic relationships plays a vital role to extract useful information from the FDA documents to facilitate the regulatory science research and improve FDA product review process. The rapid advancement in artificial intelligence (AI) for Natural Language Processing (NLP) offers an unprecedent opportunity to analyze the semantic text data by using the language models that are trained with large biomedical corpus. This study is to assess the AI based NLP for the FDA documents with a focus on the FDA labeling documents. Specifically, we will apply the publicly available language models (e.g., BERT and BioBERT) to the FDA drug labeling documents available from the FDA Label tool that manages over 120K labeling documents including over 40K Human Prescription Drug and Biological Products. We will investigate three areas of AI applications that are important to the regulatory science research: (1) the interpretation and classification of drug properties (e.g., safety and efficacy) with AI reading, (2) text summarization to provide highlights of labeling sections, (3) automatic anomaly analysis (AAA) for signal identification, and (4) information retrieval with Amazon-like Questions/Answer. We will compare the AI based NLP with MedDRA based approach whenever possible for drug safety and efficacy. The study will provide a benchmark for fit-for-purpose application of the public language models to the FDA documents and, moreover, the outcome of the study could provide a scientific basis to support the future development of FDALabel tool which is widely used in CDER review process.",fda historically generated continues generate variety documents process typically unstructured text often follows use standards therefore analysis semantic relationships plays vital role extract useful information fda documents facilitate regulatory science research improve fda product review process rapid advancement artificial intelligence ai natural language processing nlp offers unprecedent opportunity analyze semantic text data using language models trained large biomedical corpus study assess ai based nlp fda documents focus fda labeling documents specifically apply publicly available language models bert biobert fda drug labeling documents available fda label tool manages labeling documents including human prescription drug biological products investigate three areas ai applications important regulatory science research interpretation classification drug properties safety efficacy ai reading text summarization provide highlights labeling sections automatic anomaly analysis aaa signal identification information retrieval compare ai based nlp meddra based approach whenever possible drug safety efficacy study provide benchmark application public language models fda documents moreover outcome study could provide scientific basis support future development fdalabel tool widely used cder review process,9,Topic: Program Integrity
656,Informing selection of drugs for COVID-19 treatment by big data analytics and artificial intelligence,FDA,Department of Health and Human Services,HHS,"BIG DATA, ARTIFICIAL INTELLIGENCE","The pandemic of COVID-19 is the biggest global health concern currently. As of July 11, 2020, more than 12 million people have been tested positive of SARS-COV-2 virus infection and more than half million deaths have been caused by COVID-19 in the world. Currently, no vaccines and/or drugs have been proved to be effective to treat COVID-19. Therefore, many drug products on the market are being repurposed for the treatment of COVID-19. However, sufficient evidence is needed to determine that the repurposed drugs are safe and effective. Therefore, safety information on the drugs  selected for repurposing purpose is important. The proposed project aims to mine adverse drug events using artificial intelligence and big data analytics in the public domain including the agency's database, public databases, and social media data for the drugs to be repurposed for the treatment of COVID-19. The ultimate goal of this project is to provide detailed adverse event information that can be used to facilitate safety evaluation for drugs repurposed for the treatment COVID-19. The detailed adverse event information will be used to develop recommendations for selecting the right drugs for repurposing efforts and for help select the appropriate COVID-19 patients and thus better to combat the pandemic.",pandemic biggest global health concern currently july million people tested positive virus infection half million deaths caused world currently vaccines drugs proved effective treat therefore many drug products market repurposed treatment however sufficient evidence needed determine repurposed drugs safe effective therefore safety information drugs selected repurposing purpose important proposed project aims mine adverse drug events using artificial intelligence big data analytics public domain including agency database public databases social media data drugs repurposed treatment ultimate goal project provide detailed adverse event information used facilitate safety evaluation drugs repurposed treatment detailed adverse event information used develop recommendations selecting right drugs repurposing efforts help select appropriate patients thus better combat pandemic,9,Topic: Other
657,Towards Explainable AI: Advancing Predictive Modeling for Regulatory Use,FDA,Department of Health and Human Services,HHS,"ARTIFICIAL INTELLIGENCE, AI, DECISION MAKING","Artificial Intelligence (AI) is a broad discipline of training machines to think and accomplish complex intellectual tasks like humans. It learns from existing data/information to predict future outcomes, distill knowledge, offer advices, or plan action steps. The rise of AI has offered both opportunities and challenges to FDA in two aspects: (1) how to assess and evaluate marketed AI-centric products and (2) how to implement AI methods to improve the agency's operation. One of the key aspects of both regulatory applications is to understand the underlying features driving the AI performance and to the extension of its interpretability in the context of application.  
 
Different from the statistical evaluation (e.g., accuracy, sensitivity and specificity), model interpretability assessment lacks quantitative metrics. In most cases, the assessment tends to be subjective, where prior knowledge is often used as a ground-truth to explain the biological relevance of underlying features, e.g., whether the biomarkers featured by the model are in accordance with the existing findings. In reality, there is a trade-off between statistical performance and interpretability among different AI algorithms, and understanding the difference will improve the context of use of AI technologies in regulatory science.  

For that, we will investigate representative AI methods, in terms of their performance and interpretability, first through benchmark datasets that have been well-established in the research community, then extended to clinical/pre-clinical datasets. This project will provide basic parameters and offer an insightful guidance on developing explainable AI models to facilitate the real-world decision making in regulatory settings.",artificial intelligence ai broad discipline training machines think accomplish complex intellectual tasks like humans learns existing predict future outcomes distill knowledge offer advices plan action steps rise ai offered opportunities challenges fda two aspects assess evaluate marketed products implement ai methods improve agency operation one key aspects regulatory applications understand underlying features driving ai performance extension interpretability context application different statistical evaluation accuracy sensitivity specificity model interpretability assessment lacks quantitative metrics cases assessment tends subjective prior knowledge often used explain biological relevance underlying features whether biomarkers featured model accordance existing findings reality statistical performance interpretability among different ai algorithms understanding difference improve context use ai technologies regulatory science investigate representative ai methods terms performance interpretability first benchmark datasets research community extended datasets project provide basic parameters offer insightful guidance developing explainable ai models facilitate decision making regulatory settings,9,Policy-making and public engagement
658,Identification of sex differences on prescription opioid use (POU)-related cardiovascular risks by big data analysis,FDA,Department of Health and Human Services,HHS,"BIG DATA, AI","1) Prescription opioid use (POU) varies among patient population subgroups, such as gender, age, and ethnicity. POU can potentially cause various adverse effects in the respiratory, gastrointestinal, musculoskeletal, cardiovascular, immune, endocrine, and central nervous systems. Important sex differences have been observed in POU-associated cardiac endpoints. Currently, systematic knowledge is lacking for risk factors associated with the increased cardiotoxicity of POU in women. 2) Currently, the FDA utilizes two methods of analysis for data mining, the Proportional Reporting Ratio (PRR) and the Empirical Bayesian Geometric Mean (EBGM) to identify significant statistical associations between products and adverse events (AEs). These methods are not applicable when two or more reporting measures (e.g. gender, age, race, etc.) must be considered and compared. In this study, a novel statistical model will be developed to detect the safety signals when gender is considered as the third variable. Safety signals will then be detected and compared from combined multiple-layered real-world evidence in the form of EHRs from diverse sources. Sex-dependent differences in risk factors for cardiotoxicity from POU will be identified and analyzed using big data methods and AI-related tools. 3) The proposed project addresses the first of four priority areas of FDA's 2018 Strategic Policy Roadmap: Reduce the burden of addiction crises that are threatening American families, and two priority areas of Women's Health Research Roadmap: Priority Area 1: Advance Safety and Efficacy, and Priority Area 5: Expand Data Sources and Analysis. The results may provide information and knowledge to help the FDA drug reviewers and physicians be aware of sex differences to certain POU drugs and combinations of POU with other prescription drugs, therefore, preventing or reducing risk of the POU drug-induced CVD in women.",prescription opioid use pou varies among patient population subgroups gender age ethnicity pou potentially cause various adverse effects respiratory gastrointestinal musculoskeletal cardiovascular immune endocrine central nervous systems important sex differences observed cardiac endpoints currently systematic knowledge lacking risk factors associated increased cardiotoxicity pou women currently fda utilizes two methods analysis data mining proportional reporting ratio prr empirical bayesian geometric mean ebgm identify significant statistical associations products adverse events aes methods applicable two reporting measures gender age race etc must considered compared study novel statistical model developed detect safety signals gender considered third variable safety signals detected compared combined evidence form ehrs diverse sources differences risk factors cardiotoxicity pou identified analyzed using big data methods tools proposed project addresses first four priority areas fda strategic policy roadmap reduce burden addiction crises threatening american families two priority areas women health research roadmap priority area advance safety efficacy priority area expand data sources analysis results may provide information knowledge help fda drug reviewers physicians aware sex differences certain pou drugs combinations pou prescription drugs therefore preventing reducing risk pou cvd women,9,11. Other
659,NCTR/DBB-CDER/OCS collaboration on A SafetAI Initiative to Enhance IND Review Process,FDA,Department of Health and Human Services,HHS,"MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS, AI, ML, DL, DEEP LEARNING","The development of animal-free models has been actively investigated and successfully demonstrated as an alternative to animal-based approaches for toxicity assessments.  Artificial Intelligence (AI) and Machine learning (ML) have been the central engine in this paradigm shift to identify safety biomarkers from non-animal assays or to predict safety outcomes solely based on chemical structure data. AI is a computer system or algorithm that has the ability to learn from existing data to foresee the future outcome. ML, a subset of AI, has been specifically studied to make predictions for adverse drug reactions. Deep Learning (DL) is arguably the most advanced approach in ML which frequently outperforms other types of ML approaches (or conventional ML approaches) for the study of drug safety and efficacy. DL usually consists of multiple layers of neural networks to mimic the cognitive behaviors associated with the human brain learning and problem-solving process to solve data intensive problems. Among many studies using AI/ML, DL has become a default algorithm to consider due to its superior performance. This proposal will apply DL to flag safety concerns regarding drug-induced liver injury (DILI) and carcinogenicity during the IND review process.",development models actively investigated successfully demonstrated alternative approaches toxicity assessments artificial intelligence ai machine learning ml central engine paradigm shift identify safety biomarkers assays predict safety outcomes solely based chemical structure data ai computer system algorithm ability learn existing data foresee future outcome ml subset ai specifically studied make predictions adverse drug reactions deep learning dl arguably advanced approach ml frequently outperforms types ml approaches conventional ml approaches study drug safety efficacy dl usually consists multiple layers neural networks mimic cognitive behaviors associated human brain learning process solve data intensive problems among many studies using dl become default algorithm consider due superior performance proposal apply dl flag safety concerns regarding liver injury dili carcinogenicity ind review process,9,Topic: Asset management
660,individual Functional Activity Composite Tool (inFACT),NIH,Department of Health and Human Services,HHS,,inFACT is being developed for use in the Social Security Administration (SSA) disability determination process to assist adjudicators in identifying evidence on function from case records that might be hundreds or thousands of pages long. inFACT displays information on whole person function as extracted from an individual's free text medical records and aligned with key business elements.,infact developed use social security administration ssa disability determination process assist adjudicators identifying evidence function case records might hundreds thousands pages long infact displays information whole person function extracted individual free text medical records aligned key business elements,6,Service / benefits access
661,Assisted Referral Tool,NIH,Department of Health and Human Services,HHS,,To provide assistance in assigning appropriate scientific areas for grant applications.,provide assistance assigning appropriate scientific areas grant applications,14,"""Service / benefits access"""
662,NanCI: Connecting Scientists,NIH,Department of Health and Human Services,HHS,AI,"Uses AI to match scientific content to users interests. By collecting papers into a folder a user can engage the tool to find similar articles in the scientific literature, and can refine the recommendations by up or down voting of recommendations. Users can also connect with others via their interests, and receive and make recommendations via this social network.",uses ai match scientific content users interests collecting papers folder user engage tool find similar articles scientific literature refine recommendations voting recommendations users also connect others via interests receive make recommendations via social network,6,"""Service delivery"""
663,Detection of Implementation Science focus within incoming grant applications,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING","This tool uses natural language processing and machine learning to calculate an Implementation Science (IS) score that is used to predict if a newly submitted grant application proposes to use science that can be categorized as ""Implementation Science"" (a relatively new area of delineation). NHLBI uses the ""IS score"" in its decision for assigning the application to a particular division for routine grants management oversight and administration.",tool uses natural language processing machine learning calculate implementation science score used predict newly submitted grant application proposes use science categorized implementation science relatively new area delineation nhlbi uses score decision assigning application particular division routine grants management oversight administration,14,Topic: Policy-making and public engagement
664,Federal IT Acquisition Reform Act (FITARA) Tool,NIH,Department of Health and Human Services,HHS,,The tool automates the identification of NIAID contracts that are IT-related.,tool automates identification niaid contracts,9,"""Asset management"""
665,"Division of Allergy, Immunology, and Transplantation (DAIT) AIDS-Related Research Solution",NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, CLASSIFICATION, NLP","The tool uses natural language processing (NLP), text extraction, and classification algorithms to predict both high/medium/low priority and area of research for a grant application. The incoming grant applications are ranked based on these predictions and more highly-ranked applications are prioritized for review.",tool uses natural language processing nlp text extraction classification algorithms predict priority area research grant application incoming grant applications ranked based predictions applications prioritized review,9,Topic: Service Delivery
666,Scientific Research Data Management System Natural Language Processing Conflict of Interest Tool,NIH,Department of Health and Human Services,HHS,NLP,"A tool that identifies entities within a grant application to allow NIAID's Scientific Review Program team to more easily identify conflicts of interest (COI) between grant reviewers and applicants using NLP methods (e.g., OCR, text extraction).",tool identifies entities within grant application allow niaid scientific review program team easily identify conflicts interest coi grant reviewers applicants using nlp methods ocr text extraction,14,"""Service / benefits access"""
667,Tuberculosis (TB) Case Browser Image Text Detection,NIH,Department of Health and Human Services,HHS,,A tool to detect text in images that could be potentially Personally Identifiable Information (PII)/ Protected Health Information (PHI) in TB Portals.,tool detect text images could potentially personally identifiable information pii protected health information phi tb portals,6,Service delivery
668,Research Area Tracking Tool,NIH,Department of Health and Human Services,HHS,MACHINE LEARNING,A dashboard that incorporates machine learning to help identify projects within certain high-priority research areas.,dashboard incorporates machine learning help identify projects within certain research areas,7,Service delivery
669,NIDCR Digital Transformation Initiative (DTI),NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, CHATBOT","An initiative to create a natural language processing chatbot to improve efficiency, transparency, and consistency for NIDCR employees. ",initiative create natural language processing chatbot improve efficiency transparency consistency nidcr employees,4,Service delivery
670,NIDCR Data Bank,NIH,Department of Health and Human Services,HHS,"AI, ML, NLP","The project will permit intramural research program investigators to move large sets of unstructured data into a cloud archival storage, which will scale, provide cost effective data tiering, capture robust meta data sufficient for management and governance, and create secondary or tertiary opportunities for analysis leveraging cognitive services AI/ML/NLP toolsets.",project permit intramural research program investigators move large sets unstructured data cloud archival storage scale provide cost effective data tiering capture robust meta data sufficient management governance create secondary tertiary opportunities analysis leveraging cognitive services toolsets,2,"""Asset management"""
671,Automated approaches for table extraction,NIH,Department of Health and Human Services,HHS,,"This project developed an automated, model-based processes to reduce the time and level of effort for manualï¿½extraction of data from tables. Published data tables are a particularly data-rich and challenging presentation of critical information in published research.",project developed automated processes reduce time level effort data tables published data tables particularly challenging presentation critical information published research,14,"""Asset management"""
672,SWIFT Active Screener,NIH,Department of Health and Human Services,HHS,,Applies statistical models designed to save screeners time and effort through active learning. Utilize user feedback to automatically prioritize studies. Supports literature screening for Division of Translational Toxicology evidence evaluations.,applies statistical models designed save screeners time effort active learning utilize user feedback automatically prioritize studies supports literature screening division translational toxicology evidence evaluations,3,Topic: Accessibility
673,Splunk IT System Monitoring Software,NIH,Department of Health and Human Services,HHS,MACHINE LEARNING,Utilizes machine learning to aggregate system logs from on-premises IT infrastructure systems and endpoints for auditing and cybersecurity monitoring purposes.,utilizes machine learning aggregate system logs infrastructure systems endpoints auditing cybersecurity monitoring purposes,10,Internal operations
674,Clinical Trial Predictor,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING","The Clinical Trial Predictor uses an ensemble of several natural language processing and machine learning algorithms to predict whether applications may involve clinical trials based on the  text of their titles, abstracts, narratives, specific aims, and research strategies.",clinical trial predictor uses ensemble several natural language processing machine learning algorithms predict whether applications may involve clinical trials based text titles abstracts narratives specific aims research strategies,9,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
675,Stem Cell Auto Coder,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING","The Stem Cell Auto Coder uses natural language processing and machine learning to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic.",stem cell auto coder uses natural language processing machine learning predict stem cell research subcategories application human embryonic embryonic human induced pluripotent induced pluripotent human,11,Service delivery
676,JIT Automated Calculator (JAC),NIH,Department of Health and Human Services,HHS,NATURAL LANGUAGE PROCESSING,The JIT Automated Calculator (JAC) uses natural language processing to parse Just-In-Time (JIT) Other Support forms and determine how much outside support PIs are receiving from sources other than the pending application.,jit automated calculator jac uses natural language processing parse jit support forms determine much outside support pis receiving sources pending application,19,Service delivery
677,Similarity-based Application and Investigator Matching (SAIM),NIH,Department of Health and Human Services,HHS,NATURAL LANGUAGE PROCESSING,The SAIM system uses natural language processing to identify non-NIH grants awarded to NIGMS Principal Investigators. The system aids in identifying whether a grant application has significant unnecessary overlap with one funded by another agency.,saim system uses natural language processing identify grants awarded nigms principal investigators system aids identifying whether grant application significant unnecessary overlap one funded another agency,14,Topic: Service / benefits access
678,Remediate Adobe .pdf documents to be more accessible,NIH,Department of Health and Human Services,HHS,AI,Many .pdf documents could be made available for public release if they conformed to Section 508 accessibility standards. NLM has been investigating the use of AI developed to remediate Adobe .pdf files not currently accessible to Section 508 standards.ï¿½The improved files are particularly more accessible to those like the blind who use assistive technology to read.,many documents could made available public release conformed section accessibility standards nlm investigating use ai developed remediate adobe files currently accessible section improved files particularly accessible like blind use assistive technology read,9,Accessibility
679,CylanceProtect,NIH,Department of Health and Human Services,HHS,CYBERTHREATS,Protection of Windows and Mac endpoints from Cyberthreats,protection windows mac endpoints cyberthreats,3,Service delivery
680,MEDIQA: Biomedical Question Answering,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, AI",Using and developing AI approaches to automate question answering for different users. This project leverages NLM knowledge sources and traditional and neural machine learning to address a wide-range of biomedical information needs. This project aims for improving access with one-entry access point to NLM resources.,using developing ai approaches automate question answering different users project leverages nlm knowledge sources traditional neural machine learning address biomedical information needs project aims improving access access point nlm resources,2,Service delivery
681,CLARIN: Detecting clinicians' attitudes through clinical notes,NIH,Department of Health and Human Services,HHS,AI,"Understanding clinical notes and detecting bias is essential in supporting equity and diversity, as well as quality of care and decision support. NLM is using and developing AI approaches to detect clinicians' emotions, biases and burnout.",understanding clinical notes detecting bias essential supporting equity diversity well quality care decision support nlm using developing ai approaches detect clinicians emotions biases burnout,11,"""Program integrity"""
682,Best Match: New relevance search for PubMed,NIH,Department of Health and Human Services,HHS,MACHINE-LEARNING,"PubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day. With the rapid growth of biomedical literature, finding and retrieving the most relevant papers for a given query is increasingly challenging. NLM developed Best Match, a new relevance search algorithm for PubMed that leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort order. ",pubmed free search engine biomedical literature accessed millions users around world day rapid growth biomedical literature finding retrieving relevant papers given query increasingly challenging nlm developed best match new relevance search algorithm pubmed leverages intelligence users technology alternative traditional date sort order,6,Internal operations
683,SingleCite: Improving single citation search in PubMed,NIH,Department of Health and Human Services,HHS,REGRESSION,"A search that is targeted at finding a specific document in databases is called a Single Citation search, which is particularly important for scholarly databases, such as PubMed, because it is a typical information need of the users. NLM developed SingleCite, an automated algorithm that establishes a query-document mapping by building a regression function to predict the probability of a retrieved document being the target based on three variables: the score of the highest scoring retrieved document, the difference in score between the two top retrieved documents, and the fraction of a query matched by the candidate citation. SingleCite shows superior performance in benchmarking experiments and is applied to rescue queries that would fail otherwise.",search targeted finding specific document databases called single citation search particularly important scholarly databases pubmed typical information need users nlm developed singlecite automated algorithm establishes mapping building regression function predict probability retrieved document target based three variables score highest scoring retrieved document difference score two top retrieved documents fraction query matched candidate citation singlecite shows superior performance benchmarking experiments applied rescue queries would fail otherwise,6,Topic: Other
684,Computed Author: author name disambiguation for PubMed,NIH,Department of Health and Human Services,HHS,"CLUSTERING, MACHINE-LEARNING","PubMed users frequently use author names in queries for retrieving scientific literature. However, author name ambiguity (different authors share the same name) may lead to irrelevant retrieval results. NLM developed a machine-learning method to score the features for disambiguating a pair of papers with ambiguous names. Subsequently, agglomerative clustering is employed to collect all papers belong to the same authors from those classified pairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering results, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate author name searches.",pubmed users frequently use author names queries retrieving scientific literature however author name ambiguity different authors share name may lead irrelevant retrieval results nlm developed method score features disambiguating pair papers ambiguous names subsequently agglomerative clustering employed collect papers belong authors classified pairs disambiguation performance evaluated manual verification random samples pairs clustering results higher accuracy methods integrated pubmed facilitate author name searches,14,Topic: 10. Internal operations
685,NLM-Gene: towards automatic gene indexing in PubMed articles,NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, DEEP LEARNING","Gene indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, gene indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.",gene indexing part nlm medline citation indexing efforts improving literature retrieval information access currently gene indexing performed manually expert indexers assist process nlm developed automatic tool finding gene names biomedical literature using advanced natural language processing deep learning methods performance assessed evaluation datasets integrated production medline indexing pipeline,9,Topic: 10. Internal operations
686,NLM-Chem: towards automatic chemical indexing in PubMed articles,NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, DEEP LEARNING","Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.",chemical indexing part nlm medline citation indexing efforts improving literature retrieval information access currently chemicals indexing performed manually expert indexers assist process nlm developed automatic tool finding chemical names biomedical literature using advanced natural language processing deep learning methods performance assessed evaluation datasets integrated production medline indexing pipeline,9,Topic: Asset management
687,Biomedical Citation Selector (BmCS),NIH,Department of Health and Human Services,HHS,,"Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.",automation article selection allows nlm efficiently effectively index host relevant information public automation nlm able standardize article selection reduce amount time takes process medline articles,6,Topic: Asset management
688,MTIX,NIH,Department of Health and Human Services,HHS,MACHINE LEARNING,Machine learning-based system for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach. Automated indexing allows for cost-effective and timely indexing of MEDLINE articles.,machine system automated indexing medline articles medical subject headings mesh terms automated indexing achieved using neural text ranking approach automated indexing allows timely indexing medline articles,19,Topic: Asset management
689,ClinicalTrials.gov Protocol Registration and Results System Review Assistant,NIH,Department of Health and Human Services,HHS,AI,This research project aims to help ClinicalTrials.gov determine whether the addition of AI could make reviewing study records more efficient and effective.,research project aims help determine whether addition ai could make reviewing study records efficient effective,9,Service Delivery
690,MetaMap,NIH,Department of Health and Human Services,HHS,NLP,"MetaMap is a widely available program providing access from biomedical text to the concepts in the unified medical language system (UMLS) Metathesaurus. MetaMap uses NLP to provide a link between the text of biomedical literature and the knowledge, including synonymy relationships, embedded in the Metathesaurus. The flexible architecture in which to explore mapping strategies and their application are made available. MTI uses the MetaMap to generate potential indexing terms. ",metamap widely available program providing access biomedical text concepts unified medical language system umls metathesaurus metamap uses nlp provide link text biomedical literature knowledge including synonymy relationships embedded metathesaurus flexible architecture explore mapping strategies application made available mti uses metamap generate potential indexing terms,9,Topic: Asset management
691,Pangolin lineage classification of SARS-CoV-2 genome sequences,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, CLASSIFICATION","The PangoLEARN machine learning tool provides lineage classification of SARS-CoV-2 genome sequences. Classification of SARS-CoV-2 genome sequences into defined lineages supports user retrieval of sequences based on classification and tracking of specific lineages, including those lineages associated with mutations that may decrease the effectiveness of therapeutics or protection provided by vaccination.",pangolearn machine learning tool provides lineage classification genome sequences classification genome sequences defined lineages supports user retrieval sequences based classification tracking specific lineages including lineages associated mutations may decrease effectiveness therapeutics protection provided vaccination,15,Service delivery
692,HIV-related grant classifier tool,NIH,Department of Health and Human Services,HHS,VISUALIZATION,"A front-end application for scientific staff to input grant information which then runs an automated algorithm to classify HIV-related grants.  Additional features and technologies used include an interactive data visualization, such as a heat map, using Plotly Python library to display the confidence level of predicted grants. ",application scientific staff input grant information runs automated algorithm classify grants additional features technologies used include interactive data visualization heat map using plotly python library display confidence level predicted grants,14,Service delivery
693,Automated approaches to analyzing scientific topics,NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, AI, ML","Developed and implemented a validated approach that uses natural language processing and AI/ML to group semantically similar documents (including grants, publications, or patents) and extract AI labels that accurately reflect the scientific focus of each topic to aid in NIH research portfolio analysis. ",developed implemented validated approach uses natural language processing group semantically similar documents including grants publications patents extract ai labels accurately reflect scientific focus topic aid nih research portfolio analysis,9,Topic: Asset Management
694,Identification of emerging areas,NIH,Department of Health and Human Services,HHS,"AI, ML",Developed an AI/ML-based approach that computes the age and rate of progress of topics in NIH portfolios. This information can identify emerging areas of research at scale and help accelerate scientific progress.,developed approach computes age rate progress topics nih portfolios information identify emerging areas research scale help accelerate scientific progress,9,Service delivery
695,Person-level disambiguation for PubMed authors and NIH grant applicants,NIH,Department of Health and Human Services,HHS,"DATA-DRIVEN, DECISION MAKING","Correct attribution of grants, articles, and other products to individual researchers is critical for high quality person-level analysis. This improved method for disambiguation of authors on articles in PubMed and NIH grant applicants can inform data-driven decision making",correct attribution grants articles products individual researchers critical high quality analysis improved method disambiguation authors articles pubmed nih grant applicants inform decision making,14,People operations
696,Prediction of transformative breakthroughs,NIH,Department of Health and Human Services,HHS,,"The ability to predict scientific breakthroughs at scale would accelerate the pace of discovery and improve the efficiency of research investments. The initiative has helped identify a common signature within co-citation networks that accurately predicts the occurrence of breakthroughs in biomedicine, on average more than 5 years in advance of the subsequent publication(s) that announced the discovery.ï¿½There is a patent application filed for this approach: U.S. Patent Application No. 63/257,818 (filed October 20, 2021)",ability predict scientific breakthroughs scale would accelerate pace discovery improve efficiency research investments initiative helped identify common signature within networks accurately predicts occurrence breakthroughs biomedicine average years advance subsequent publication announced patent application filed approach patent application filed october,4,Internal operations
697,Machine learning pipeline for mining citations from full-text scientific articles,NIH,Department of Health and Human Services,HHS,"MACHINE LEARNING, LONG SHORT-TERM MEMORY, LSTM, RECURRENT NEURAL NETWORK","The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003).",nih office portfolio analysis developed machine learning pipeline identify scientific articles freely available internet require institutional library subscription access pipeline harvests pdfs converts xml uses long memory lstm recurrent neural network model discriminates reference text text scientific article references passed citation resolution service information see publication describing pipeline hutchins et al https,14,Topic: Asset management
698,Machine learning system to predict translational progress in biomedical research,NIH,Department of Health and Human Services,HHS,MACHINE LEARNING,A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. Translational progress in biomedicine can therefore be assessed and predicted in real time based on information conveyed by the scientific community's early reaction to a paper. For more information see the publication describing this system: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416),machine learning system detects whether research paper likely cited future clinical trial guideline translational progress biomedicine therefore assessed predicted real time based information conveyed scientific community early reaction paper information see publication describing system hutchins et al https,11,Service delivery
699,"Research, Condition, and Disease Categorization (RCDC) AI Validation Tool",NIH,Department of Health and Human Services,HHS,,The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. ,goal tool ensure rcdc categories accurate complete public reporting data,5,Service delivery
700,Internal Referral Module (IRM),NIH,Department of Health and Human Services,HHS,"NATURAL LANGUAGE PROCESSING, ARTIFICIAL INTELLIGENCE",The IRM initiative automates a manual process by using Artificial Intelligence & Natural Language Processing capabilities to help predict grant applications to NIH Institutes and Centers (ICs) Program Officers to make informed decisions.,irm initiative automates manual process using artificial intelligence natural language processing capabilities help predict grant applications nih institutes centers ics program officers make informed decisions,9,Service delivery
701,NIH Grants Virtual Assistant,NIH,Department of Health and Human Services,HHS,CHAT BOT,Chat Bot to assist users in finding grant related information via OER resources,chat bot assist users finding grant related information via oer resources,14,Service delivery
702,Tool for Nature Gas Procurement Planning,NIH,Department of Health and Human Services,HHS,,"With this tool, NIH can establish a natural gas procurement plan and set realistic price targets based on current long-term forecasts.",tool nih establish natural gas procurement plan set realistic price targets based current forecasts,15,Asset management
703,NIH Campus Cooling Load Forecaster,NIH,Department of Health and Human Services,HHS,,"This project forecasts the NIH campus's chilled water demand for the next four days. With this information, the NIH Central Utilities Plant management can plan and optimize the chiller plant's operation and maintenance.",project forecasts nih campus chilled water demand next four days information nih central utilities plant management plan optimize chiller plant operation maintenance,3,Asset management
704,NIH Campus Steam Demand Forecaster,NIH,Department of Health and Human Services,HHS,,"This project forecasts the NIH campus steam demand for the next four days. With this information, the stakeholders at the NIH Central Utilities Plant can plan and optimize the plant operation and maintenance in advance.",project forecasts nih campus steam demand next four days information stakeholders nih central utilities plant plan optimize plant operation maintenance advance,3,Asset management
705,Chiller Plant Optimization,NIH,Department of Health and Human Services,HHS,,This project will help to reduce the energy usage for producing chilled water to cool the NIH campus.,project help reduce energy usage producing chilled water cool nih campus,10,Service delivery
706,Natural Language Processing Tool for Open Text Analysis,NIH,Department of Health and Human Services,HHS,,This project will improve facility readiness and reduce downtime by allowing other software to analyze data that was locked away in open text.,project improve facility readiness reduce downtime allowing software analyze data locked away open text,3,"""Asset management"""
707,Contracts and Grants Analytics Portal,OIG,Department of Health and Human Services,HHS,AI,"The Contracts and Grants Analytics Portal uses AI to enhance HHS OIG staff's ability to access grants related data quickly and easily by: quickly navigating directly to the text of relevant findings across thousands of audits, the ability to discover similar findings, analyze trends, compare data between OPDIVs, and the means to see preliminary assessments of potential anomalies between grantees.",contracts grants analytics portal uses ai enhance hhs oig staff ability access grants related data quickly easily quickly navigating directly text relevant findings across thousands audits ability discover similar findings analyze trends compare data opdivs means see preliminary assessments potential anomalies grantees,14,Service delivery
708,Text Analytics Portal,OIG,Department of Health and Human Services,HHS,"TOPIC MODELING, ENTITY RECOGNITION","The text analytics portal allows personnel without an analytics background to quickly examine text documents through a related set of search, topic modeling and entity recognition technologies; Initial implementation's focus is on HHS-OIG specific use cases.",text analytics portal allows personnel without analytics background quickly examine text documents related set search topic modeling entity recognition technologies initial implementation focus specific use cases,9,Topic: Asset management
709,Consolidated Plan Pilot Analysis,,Department of Housing and Urban Development,HUD,,"In March 2023, PD&R began a pilot project to analyze aspects of HUD's Consolidated Plans. HUD requires grantees of its formula block grant programs to submit Consolidated Plans, which are meant to identify and assess affordable housing and community development needs and market conditions. These plans are publicly available via HUD's website. HUD staff currently review these plans for compliance, but HUD lacks the capacity to do in-depth analysis of commonalities or trends contained within plans. This pilot project will explore creating a database and chat-bot that will enable HUD staff to query features of the nearly 1,000 active Consolidated Plans. This pilot exercise has the potential to inform grantees, technical assistance, and other programmatic tweaks, as well as inform how advanced data science tools can benefit our programs and operations.",march pd r began pilot project analyze aspects hud consolidated plans hud requires grantees formula block grant programs submit consolidated plans meant identify assess affordable housing community development needs market conditions plans publicly available via hud website hud staff currently review plans compliance hud lacks capacity analysis commonalities trends contained within plans pilot project explore creating database enable hud staff query features nearly active consolidated plans pilot exercise potential inform grantees technical assistance programmatic tweaks well inform advanced data science tools benefit programs operations,14,Topic: Asset management
752,Modernized Development Worksheet (MDW),"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,"NATURAL LANGUAGE PROCESSING, AI",This process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.,process uses ai review textual data part claim development tasks categorized workload topics using natural language processing facilitate faster technician review,9,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
753,Anomalous iClaim Predictive Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,The anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. ,anomalous iclaim predictive model machine learning model identifies iclaims claims sent operations review additional action taken adjudicate claims,1,Topic: Service delivery
754,Pre-Effectuation Review / Targeted Denial Review Models,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,These review models use machine learning to identify cases with greatest likelihood of disability eligibility determination error and refer them for quality review checks.  ,review models use machine learning identify cases greatest likelihood disability eligibility determination error refer quality review checks,0,Service / benefits access
755,Rep Payee Misuse Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,This model uses machine learning to estimate the probability of resource misuse by representative payees and flag the cases for a technician to examine.,model uses machine learning estimate probability resource misuse representative payees flag cases technician examine,1,Program integrity
756,CDR Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,This model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review.,model uses machine learning techniques identify disability cases greatest likelihood medical improvement flag coninuing disability review,4,Service / benefits access
757,SSI Redetermination Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,This model uses machine learning to identify supplemental security income cases with highest expected overpayments due to changes in financial eligibility and flag them for technician review.  ,model uses machine learning identify supplemental security income cases highest expected overpayments due changes financial eligibility flag technician review,1,Service / benefits access
758,Medicare Part D Subsidy Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,This model uses machine learning to identify cases most likely to have incorrect Medicare Part D subsidies and flag them for technician review.,model uses machine learning identify cases likely incorrect medicare part subsidies flag technician review,1,Program integrity
759,PATH Model,"Office of Analytics, Review, and Oversight",Social Security Administration,SSA,MACHINE LEARNING,This model uses machine learning to identify cases likely to receive an allowance at the hearing level and refer them to administrative law judges or senior adjudicators for prioritized review.,model uses machine learning identify cases likely receive allowance hearing level refer administrative law judges senior adjudicators prioritized review,1,Service delivery
760,Insight,"Office of Analytics, Review, and Oversight; Office of Hearing Operations, Office of Disability Systems",Social Security Administration,SSA,"NATURAL LANGUAGE PROCESSING, ARTIFICIAL INTELLIGENCE, DECISION MAKING","Insight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insightï¿½s features are powered by several natural language processing and artificial intelligence packages and techniques.",insight decision support software used hearings disability program adjudicators help maximize quality speed consistency decision making insight analyzes free text disability decisions case data offer adjudicators alerts potential quality issues reference information within web application also offers adjudicators series interactive tools help streamline work adjudicators leverage features speed work fix issues case moves forward another reviewing employee claimant features powered several natural language processing artificial intelligence packages techniques,14,"Accessibility: using AI for translation / interpretation, section 508 compliance, plain language, or other activities to increase accessibility of documents and interactions with the government"
761,Intelligent Medical Language Analysis Generation (IMAGEN),"Office of Disability Determinations, Office of Disability Information Systems",Social Security Administration,SSA,"MACHINE LEARNING, NATURAL LANGUAGE PROCESSING, NLP","IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will provide new tools and services to visualize, search and more easily identify relevant clinical content in medical records.  These tools and services will improve the efficiency and consistency of disability determinations and decisions and provide a foundation for machine-based decisional guidance. IMAGEN will transform text to data and enable disability adjudicators to leverage various machine learning technologies like Natural Language Processing (NLP) and predictive analytics and will support other high-priority agency initiatives such as fraud prevention and detection.",imagen modernization disability analytics disability decision support adds product provide new tools services visualize search easily identify relevant clinical content medical records tools services improve efficiency consistency disability determinations decisions provide foundation decisional guidance imagen transform text data enable disability adjudicators leverage various machine learning technologies like natural language processing nlp predictive analytics support agency initiatives fraud prevention detection,9,Accessibility
762,Duplicate Identification Process (DIP),"Office of Disability Information Systems, Office of Hearing Operations, Office of Appellate Operations",Social Security Administration,SSA,,"Duplicate Identification Process's (DIP's) objective is to help the user toï¿½identify and flagï¿½and mark duplicatesï¿½more efficiently, reducing the amountï¿½of time spent to reviewï¿½cases forï¿½hearings.ï¿½DIP uses artificialï¿½intelligence software in the form of image recognition technology to accuratelyï¿½identify duplicates consistent with SSAï¿½policy.?",duplicate identification process dip objective help user mark efficiently reducing time spent uses software form image recognition technology duplicates consistent,3,Service delivery: using AI to provide direct services either to the public or to state/local/tribal/territorial governments
763,Handwriting recognition from forms,"Office of Disability Information Systems, Office of Hearing Operations, Office of Appellate Operations",Social Security Administration,SSA,AI,AI performs OCR against handwritten entries on specific standard forms submitted by clients. This use case is in support of an Robtic Process Automation effort as well as a standalone use.,ai performs ocr handwritten entries specific standard forms submitted clients use case support robtic process automation effort well standalone use,18,Asset management
764,Quick Disability Determinations Process,Office of Retirement of Disability Programs,Social Security Administration,SSA,,"The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD modelï¿½s predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. ",quick disability determinations qdd process uses predictive model screen initial applications identify cases favorable disability determination highly likely medical evidence readily available agency bases qdd predictive scores historical data application forms completed millions applicants identifying qdd cases early process social security administration prioritize workload expedite case processing agency routinely refines qdd model reflect characteristics recent applicant population optimize ability identify strong candidates expedited processing,4,Service delivery
765,Mobile Wage Reporting (MOBWR),Office of Systems,Social Security Administration,SSA,AI,Mobile Wage Reporting uses AI to extract text/data from scanned images/documents represeting pay stubs or payroll information to enable faster processing.,mobile wage reporting uses ai extract scanned represeting pay stubs payroll information enable faster processing,18,Service / benefits access
794,Predictive modeling of invasive pest species and category at the port of entry using machine learning algorithms,USDA,Department of Agriculture,USDA,MACHINE LEARNING,Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.,macine learning algorithms used develop inspection data improve prediction ability detecting significant pests port entry,8,Asset management
795,Detection of pre-symptomatic HLB infected citrus,USDA,Department of Agriculture,USDA,VISUAL ANALYSIS,Identify pixels with HLB infection signature in multispectral and thermal imagery,identify pixels hlb infection signature multispectral thermal imagery,3,Asset management
796,High throughput phenotyping in citrus orchards,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Locate, count, and categorize citrus trees in an orchard to monitor orchard health",locate count categorize citrus trees orchard monitor orchard health,6,Service delivery
797,Detection of aquatic weeds,USDA,Department of Agriculture,USDA,MACHINE LEARNING,Identify and locate aquatic weeds,identify locate aquatic weeds,6,Service delivery
798,Automated Detection & Mapping of Host Plants from Ground Level Imagery,USDA,Department of Agriculture,USDA,MACHINE LEARNING,Generate maps of target trees from ground-level (streetview) imagery,generate maps target trees streetview imagery,9,"""Asset management"""
799,Standardization of cut flower business names for message set data,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"Natural language processing technique. Data are cleaned (e.g., remove punctuation) to facilitate matching. Cosine similarity is calculated, similar terms are matched, and the results are output.",natural language processing technique data cleaned remove punctuation facilitate matching cosine similarity calculated similar terms matched results output,5,Service / benefits access
800,"Approximate string or fuzzy matching, used to automate matching similar, but not identical, text in administrative documents",USDA,Department of Agriculture,USDA,FUZZY MATCHING,"The algorithm computes a string similarity metric which can be used to classify similar strings into a single category, reducing information duplication and onerous, manual error-checking",algorithm computes string similarity metric used classify similar strings single category reducing information duplication onerous manual,14,"""Internal operations"""
801,Training machine learning models to automatically read file attachments and save information into a more convenient Excel format.,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Artificial intelligence used to automate document processing and information extraction. Program managers often need information from specific form fields that are sent as PDF email attachments. Many emailed documents are received each day, making manually opening each attachment and copying the needed information too time-consuming. ",artificial intelligence used automate document processing information extraction program managers often need information specific form fields sent pdf email attachments many emailed documents received day making manually opening attachment copying needed information,9,Asset management
802,Artificial Intelligence for correlative statistical analysis,USDA,Department of Agriculture,USDA,"NEURAL NETWORKS,CLUSTERING","AI-type statistical techniques are used to model predictive relationships between variables. We routinely use modeling approaches such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, for statistical prediction. ",statistical techniques used model predictive relationships variables routinely use modeling approaches random forest artificial neural networks neighbor clustering support vector machines statistical prediction,12,Internal operations
803,4% Repair Dashboard,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"The model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as ""repair"" or ""not repair"" based on keywords in context.",model reviews descriptions expenses tagged repairs maintenance classifies expenses repair repair based keywords context,1,Asset management
804,ARS Project Mapping,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,NLP of research project plans including term analysis and clustering enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.,nlp research project plans including term analysis clustering enables national program leaders work interactive dashboard find synergies patterns within across various ars research program portfolios,9,Policy-making and public engagement
805,NAL Automated indexing,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"Cogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.",cogito vendor software uses ai automated subject indexing annotate peer reviewed journal articles annually using national ag library thesaurus concept space nalt nalt concepts annotated metadata content library bibliographic citation database agricola pubag ag data commons,14,Asset management
806,Democratizing Data,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"The purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.",purpose project use ai tools machine learning natural language processing understand data evidence used serve science society,18,Service Delivery
807,Westat,USDA,Department of Agriculture,USDA,"NATURAL LANGUAGE PROCESSING,MACHINE LEARNING,OTHER","A competition to find automated, yet effective, ways of linking USDA nutrition information to 750K food items in a proprietary data set of food purchases and acquisitions. Competing teams used a number of  AI methods including Natural Language Processing (NLP), random forest, and semantic matching.",competition find automated yet effective ways linking usda nutrition information food items proprietary data set food purchases acquisitions competing teams used number ai methods including natural language processing nlp random forest semantic matching,9,Service / benefits access
808,Retailer Receipt Analysis,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"The Retailer Receipt Analysis is a Proof of Concept (POC) that uses Optical Character Recognition (OCR), an application of artificial intelligence on a sample (no more than 1000) of FNS receipt and invoice data. Consultants will use this data to demonstrate how the existing manual process can be automated, saving staff time, ensuring accurate review, and detecting difficult patterns. The goal of this POC will pave the way for a review system that (1) has an automated workflow and learns from analyst feedback (2) can incorporate know SNAP fraud patterns, look for new patterns, and visualize alerts on these patterns on retailer invoices and receipts.",retailer receipt analysis proof concept poc uses optical character recognition ocr application artificial intelligence sample fns receipt invoice data consultants use data demonstrate existing manual process automated saving staff time ensuring accurate review detecting difficult patterns goal poc pave way review system automated workflow learns analyst feedback incorporate know snap fraud patterns look new patterns visualize alerts patterns retailer invoices receipts,7,Topic: Asset management
809,Nutrition Education & Local Access Dashboard,USDA,Department of Agriculture,USDA,"MACHINE LEARNING,K-MEANS CLUSTERING,VISUAL ANALYSIS","The goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health.Â As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.",goal dashboard provide visualization fns nutrition support specifically nutrition education local food access alongside metrics related hunger nutritional part dashboard team developed clustering script group states different clustering options farm school intensity size program activity intensity ethnicity race fresh food access school size program participation allows users find similar states based characteristics opening avenues partnerships states otherwise may considered,2,Service delivery
810,Land Change Analysis Tool (LCAT),USDA,Department of Agriculture,USDA,MACHINE LEARNING,We employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.,employ random forest machine learning classifier produce high resolution land cover maps aerial satellite imagery training data generate web application built operate docker cluster parallize processing tasks publishing results publicly available image service date mapped million acres generated thousand traiing samples,7,Asset management
811,OCIO/CDO Council Comment Analysis Tool,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"The Comment Analysis pilot has shown that a toolset leveraging recent advances in Natural Language Processing (NLP) can aid the regulatory comment analysis process. We developed tools that help comment reviewers identify the topics and themes of comments, as well as group comments that are semantically similar. Tools like these offer significant value by creating efficiencies through novel insights and streamlined processing of comments, reducing duplicative, upfront development efforts across government, and ultimately realizing cost savings for agencies and the USG. 
",comment analysis pilot shown toolset leveraging recent advances natural language processing nlp aid regulatory comment analysis process developed tools help comment reviewers identify topics themes comments well group comments semantically similar tools like offer significant value creating efficiencies novel insights streamlined processing comments reducing duplicative upfront development efforts across government ultimately realizing cost savings agencies usg,18,Policy-making and public engagement:
812,Ecosystem Management Decision Support System (EMDS),USDA,Department of Agriculture,USDA,MACHINE LEARNING,"EMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.",emds spatial decision support system landscape analysis planning runs component arcgis qgis users develop applications specific problem may use combination four ai engines logic processing decision analysis bayesian networks decision trees,12,Asset management
813,Wildland Urban Interface - Mapping Wildfire Loss,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"This is a proof-of-concept study to investigate the use of machine learning (deep learning / convolutional neural networks) and object-based image classification techniques to identify buildings, building loss, and defensible space around buildings before and after a wildfire event in wildland-urban interface settings.",study investigate use machine learning deep learning convolutional neural networks image classification techniques identify buildings building loss defensible space around buildings wildfire event interface settings,12,Asset management
814,CLT Knowledge Database,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"The CLT knowledge database catalogs cross-laminated timber information in an interface that helps users find relevant information. The information system uses data aggregator bots that search the internet for relevant information. These bots search for hundreds of keywords and use machine learning to determine if what is found is relevant. The search engine uses intelligent software to locate and update pertinent CLT references, as well as categorize information with respect to common application and interest areas. As of 2/24/2022, the CLT knowledge database has cataloged >3,600 publications on various aspects of CLT. This system fosters growth of mass timber markets by disseminating knowledge and facilitating collaboration among stakeholders, and by reducing the risk of duplication of efforts. Manufacturers, researchers, design professionals, code officials, government agencies, and other stakeholders directly benefit from the tool, thereby supporting the increasing use of mass timber, which benefits forest health by increasing the economic value of forests.",clt knowledge database catalogs timber information interface helps users find relevant information information system uses data aggregator bots search internet relevant information bots search hundreds keywords use machine learning determine found relevant search engine uses intelligent software locate update pertinent clt references well categorize information respect common application interest areas clt knowledge database cataloged publications various aspects clt system fosters growth mass timber markets disseminating knowledge facilitating collaboration among stakeholders reducing risk duplication efforts manufacturers researchers design professionals code officials government agencies stakeholders directly benefit tool thereby supporting increasing use mass timber benefits forest health increasing economic value forests,6,Asset management: use of AI to manage both physical and digital assets
815,RMRS Raster Utility,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"RMRS Raster Utility is a .NET object oriented library that simplifies data acquisition, raster sampling, and statistical and spatial modeling while reducing the processing time and storage space associated with raster analysis. It includes machine learning techniques.",rmrs raster utility object oriented library simplifies data acquisition raster sampling statistical spatial modeling reducing processing time storage space associated raster analysis includes machine learning techniques,11,Asset management
816,TreeMap 2016,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"TreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.",treemap provides model forests conterminous united states matches forest plot data forest inventory analysis fia meter grid treemap used private public sectors projects including fuel treatment planning snag hazard mapping estimation terrestrial carbon resources random forests algorithm used impute forest plot data set target rasters provided landscape fire resource management planning tools landfire https predictor variables consisted percent forest cover height vegetation type well topography slope elevation aspect location latitude longitude biophysical variables photosynthetically active radiation precipitation maximum temperature minimum temperature relative humidity vapour pressure deficit disturbance history time since disturbance disturbance type landscape circa,5,Asset management
817,Landscape Change Monitoring System (LCMS),USDA,Department of Agriculture,USDA,"MACHINE LEARNING,VISUAL ANALYSIS","The Landscape Change Monitoring System (LCMS) is a National landsat/sentinal remote sensing-based data produced by the USDA Forest Service for mapping and monitoring changes related to vegetation canopy cover, as well as land cover and land use. The process utilizes temporal change classifications together with training data in a supervised classification process for vegetation gain, and loss as well as land cover and use.",landscape change monitoring system lcms national remote data produced usda forest service mapping monitoring changes related vegetation canopy cover well land cover land use process utilizes temporal change classifications together training data supervised classification process vegetation gain loss well land cover use,12,Asset management
818,Geospatial and Remote Sensing Training Courses,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Several courses are offered which teach the use of software and scripting which allow for machine learning.  The courses change, but current topics include Intro and Advanced Change Detection, eCognition (software package), Geospatial Scripting for Google Earth Engine.  Some of the courses show how to use Collect Earth Online.",several courses offered teach use software scripting allow machine learning courses change current topics include intro advanced change detection ecognition software package geospatial scripting google earth engine courses show use collect earth online,3,Topic: Service Delivery
819,Forest Health Detection Monitoring,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Machine learning models are used to (1) upscale training data, using Sentinel-2, Landsat,  MODIS, and lidar imagery, that was collected from both the field and high-resolution imagery to map and monitor stages of forest mortality and defoliation across the United States, and (2) to post-process raster outputs to vector polygons.",machine learning models used upscale training data using landsat modis lidar imagery collected field imagery map monitor stages forest mortality defoliation across united states raster outputs vector polygons,7,Asset management
820,Cropland Data Layer,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"A machine learning algorithm is used to interpret readings from satellite-based sensors and CLASSIFY the type of crop or activity that falls in each 30 square meter pixel (a box of fixed size) on the ground.  The algorithms are trained on USDA&%2339;s Farm Services Agency data and other sources of data as sources of &quot;ground truth&quot;.  It allows us to not only produce a classification, but to assess the accuracy of the classification as well.  For commodities, like corn and soybeans, the CDL is highly accurate.  The CDL has been produced for national coverage since 2008.  Some summary and background about the CDL is available in a number of peer reviewed research papers and presentations
https://www.nass.usda.gov/Research_and_Science/Cropland/othercitations/index.php",machine learning algorithm used interpret readings sensors classify type crop activity falls square meter pixel box fixed size ground algorithms trained usda farm services agency data sources data sources quot ground truth quot allows us produce classification assess accuracy classification well commodities like corn soybeans cdl highly accurate cdl produced national coverage since summary background cdl available number peer reviewed research papers presentations https,15,Topic: Asset management
821,List Frame Deadwood Identification,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"The deadwood model leverages boosted regression trees with inputs such as  administrative linkage data, frame data, and historical response information as inputs, to produce a propensity score representing a relative likelihood of a farm operation being out of business.  Common tree splits were identified using the model and combined with expert knowledge to develop a recurring process for deadwood clean up.",deadwood model leverages boosted regression trees inputs administrative linkage data frame data historical response information inputs produce propensity score representing relative likelihood farm operation business common tree splits identified using model combined expert knowledge develop recurring process deadwood clean,2,Topic: Asset management
822,Census of Agricuilture Response Propensity Scores,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"The response propensity scores to the COA are derived from random forest models that use historical data, control data, and other survey data. These scores are used to help target more effective data collection.",response propensity scores coa derived random forest models use historical data control data survey data scores used help target effective data collection,7,Internal operations
823,Climate Change Classification NLP,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"The model classifies NIFA funded projects as climate change related or not climate related through natural language processing techniques. The model input features include text fields containing the project's title, non-technical summary, objectives and keywords. The target is a dummy variable classification of projects as climate change related or not climate change related.",model classifies nifa funded projects climate change related climate related natural language processing techniques model input features include text fields containing project title summary objectives keywords target dummy variable classification projects climate change related climate change related,12,"""Service / benefits access"""
824,Operational water supply forecasting for western US rivers,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Western US water management is underpinned by forecasts of spring-summer river flow volumes made using operational hydrologic models. The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center operates the largest such forecast system regionally, carrying on a nearly century-old tradition. The NWCC recently developed a next-generation prototype for generating such operational water supply forecasts (WSFs), the multi-model machine-learning metasystem (M4), which integrates a variety of AI and other data-science technologies carefully chosen or developed to satisfy specific user needs. Required inputs are data around snow and precipitation from the NRCS Snow Survey and Water Supply Forecast program SNOTEL environmental monitoring network, but are flexible.  In hindcasting test-cases spanning diverse environments across the western US and Alaska, out-of-sample accuracy improved markedly over current benchmarks. Various technical design elements, including multi-model ensemble modeling, autonomous machine learning (AutoML), hyperparameter pre-calibration, and theory-guided data science, collectively permitted automated training and operation.  Live operational testing at a subset of sites additionally demonstrated logistical feasibility of workflows, as well as geophysical explainability of results in terms of known hydroclimatic processes, belying the black-box reputation of machine learning and enabling relatable forecast storylines for NRCS customers.",western us water management underpinned forecasts river flow volumes made using operational hydrologic models usda natural resources conservation service nrcs national water climate center operates largest forecast system regionally carrying nearly tradition nwcc recently developed prototype generating operational water supply forecasts wsfs metasystem integrates variety ai technologies carefully chosen developed satisfy specific user needs required inputs data around snow precipitation nrcs snow survey water supply forecast program snotel environmental monitoring network flexible hindcasting spanning diverse environments across western us alaska accuracy improved markedly current benchmarks various technical design elements including ensemble modeling autonomous machine learning automl hyperparameter data science collectively permitted automated training operation live operational testing subset sites additionally demonstrated logistical feasibility workflows well geophysical explainability results terms known hydroclimatic processes belying reputation machine learning enabling relatable forecast storylines nrcs customers,19,Asset management
825,Ecological Site Descriptions (machine learning),USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Analysis of over 20 million records of soils data and 20,000 text documents of ecological state and transition information. ",analysis million records soils data text documents ecological state transition information,9,Asset management
826,Conservation Effects Assessment Project,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"The goal is to predict conservation benefits at the field level. The model uses farmer survey data, APEX modeling results and environmental data.",goal predict conservation benefits field level model uses farmer survey data apex modeling results environmental data,7,Service delivery
827,Digital Imagery (no-change) for NRI program,USDA,Department of Agriculture,USDA,NEURAL NETWORKS,Using neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program ,using neural networks ai technologies detect digital imagery nri national resources inventory program,12,"""Asset management"""
828,Artificial Intelligence SPAM Mitigation Project,USDA,Department of Agriculture,USDA,"MACHINE LEARNING,MACHINE LANGUAGE LEARNING","The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. 
",ai solution invoves robotic process automation model solution automatically classify remove spam marketing emails appear civil rights complaints email channels significant portion incoming oascr emails spam marketing phishing emails,4,"""Service / benefits access"""
829,Acquisition Approval Request Compliance Tool,USDA,Department of Agriculture,USDA,NATURAL LANGUAGE PROCESSING,"A natural language processing (NLP) model was developed to utilize the text in procurement header and line descriptions within USDA's Integrated Acquisition System (IAS) to determine the likelihood that an award is IT-related, and therefore might require an AAR. The model uses the text characteristics for awards that have an AAR number entered into IAS and then calculates the probability of being IT-related for those procurements that did not have an AAR Number entered in IAS.",natural language processing nlp model developed utilize text procurement header line descriptions within usda integrated acquisition system ias determine likelihood award therefore might require aar model uses text characteristics awards aar number entered ias calculates probability procurements aar number entered ias,9,Asset management: use of AI to manage both physical and digital assets
830,Intelligent Ticket Routing,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Routes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.",routes bmc remedy tickets proper work group automatically utilizing python jupyterhub scikit learn gitlab flask gunicorn nginx erms,14,Topic: Hotlines and service desks
831,Predictive Maintenance Impacts,USDA,Department of Agriculture,USDA,MACHINE LEARNING,"Predict impacts of DISC maintenance on infrastructure items.  Utilizes: einblick, mysql, python, linux, tableau",predict impacts disc maintenance infrastructure items utilizes einblick mysql python linux tableau,14,Asset management
832,Video Surveillance System,USDA,Department of Agriculture,USDA,VISUAL ANALYSIS,"The Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.",video surveillance system vss system design include video management system nvrs dvrs encoders fixed cameras pan tilt cameras network switches routers ip cables equipment racks mounting hardware video surveillance system vss shall control multiple sources video surveillance subsystems collect manage present video clearly concisely vms shall integrate capabilities subsystem across single multiple sites allowing video management compatible analog digital video device unified configuration platform viewer disparate video systems normalized funneled shared video experience drag drop cameras security management system hardware tree vms views leverage security management system alarm integration advanced features help operator track target set sequential cameras simplified method select new central camera surrounding camera views,16,Asset management: use of AI to manage both physical and digital assets
833,Artificial Intelligence physical therapy app,,Department of Veterans Affairs,VA,,This app is a physical therapy support tool.Â  It is a data source agnostic tool which takes input from a variety of wearable sensors and then analyzes the data to give feedback to the physical therapist in an explainable format.Â ,app physical therapy support data source agnostic tool takes input variety wearable sensors analyzes data give feedback physical therapist explainable,14,"""Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments """
834,Artificial intelligence coach in cardiac surgery,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"The artificial intelligence coach in cardiac surgery infers misalignment in team membersâ mental models during complex healthcare task execution. Of interest are safety-critical domains (e.g., aviation, healthcare), where lack of shared mental models can lead to preventable errors and harm. Identifying model misalignment provides a building block for enabling computer-assisted interventions to improve teamwork and augment human cognition in the operating room.",artificial intelligence coach cardiac surgery infers misalignment team mental models complex healthcare task execution interest domains aviation healthcare lack shared mental models lead preventable errors harm identifying model misalignment provides building block enabling interventions improve teamwork augment human cognition operating room,10,Service delivery:
835,AI Cure,,Department of Veterans Affairs,VA,,AICURE is a phone app that monitors adherence to orally prescribed medications during clinical or pharmaceutical sponsorÂ  drug studies.,aicure phone app monitors adherence orally prescribed medications clinical pharmaceutical sponsorâ drug studies,9,Service delivery
836,Acute kidney injury (AKI),,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.",project collaboration google deepmind focuses detecting acute kidney injury aki ranging minor loss kidney function complete kidney failure artificial intelligence also detect aki may result another illness,13,Service delivery
837,Assessing lung function in health and disease,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.,health professionals use artificial intelligence determine predictors normal abnormal lung function sleep parameters,13,Service / benefits access
838,Automated eye movement analysis and diagnostic prediction of neurological disease,,Department of Veterans Affairs,VA,,"Artificial intelligenceÂ  recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).",artificial intelligenceâ recursively analyzes previously collected data improve quality accuracy automated algorithms well screen markers neurological disease traumatic brain injury parkinson stroke etc,13,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
839,Automatic speech transcription engines to aid scoring neuropsychological tests.,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,Automated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.,automated speech transcription engines analyze cognitive decline older va patients digitally recorded speech responses transcribed using multiple artificial engines transcriptions fused together reduce obviate need manual transcription patient speech order score neuropsychological tests,5,Service / benefits access
840,CuraPatient,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"CuraPatient is a remote tool that allows patients to better manage their conditions without having to see a provider.Â  Driven by artificial intelligence, it allows patients to create a profile to track their health, enroll in programs, manage insurance, and schedule appointments.",curapatient remote tool allows patients better manage conditions without see driven artificial intelligence allows patients create profile track health enroll programs manage insurance schedule appointments,12,Service delivery
841,Digital command center,,Department of Veterans Affairs,VA,,The Digital Command Center seeks to consolidate all data in a medical center and apply predictive prescriptive analytics to allow leaders to better optimize hospital performance.Â Â ,digital command center seeks consolidate data medical center apply predictive prescriptive analytics allow leaders better optimize hospital â,3,Service delivery
842,Disentangling dementia patterns using artificial intelligence on brain imaging and electrophysiological data,,Department of Veterans Affairs,VA,DEEP LEARNING,This collaborative effort focuses on developing a deep learning framework to predict the various patterns of dementia seen on MRI and EEG and explore the use of these imaging modalities as biomarkers for various dementias and epilepsy disorders.Â  The VA is performing retrospective chart review to achieve this.,collaborative effort focuses developing deep learning framework predict various patterns dementia seen mri eeg explore use imaging modalities biomarkers various dementias epilepsy va performing retrospective chart review achieve,16,Internal operations
843,Machine learning (ML) for enhanced diagnostic error detection and ML classification of protein electrophoresis text,,Department of Veterans Affairs,VA,MACHINE LEARNING,"Researchers are performing chart review to collect true/false positive annotations and construct a vector embedding of patient records, followed by similarity-based retrieval of unlabeled records ""near"" the labeled ones (semi-supervised approach). The aim is to use machine learning as a filter, after the rules-based retrieval, to improve specificity. Embedding inputs will be selected high-value structured data pertinent to stroke risk and possibly selected prior text notes.",researchers performing chart review collect positive annotations construct vector embedding patient records followed retrieval unlabeled records near labeled ones approach aim use machine learning filter retrieval improve specificity embedding inputs selected structured data pertinent stroke risk possibly selected prior text notes,2,Service / benefits access
844,Behavidence,,Department of Veterans Affairs,VA,,Behavidence is a mental health tracking app. Veterans download the app onto their phone and it compares their phone usage to that of a digital phenotype that represents people with confirmed diagnosis of mental health conditions.Â ,behavidence mental health tracking app veterans download app onto phone compares phone usage digital phenotype represents people confirmed diagnosis mental health,1,Service / benefits access
845,Machine learning tools to predict outcomes of hospitalized VA patients,,Department of Veterans Affairs,VA,MACHINE LEARNING,"This is an IRB-approved study which aims to examine machine learning approaches to predict health outcomes of VA patients.Â  It will focus on the prediction of Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",study aims examine machine learning approaches predict health outcomes va focus prediction alzheimer disease rehospitalization chlostridioides difficile infection,1,Service delivery
846,Nediser reports QA,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"Nediser is a continuously trained artificial intelligence âradiology residentâ that assists radiologists in confirming the X-ray properties in their radiology reports.Â  Nediser can select normal templates, detect hardware, evaluate patella alignment and leg length and angle discrepancy, and measure Cobb angles.",nediser continuously trained artificial intelligence assists radiologists confirming properties radiology nediser select normal templates detect hardware evaluate patella alignment leg length angle discrepancy measure cobb angles,16,Service delivery
847,Precision medicine PTSD and suicidality diagnostic and predictive tool,,Department of Veterans Affairs,VA,,"This model interprets various real time inputs in a diagnostic and predictive capacity in order to forewarn episodes of PTSD and suicidality, support early and accurate diagnosis of the same, and gain a better understanding of the short and long term effects of stress, especially in extreme situations, as it relates to the onset of PTSD.",model interprets various real time inputs diagnostic predictive capacity order forewarn episodes ptsd suicidality support early accurate diagnosis gain better understanding short long term effects stress especially extreme situations relates onset ptsd,11,Service / benefits access
848,Prediction of Veterans' Suicidal Ideation following Transition from Military Service,,Department of Veterans Affairs,VA,MACHINE LEARNING,Machine learning is used to identify predictors of veterans' suicidal ideation. The relevant data come from a web-based survey of veteransâ experiences within three months of separation and every six months after for the first three years after leaving military service.,machine learning used identify predictors veterans suicidal ideation relevant data come survey experiences within three months separation every six months first three years leaving military service,1,"""Service / benefits access"""
849,PredictMod,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,PredictMod uses artificial intelligence to determine if predictions can be made about diabetes based on the gut microbiome.,predictmod uses artificial intelligence determine predictions made diabetes based gut microbiome,5,Service delivery
850,Predictor profiles of OUD and overdose,,Department of Veterans Affairs,VA,"MACHINE LEARNING, MACHINE LEARNING CLASSIFICATION, CLASSIFICATION",Machine learning prediction models evaluate the interactions of known and novel risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Several machine learning classification-tree modeling approaches are used to develop predictor profiles of OUD and overdose.Â ,machine learning prediction models evaluate interactions known novel risk factors opioid use disorder oud overdose veterans several machine learning modeling approaches used develop predictor profiles oud,1,Service delivery
851,Provider directory data accuracy and system of record alignment,,Department of Veterans Affairs,VA,"MACHINE LEARNING, AI","AI is used to add value as a transactor for intelligent identity resolution and linking.Â  AI also has a domain cache function that can be used for both Clinical Decision Support and for intelligent state reconstruction over time and real-time discrepancy detection.Â  As a synchronizer, AI can perform intelligent propagation and semi-automated discrepancy resolution.Â  AI adapters can be used for inference via OWL and logic programming.Â  Lastly, AI has long term storage (âblack box flight recorderâ) for virtually limitless machine learning and BI applications.",ai used add value transactor intelligent identity resolution ai also domain cache function used clinical decision support intelligent state reconstruction time discrepancy synchronizer ai perform intelligent propagation discrepancy ai adapters used inference via owl logic lastly ai long term storage box flight virtually limitless machine learning bi applications,16,Service delivery:
852,Seizure detection from EEG and video,,Department of Veterans Affairs,VA,MACHINE LEARNING,Machine learning algorithms use EEG and video data from a VHA epilepsy monitoring unit in order to automatically identify seizures without human intervention.,machine learning algorithms use eeg video data vha epilepsy monitoring unit order automatically identify seizures without human intervention,18,"""Service / benefits access"""
853,SoKat Suicidial Ideation Detection Engine,,Department of Veterans Affairs,VA,"NATURAL LANGUAGE PROCESSING, NLP",The SoKat Suicide Ideation Engine (SSIE) uses natural language processing (NLP) to improve identification of Veteran suicide ideation (SI) from survey data collected by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team (VSignals).,sokat suicide ideation engine ssie uses natural language processing nlp improve identification veteran suicide ideation si survey data collected office mental health omh veteran crisis line vcl support team vsignals,9,Topic: 11. Other
854,Using machine learning to predict perfusionistsâ critical decision-making during cardiac surgery,,Department of Veterans Affairs,VA,"MACHINE LEARNING, DECISION-MAKING","A machine learning approach is used to build predictive models of perfusionistsâ decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.",machine learning approach used build predictive models critical situations occur cardiopulmonary bypass phase cardiac surgery results may inform future development computerized clinical decision support tools embedded operating room improving patient safety surgical outcomes,7,Service delivery
855,Gait signatures in patients with peripheral artery disease,,Department of Veterans Affairs,VA,MACHINE LEARNING,Machine learning is used to improve treatment of functional problems in patients with peripheral artery disease (PAD). Previously collected biomechanics data is used to identify representative gait signatures of PAD to 1) determine the gait signatures of patients with PAD and 2) the ability of limb acceleration measurements to identify and model the meaningful biomechanics measures from PAD data.,machine learning used improve treatment functional problems patients peripheral artery disease pad previously collected biomechanics data used identify representative gait signatures pad determine gait signatures patients pad ability limb acceleration measurements identify model meaningful biomechanics measures pad data,1,Service delivery
856,Medication Safety (MedSafe) Clinical Decision Support (CDS),,Department of Veterans Affairs,VA,,"Using VA electronic clinical data, the Medication Safety (MedSafe) Clinical Decision Support (CDS) system analyzes current clinical management for diabetes, hypertension, and chronic kidney disease, and makes patient-specific, evidence-based recommendations to primary care providers.Â  The system uses knowledge bases that encode clinical practice guideline recommendations and an automated execution engine to examine multiple comorbidities, laboratory test results, medications, and history of adverse drug events in evaluating patient clinical status and generating patient-specific recommendations",using va electronic clinical data medication safety medsafe clinical decision support cds system analyzes current clinical management diabetes hypertension chronic kidney disease makes recommendations primary care system uses knowledge bases encode clinical practice guideline recommendations automated execution engine examine multiple comorbidities laboratory test results medications history adverse drug events evaluating patient clinical status generating recommendations,5,Service Delivery
857,"Prediction of health outcomes, including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",,Department of Veterans Affairs,VA,,"Using electronic health records (EHR) (both structured and unstructured data) asÂ  inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",using electronic health records ehr structured unstructured data asâ inputs tool outputs deep phenotypes predictions health outcomes including suicide death opioid overdose decompensated outcomes chronic diseases,13,Service / benefits access:
858,VA-DoE Suicide Exemplar Project,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,The VA-DoE Suicide Exemplar project is currently utilizing artificial intelligence to improve VA's ability to identify Veterans at risk for suicide through three closely related projects that all involve collaborations with the Department of Energy.,suicide exemplar project currently utilizing artificial intelligence improve va ability identify veterans risk suicide three closely related projects involve collaborations department energy,10,Service delivery: use of AI to provide direct services either to the public or to state/local/tribal/territorial governments
859,Machine learning models to predict disease progression among veterans with hepatitis C virus,,Department of Veterans Affairs,VA,MACHINE LEARNING,A machine learning model is used to predict disease progression among veterans with hepatitis C virus.,machine learning model used predict disease progression among veterans hepatitis c virus,1,Service Delivery
860,Prediction of biologic response to thiopurines,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"Using CPRS and CDW data, artificial intelligence is used to predict biologic response to thiopurines among Veterans with irritable bowel disease.",using cprs cdw data artificial intelligence used predict biologic response thiopurines among veterans irritable bowel disease,1,Service delivery
861,Predicting hospitalization and corticosteroid use as a surrogate for IBD flares,,Department of Veterans Affairs,VA,RANDOM FOREST,"This work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.",work examines data veterans health administration vha patients irritable bowel disease ibd diagnosis longitudinal labs associated predictors used random forest models predict hospitalizations steroid usage surrogate ibd flares,1,Topic: Service / benefits access
862,Predicting corticosteroid free endoscopic remission with Vedolizumab in ulcerative colitis,,Department of Veterans Affairs,VA,RANDOM FOREST,This work uses random forest modeling on a cohort of 594 patients with Vedolizumab to predict the outcome of corticosteroid-free biologic remission at week 52 on the testing cohort. Models were constructed using baseline data or data through week 6 of VDZ therapy.,work uses random forest modeling cohort patients vedolizumab predict outcome biologic remission week testing cohort models constructed using baseline data data week vdz therapy,7,Internal operations
863,Use of machine learning to predict surgery in Crohnâs disease,,Department of Veterans Affairs,VA,MACHINE LEARNING,"Machine learning analyzes patient demographics, medication use, and longitudinal laboratory values collected between 2001 and 2015 from adult patients in the Veterans Integrated Service Networks (VISN) 10 cohort. The data was used for analysis in prediction of Crohnâs disease and to model future surgical outcomes within 1 year.",machine learning analyzes patient demographics medication use longitudinal laboratory values collected adult patients veterans integrated service networks visn cohort data used analysis prediction disease model future surgical outcomes within year,1,Service delivery
864,Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus,,Department of Veterans Affairs,VA,MACHINE LEARNING,A machine learning model is used to predict disease progression among veterans with hepatitis C virus.,machine learning model used predict disease progression among veterans hepatitis c virus,1,Service delivery
865,Predicting hepatocellular carcinoma in patients with hepatitis C,,Department of Veterans Affairs,VA,"REGRESSION, DEEP LEARNING, RECURRENT NEURAL NETWORK",This prognostic study used data on patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. The data was used to examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).,prognostic study used data patients hepatitis c virus hcv cirrhosis national veterans health administration least years diagnosis cirrhosis data used examine whether deep learning recurrent neural network rnn models use raw longitudinal data extracted directly electronic health records outperform conventional regression models predicting risk developing hepatocellular carcinoma hcc,1,Internal operations
866,Computer-aided detection and classification of colorectal polyps,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,This study is investigating the use of artificial intelligence models for improving clinical management of colorectal polyps. The models receive video frames from colonoscopy video streams and analyze them in real time in order to (1) detect whether a polyp is in the frame and (2) predict the polyp's malignant potential.,study investigating use artificial intelligence models improving clinical management colorectal polyps models receive video frames colonoscopy video streams analyze real time order detect whether polyp frame predict polyp malignant potential,9,Service delivery
867,GI Genius (Medtronic),,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,The Medtronic GI Genius aids in detection of colon polyps through artificial intelligence.,medtronic gi genius aids detection colon polyps artificial intelligence,12,Service delivery
868,Extraction of family medical history from patient records,,Department of Veterans Affairs,VA,,This pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.,pilot project uses tiu documentation african american veterans aged extract family medical history data identify veterans risk prostate cancer undergone prostate cancer screening,1,Service delivery
869,VA /IRB approved research study for finding colon polyps,,Department of Veterans Affairs,VA,,This IRB approved research study usesÂ  a randomized trial for finding colon polyps with artifical intelligence.,irb approved research study usesâ randomized trial finding colon polyps artifical intelligence,9,Service delivery
870,Interpretation/triage of eye images,,Department of Veterans Affairs,VA,ARTIFICIAL INTELLIGENCE,"Artificial intelligence supports triage of eye patients cared for through telehealth, interprets eye images, and assesses health risks based on retina photos. The goal is to improve diagnosis of a variety of conditions, including glaucoma, macular degeneration, and diabetic retinopathy.",artificial intelligence supports triage eye patients cared telehealth interprets eye images assesses health risks based retina photos goal improve diagnosis variety conditions including glaucoma macular degeneration diabetic retinopathy,12,Topic: Service / benefits access
871,Screening for esophageal adenocarcinoma,,Department of Veterans Affairs,VA,,National VHA administrative data is used to adapt tools that use electronic health records to predict the risk for esophageal adenocarcinoma.,national vha administrative data used adapt tools use electronic health records predict risk esophageal adenocarcinoma,18,Service / benefits access:
872,Social determinants of health extractor,,Department of Veterans Affairs,VA,AI,"AI is used with clinical notes to identify social determinants of health (SDOH) information. The extracted SDOH variables can be used during associated health related analysis to determine, among other factors, whether SDOH can be a contributor to disease risks or healthcare inequality.",ai used clinical notes identify social determinants health sdoh information extracted sdoh variables used associated health related analysis determine among factors whether sdoh contributor disease risks healthcare inequality,1,"""Service / benefits access"""
